{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"nbagg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_bci as bci\n",
    "from utility import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "Fetches the data from the server and saves it to a folder at the root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n",
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_input_100, train_target_100, test_input_100, test_target_100 = import100HzData()\n",
    "train_input, train_target, test_input, test_target = import1000HzData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([316, 28, 500])\n",
      "torch.Size([316])\n",
      "torch.Size([100, 28, 500])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape) \n",
    "print(train_target.shape) \n",
    "print(test_input.shape) \n",
    "print(test_target.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rawDataForSingleElectrodeVisualization(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the neural network from the Neural Networks section before and modify it to take 18-channel signal (instead of 1-channel images as it was defined)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.n_filters_time=25\n",
    "        self.n_filters_spat=25\n",
    "        self.n_filters_conv=25\n",
    "        self.n_input_channel=28\n",
    "        self.final_conv_length=2 #!!!!!\n",
    "        self.filter_time_length=10\n",
    "        self.conv_stride = 1  #Stride after pooling \n",
    "        self.pool_stride = 3\n",
    "        self.batch_norm_alpha=0.1\n",
    "        self.pool_time_length=3\n",
    "        self.pool_time_stride=3\n",
    "        self.n_filters_2=50\n",
    "        self.filter_length_2=10\n",
    "        self.n_filters_3=100\n",
    "        self.filter_length_3=10\n",
    "        self.n_filters_4=200\n",
    "        self.filter_length_4=10\n",
    "        self.drop_prob=0.5\n",
    "        self.batch_norm=True\n",
    "        self.n_classes=2\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Layer 1 - REMINDER nn.Conv2d(nbChannels, outputChannels, kxk Square convolution)\n",
    "            nn.Conv2d(1, self.n_filters_time, (1, self.filter_time_length), stride = 1), #'Time Convolution' \n",
    "            nn.Conv2d(25, self.n_filters_spat, (self.n_input_channel, 1), stride=(self.conv_stride, 1), bias=False), #'Spatial Convolution' \n",
    "            nn.BatchNorm2d(self.n_filters_conv, momentum=self.batch_norm_alpha, affine=True, eps=1e-5),\n",
    "            nn.MaxPool2d(kernel_size=(1, self.pool_time_length), stride=(1, self.pool_stride)),\n",
    "\n",
    "            # Layer 2\n",
    "            nn.Dropout(p=self.drop_prob),\n",
    "            nn.Conv2d(self.n_filters_conv, self.n_filters_2,(1, self.filter_length_2),stride=(1, self.conv_stride),\n",
    "                                       bias=False),\n",
    "            nn.BatchNorm2d(self.n_filters_2,momentum=self.batch_norm_alpha,affine=True,eps=1e-5),\n",
    "            nn.MaxPool2d(kernel_size=(1, self.pool_time_length),stride=(1, self.pool_stride)),\n",
    "\n",
    "            # Layer 3\n",
    "            nn.Dropout(p=self.drop_prob),\n",
    "            nn.Conv2d(self.n_filters_2, self.n_filters_3, (1, self.filter_length_3), stride=(1, self.conv_stride),\n",
    "                                       bias=False),\n",
    "            nn.BatchNorm2d(self.n_filters_3,momentum=self.batch_norm_alpha,affine=True,eps=1e-5),\n",
    "            nn.MaxPool2d(kernel_size=(1, self.pool_time_length), stride=(1, self.pool_stride)),\n",
    "\n",
    "            # Layer 4\n",
    "            nn.Dropout(p=self.drop_prob),\n",
    "            nn.Conv2d(self.n_filters_3, self.n_filters_4,\n",
    "                                       (1, self.filter_length_4),\n",
    "                                       stride=(1, self.conv_stride),\n",
    "                                       bias=False),\n",
    "            nn.BatchNorm2d(self.n_filters_4,momentum=self.batch_norm_alpha,affine=True,eps=1e-5),\n",
    "            nn.MaxPool2d(kernel_size=(1, self.pool_time_length),stride=(1, self.pool_stride-1)),\n",
    "\n",
    "            #Classifier Layer\n",
    "            #nn.Conv2d(self.n_filters_4, self.n_classes, (1, self.final_conv_length), bias=True),\n",
    "            #nn.LogSoftmax(dim=-1),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(200*1*2, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 2),)\n",
    "              \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.features(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 200*1*2)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        print(x.shape)\n",
    "\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "Let’s use a Classification Cross-Entropy loss and SGD with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#criterion = nn.BCELoss()\n",
    "#optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.7016448378562927\n",
      "\n",
      "Epoch  1\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6946173310279846\n",
      "\n",
      "Epoch  2\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6990748643875122\n",
      "\n",
      "Epoch  3\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6915135979652405\n",
      "\n",
      "Epoch  4\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.693992018699646\n",
      "\n",
      "Epoch  5\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6972536444664001\n",
      "\n",
      "Epoch  6\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.7037245035171509\n",
      "\n",
      "Epoch  7\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.693381130695343\n",
      "\n",
      "Epoch  8\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6939682960510254\n",
      "\n",
      "Epoch  9\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6951721906661987\n",
      "\n",
      "Epoch  10\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6897551417350769\n",
      "\n",
      "Epoch  11\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6937182545661926\n",
      "\n",
      "Epoch  12\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6981492638587952\n",
      "\n",
      "Epoch  13\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.692133367061615\n",
      "\n",
      "Epoch  14\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6982240676879883\n",
      "\n",
      "Epoch  15\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6843557953834534\n",
      "\n",
      "Epoch  16\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6934041380882263\n",
      "\n",
      "Epoch  17\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6929678916931152\n",
      "\n",
      "Epoch  18\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6887351870536804\n",
      "\n",
      "Epoch  19\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6972193717956543\n",
      "\n",
      "Epoch  20\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6965407729148865\n",
      "\n",
      "Epoch  21\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6950883269309998\n",
      "\n",
      "Epoch  22\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6907245516777039\n",
      "\n",
      "Epoch  23\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6946833729743958\n",
      "\n",
      "Epoch  24\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6938737034797668\n",
      "\n",
      "Epoch  25\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.698483943939209\n",
      "\n",
      "Epoch  26\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6871999502182007\n",
      "\n",
      "Epoch  27\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6855130195617676\n",
      "\n",
      "Epoch  28\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6863111853599548\n",
      "\n",
      "Epoch  29\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6968064308166504\n",
      "\n",
      "Epoch  30\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6940399408340454\n",
      "\n",
      "Epoch  31\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6901983022689819\n",
      "\n",
      "Epoch  32\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6877516508102417\n",
      "\n",
      "Epoch  33\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6887410879135132\n",
      "\n",
      "Epoch  34\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6852575540542603\n",
      "\n",
      "Epoch  35\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6907618641853333\n",
      "\n",
      "Epoch  36\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6897048354148865\n",
      "\n",
      "Epoch  37\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6960597634315491\n",
      "\n",
      "Epoch  38\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6874071955680847\n",
      "\n",
      "Epoch  39\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6911271214485168\n",
      "\n",
      "Epoch  40\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6933650374412537\n",
      "\n",
      "Epoch  41\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6854694485664368\n",
      "\n",
      "Epoch  42\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6793282628059387\n",
      "\n",
      "Epoch  43\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.687479555606842\n",
      "\n",
      "Epoch  44\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6871407628059387\n",
      "\n",
      "Epoch  45\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6873636245727539\n",
      "\n",
      "Epoch  46\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6869531273841858\n",
      "\n",
      "Epoch  47\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6867451071739197\n",
      "\n",
      "Epoch  48\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6881002187728882\n",
      "\n",
      "Epoch  49\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6863027215003967\n",
      "\n",
      "Epoch  50\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6870291233062744\n",
      "\n",
      "Epoch  51\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6806201934814453\n",
      "\n",
      "Epoch  52\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6855310797691345\n",
      "\n",
      "Epoch  53\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6871996521949768\n",
      "\n",
      "Epoch  54\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6820931434631348\n",
      "\n",
      "Epoch  55\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6800728440284729\n",
      "\n",
      "Epoch  56\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.684219479560852\n",
      "\n",
      "Epoch  57\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6789602041244507\n",
      "\n",
      "Epoch  58\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6894830465316772\n",
      "\n",
      "Epoch  59\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6767959594726562\n",
      "\n",
      "Epoch  60\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6862645745277405\n",
      "\n",
      "Epoch  61\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6765134930610657\n",
      "\n",
      "Epoch  62\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.677394688129425\n",
      "\n",
      "Epoch  63\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.688378632068634\n",
      "\n",
      "Epoch  64\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6799231171607971\n",
      "\n",
      "Epoch  65\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6841543912887573\n",
      "\n",
      "Epoch  66\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6779878735542297\n",
      "\n",
      "Epoch  67\n",
      "torch.Size([316, 1, 28, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6776832342147827\n",
      "\n",
      "Epoch  68\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6783090233802795\n",
      "\n",
      "Epoch  69\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.675460159778595\n",
      "\n",
      "Epoch  70\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.674898624420166\n",
      "\n",
      "Epoch  71\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6755468845367432\n",
      "\n",
      "Epoch  72\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6751258373260498\n",
      "\n",
      "Epoch  73\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6761224865913391\n",
      "\n",
      "Epoch  74\n",
      "torch.Size([316, 1, 28, 500])\n",
      "torch.Size([316, 200, 1, 2])\n",
      "torch.Size([316, 2])\n",
      "Running loss 0.6784277558326721\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(75):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "    running_loss = 0.0\n",
    "   \n",
    "    #inputs = torch.from_numpy(normalized_input_train).float()\n",
    "    inputs = train_input #x_train\n",
    "    inputs = torch.unsqueeze(inputs,1) # make it float and insert a fake batch dimension\n",
    "    labels = train_target #y_train\n",
    "\n",
    "    # wrap them in Variable\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    " \n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.data[0]\n",
    "    print(\"Running loss\", running_loss)\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset - Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 500])\n",
      "torch.Size([100, 200, 1, 2])\n",
      "torch.Size([100, 2])\n",
      "Accuracy of the network on the test singals: 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#prediction = torch.from_numpy(normalized_input_test).float() #With normalized input \n",
    "prediction = test_input #x_train\n",
    "prediction_squeezed = torch.unsqueeze(prediction,1) # make it float and insert a fake batch dimension\n",
    "labels = test_target #y_train\n",
    "\n",
    "# wrap them in Variable\n",
    "predictionVar, labelsVar = Variable(prediction_squeezed), Variable(labels)\n",
    "\n",
    "# forward + backward + optimize\n",
    "#The outputs are energies for the 10 classes. Higher the energy for a class, the more the network thinks\n",
    "#that the image is of the particular class. So, let’s get the index of the highest energy:\n",
    "outputsPred = net(predictionVar) \n",
    "\n",
    "_, predicted = torch.max(outputsPred.data, 1) #predicted contains the predicted labels \n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the test singals: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       "[torch.LongTensor of size 100]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape\n",
    "\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
