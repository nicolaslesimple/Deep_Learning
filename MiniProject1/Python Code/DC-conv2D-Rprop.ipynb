{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input 100 Hz: 316x28x50\n",
      "Train target 100 Hz: 316\n",
      "Test input 100 Hz: 100x28x50\n",
      "Test target 100 Hz: 100\n",
      "\n",
      "Train input 1000 Hz: 316x28x500\n",
      "Train target 1000 Hz: 316\n",
      "Test input 1000 Hz: 100x28x500\n",
      "Test target 1000 Hz: 100\n"
     ]
    }
   ],
   "source": [
    "import dlc_bci\n",
    "\n",
    "train_input_100 , train_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False)\n",
    "test_input_100 , test_target_100 = dlc_bci.load(root = './data_bci_100Hz', download = False, train = False)\n",
    "\n",
    "train_input_1000 , train_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, one_khz = True)\n",
    "test_input_1000 , test_target_1000 = dlc_bci.load(root = './data_bci_1000Hz', download = False, train = False, one_khz = True)\n",
    "\n",
    "print(\"Train input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_100.size())))\n",
    "print(\"Train target 100 Hz: {:d}\".format(*(s for s in train_target_100.size())))\n",
    "print(\"Test input 100 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_100.size())))\n",
    "print(\"Test target 100 Hz: {:d}\".format(*(s for s in test_target_100.size())))\n",
    "print(\"\")\n",
    "print(\"Train input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in train_input_1000.size())))\n",
    "print(\"Train target 1000 Hz: {:d}\".format(*(s for s in train_target_1000.size())))\n",
    "print(\"Test input 1000 Hz: {:d}x{:d}x{:d}\".format(*(s for s in test_input_1000.size())))\n",
    "print(\"Test target 1000 Hz: {:d}\".format(*(s for s in test_target_1000.size())))\n",
    "\n",
    "Ntrain = train_input_100.size(0)\n",
    "Ntest = test_input_100.size(0)\n",
    "Nchannels = train_input_100.size(1)\n",
    "Nsamples_100 = train_input_100.size(-1)\n",
    "Nsamples_1000 = train_input_1000.size(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Nchannels, Nsamples, output_units):\n",
    "        \"\"\"Initializes neural network with 3 convolutional layers and 1 fully-connected layer.\n",
    "        \n",
    "        Args:\n",
    "            - Nchannels (int): number of EEG channels\n",
    "            - Nsamples (int): number of time points in each EEG signal\n",
    "            - output_units (int): number of output units, e.g. 1 for training with loss torch.nn.BCELoss or 2 with \n",
    "            loss torch.nn.CrossEntropyLoss            \n",
    "            \n",
    "            \"\"\"\n",
    "        super(conv2DNet, self).__init__()\n",
    "        # Layer 1\n",
    "        l1_channels = 16  \n",
    "        self.conv1 = nn.Conv2d(1, l1_channels, (Nchannels, 1), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(l1_channels, False) # final size bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        l2_channels = 4\n",
    "        l2_temp_window = 32\n",
    "        l2_l1channel_overlap = 2\n",
    "        self.padding1 = nn.ZeroPad2d((l2_temp_window // 2, l2_temp_window // 2 - 1, l2_l1channel_overlap//2-1, l2_l1channel_overlap//2)) # left, right, top, bottom\n",
    "        self.conv2 = nn.Conv2d(1, l2_channels, (l2_l1channel_overlap, l2_temp_window))  # does not change size if combined with above padding\n",
    "        self.batchnorm2 = nn.BatchNorm2d(l2_channels, False)\n",
    "        self.pooling2 = nn.MaxPool2d((2, 4)) # final size bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        l3_channels = 4\n",
    "        l3_temp_window = 4\n",
    "        l3_l2channel_overlap = 8\n",
    "        self.padding2 = nn.ZeroPad2d((l3_temp_window//2, l3_temp_window//2-1, l3_l2channel_overlap//2, l3_l2channel_overlap//2-1))\n",
    "        self.conv3 = nn.Conv2d(l2_channels, l3_channels, (l3_l2channel_overlap, l3_temp_window))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(l3_channels, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4)) # final size bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # FC Layer\n",
    "        fc_inputs = l3_channels * (l1_channels//4) * (Nsamples//16)\n",
    "        self.fc1 = nn.Linear(fc_inputs, output_units)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies forward pass consisting of 3 convolutional layers followed by a fully-connected linear layer.\n",
    "        \n",
    "        Args:\n",
    "            - x (torch.autograd.Variable): the input batch. It has dimension batch_size x Nchannel x Nsamples x 1,\n",
    "            where Nchannel is the number of EEG channels and Nsamples the number of time points.\n",
    "        \n",
    "        Returns:\n",
    "            - (torch.autograd.Variable) of size either batch_size x output_units   \n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.permute(0, 3, 1, 2)             # bsize x 1 x Nchannels x Nsamples\n",
    "        \n",
    "        # Layer 1\n",
    "        x = F.relu(self.conv1(x))              # bsize x l1_channels x 1 x Nsamples\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = x.permute(0, 2, 1, 3)             # bsize x 1 x l1_channels x Nsamples\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.relu(self.conv2(x))              # bsize x l2_channels x l1_channels x Nsamples\n",
    "        x = self.batchnorm2(x)       \n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = self.pooling2(x)                  # bsize x l2_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.relu(self.conv3(x))              # bsize x l3_channels x floor(l1_channels/2) x floor(Nsamples/4)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = self.pooling3(x)                  # bsize x l3_channels x floor(l1_channels/4) x floor(Nsamples/16)\n",
    "\n",
    "        # Fully-connected Layer\n",
    "        x = x.view(-1, self.fc1.in_features)  # bsize x (l3_channels*floor(l1_channels/4)*floor(Nsamples/16))\n",
    "        x = F.sigmoid(self.fc1(x))            # bisze x self.fc1.out_features  \n",
    "        \n",
    "        if self.fc1.out_features == 1:\n",
    "            x = x.view(-1)                     # bsize (1D if 1 output unit)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target):\n",
    "    batch_size = 25  # not as crucial as in training. Just a matter of memory.\n",
    "    nb_errors = 0\n",
    "    Ndata = data_input.size(0)\n",
    "    model.eval()\n",
    "    \n",
    "    for b_start in range(0, data_input.size(0), batch_size):\n",
    "        bsize_eff = batch_size - max(0, b_start+batch_size-Ndata)  # boundary case\n",
    "        batch_output = model.forward(data_input.narrow(0, b_start, bsize_eff))  # is Variable if data_input is Variable\n",
    "        if len(list(batch_output.size()))>1 and batch_output.size(1) > 1:\n",
    "            # as many ouputs as there are classes => select maximum output\n",
    "            nb_err_batch = (batch_output.max(1)[1] != data_target.narrow(0, b_start, bsize_eff)).long().sum()\n",
    "            # overflow problem if conversion to Long Int not performed, treated as short 1-byte int otherwise!!\n",
    "        else:\n",
    "            # output is a scalar in [0, 1]\n",
    "            nb_err_batch = batch_output.round().sub(data_target.narrow(0, b_start, bsize_eff)).sign().abs().sum()\n",
    "        \n",
    "        nb_errors += nb_err_batch\n",
    "    if isinstance(nb_errors, Variable):\n",
    "        nb_errors = nb_errors.data[0]\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2701, 28, 50)\n",
      "test (100, 28, 50)\n",
      "validation (144, 28, 50)\n",
      "Ntrain 2701\n",
      "Ntest 100\n",
      "Nvalidation 144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utility import * \n",
    "\n",
    "preprocessed_input_train, preprocessed_input_validation, preprocessed_input_train_target, preprocessed_input_validation_target = preprocessing_train(train_input_1000, train_target_1000, False, False)\n",
    "preprocessed_input_test = preprocessing_test(test_input_100, False)\n",
    "\n",
    "#Remove Noise\n",
    "#preprocessed_input_train = denoisedSignals(preprocessed_input_train)\n",
    "#preprocessed_input_validation = denoisedSignals(preprocessed_input_validation)\n",
    "#preprocessed_input_test = denoisedSignals(preprocessed_input_test)\n",
    "#add random noise\n",
    "#preprocessed_input_train = whiteNoise(preprocessed_input_train)\n",
    "#preprocessed_input_validation = whiteNoise(preprocessed_input_validation)\n",
    "#preprocessed_input_test = whiteNoise(preprocessed_input_test)\n",
    "\n",
    "print('train', preprocessed_input_train.shape)\n",
    "print('test', preprocessed_input_test.shape)\n",
    "print('validation', preprocessed_input_validation.shape)\n",
    "\n",
    "labels_train = torch.from_numpy(preprocessed_input_train_target)\n",
    "labels_test = test_target_100\n",
    "labels_validation = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "preprocessed_input_train = torch.from_numpy(preprocessed_input_train).float()\n",
    "preprocessed_input_test = torch.from_numpy(preprocessed_input_test).float()\n",
    "preprocessed_input_validation = torch.from_numpy(preprocessed_input_validation).float()\n",
    "\n",
    "preprocessed_input_train_target = torch.from_numpy(preprocessed_input_train_target)\n",
    "preprocessed_input_validation_target = torch.from_numpy(preprocessed_input_validation_target)\n",
    "\n",
    "Ntrain = len(preprocessed_input_train[:,0,0])\n",
    "Ntest = len(preprocessed_input_test[:,0,0])\n",
    "Nvalidation = len(preprocessed_input_validation[:,0,0])\n",
    "\n",
    "print('Ntrain', Ntrain)\n",
    "print('Ntest', Ntest)\n",
    "print('Nvalidation', Nvalidation)\n",
    "\n",
    "train_input = Variable(preprocessed_input_train.view(Ntrain, Nchannels, Nsamples_100, 1))\n",
    "validation_input = Variable(preprocessed_input_validation.view(Nvalidation, Nchannels, Nsamples_100, 1), volatile=True )\n",
    "test_input = Variable(preprocessed_input_test.view(Ntest, Nchannels, Nsamples_100, 1), volatile=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training and testing\n",
    "Non-linearity: elu  \n",
    "\n",
    "\n",
    "|criterion | optimizer | lr  | momentum | batch size | Nepochs | Train acc. | Test acc.|\n",
    "|----------|-----------|-----|----------|------------|---------|------------|----------|\n",
    "| BCE  | Adam  |1e-1 | def. | 15 | 150 | 86.4 | 61.4 | \n",
    "| BCE  | Adam  |1e-1 | def. | 20 | 150 | 99.8 | 79.5 | \n",
    "| BCE  | SGD   | 1e-2 | 0.85 | 20 | 150 | 98.9  | 61.5 | \n",
    "| CE   | Adam  | 1e-2 | def. | 20 | 150 | 98.4  |  70.5 | \n",
    "| CE   | SGD   | 1e-2 | 0.85 | 20 | 150 | 99.1 | 75.1 |\n",
    "\n",
    "\n",
    "Non-linearity: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  0\n",
      "\t Training accuracy:  58.83006293965198\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  73.16120147705078\n",
      "Epoch Number :  1\n",
      "\t Training accuracy:  58.607922991484635\n",
      "\t Validation accuracy  60.416666666666664\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  72.38387298583984\n",
      "Epoch Number :  2\n",
      "\t Training accuracy:  58.718992965568304\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  72.36580657958984\n",
      "Epoch Number :  3\n",
      "\t Training accuracy:  58.79303961495742\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  72.35186004638672\n",
      "Epoch Number :  4\n",
      "\t Training accuracy:  58.83006293965198\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  72.33895111083984\n",
      "Epoch Number :  5\n",
      "\t Training accuracy:  58.9041095890411\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  72.32614135742188\n",
      "Epoch Number :  6\n",
      "\t Training accuracy:  58.9041095890411\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.3134536743164\n",
      "Epoch Number :  7\n",
      "\t Training accuracy:  58.97815623843021\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.2993392944336\n",
      "Epoch Number :  8\n",
      "\t Training accuracy:  59.05220288781933\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.28155517578125\n",
      "Epoch Number :  9\n",
      "\t Training accuracy:  59.01517956312477\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.26895904541016\n",
      "Epoch Number :  10\n",
      "\t Training accuracy:  59.01517956312477\n",
      "\t Validation accuracy  61.111111111111114\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.25639343261719\n",
      "Epoch Number :  11\n",
      "\t Training accuracy:  58.97815623843021\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.2441635131836\n",
      "Epoch Number :  12\n",
      "\t Training accuracy:  59.01517956312477\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.23194885253906\n",
      "Epoch Number :  13\n",
      "\t Training accuracy:  59.126249537208444\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.2197265625\n",
      "Epoch Number :  14\n",
      "\t Training accuracy:  59.200296186597555\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.20748901367188\n",
      "Epoch Number :  15\n",
      "\t Training accuracy:  59.200296186597555\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.19515228271484\n",
      "Epoch Number :  16\n",
      "\t Training accuracy:  59.34838948537579\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  47.0\n",
      "\t Epoch Loss  72.18235778808594\n",
      "Epoch Number :  17\n",
      "\t Training accuracy:  59.4224361347649\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  47.0\n",
      "\t Epoch Loss  72.16976928710938\n",
      "Epoch Number :  18\n",
      "\t Training accuracy:  59.4224361347649\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  47.0\n",
      "\t Epoch Loss  72.15721130371094\n",
      "Epoch Number :  19\n",
      "\t Training accuracy:  59.45945945945946\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.14472961425781\n",
      "Epoch Number :  20\n",
      "\t Training accuracy:  59.45945945945946\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.1322250366211\n",
      "Epoch Number :  21\n",
      "\t Training accuracy:  59.45945945945946\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.1193618774414\n",
      "Epoch Number :  22\n",
      "\t Training accuracy:  59.45945945945946\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.10623931884766\n",
      "Epoch Number :  23\n",
      "\t Training accuracy:  59.53350610884858\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.0932846069336\n",
      "Epoch Number :  24\n",
      "\t Training accuracy:  59.57052943354313\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.07960510253906\n",
      "Epoch Number :  25\n",
      "\t Training accuracy:  59.60755275823769\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.06572723388672\n",
      "Epoch Number :  26\n",
      "\t Training accuracy:  59.60755275823769\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  48.0\n",
      "\t Epoch Loss  72.05193328857422\n",
      "Epoch Number :  27\n",
      "\t Training accuracy:  59.64457608293225\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  72.03902435302734\n",
      "Epoch Number :  28\n",
      "\t Training accuracy:  59.681599407626805\n",
      "\t Validation accuracy  61.80555555555556\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  72.02609252929688\n",
      "Epoch Number :  29\n",
      "\t Training accuracy:  59.75564605701592\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  72.01265716552734\n",
      "Epoch Number :  30\n",
      "\t Training accuracy:  59.829692706405034\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.99954223632812\n",
      "Epoch Number :  31\n",
      "\t Training accuracy:  59.829692706405034\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.98595428466797\n",
      "Epoch Number :  32\n",
      "\t Training accuracy:  59.90373935579415\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.9721908569336\n",
      "Epoch Number :  33\n",
      "\t Training accuracy:  59.97778600518327\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.95829010009766\n",
      "Epoch Number :  34\n",
      "\t Training accuracy:  60.162902628656056\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.94442749023438\n",
      "Epoch Number :  35\n",
      "\t Training accuracy:  60.1258793039615\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.93070220947266\n",
      "Epoch Number :  36\n",
      "\t Training accuracy:  60.19992595335061\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  49.0\n",
      "\t Epoch Loss  71.91511535644531\n",
      "Epoch Number :  37\n",
      "\t Training accuracy:  60.273972602739725\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  71.90188598632812\n",
      "Epoch Number :  38\n",
      "\t Training accuracy:  60.34801925212884\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  50.0\n",
      "\t Epoch Loss  71.88922119140625\n",
      "Epoch Number :  39\n",
      "\t Training accuracy:  60.49611255090707\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.87611389160156\n",
      "Epoch Number :  40\n",
      "\t Training accuracy:  60.53313587560163\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.8629150390625\n",
      "Epoch Number :  41\n",
      "\t Training accuracy:  60.53313587560163\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.84994506835938\n",
      "Epoch Number :  42\n",
      "\t Training accuracy:  60.49611255090707\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.83702087402344\n",
      "Epoch Number :  43\n",
      "\t Training accuracy:  60.45908922621251\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.82421875\n",
      "Epoch Number :  44\n",
      "\t Training accuracy:  60.49611255090707\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.81143951416016\n",
      "Epoch Number :  45\n",
      "\t Training accuracy:  60.42206590151795\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.79830932617188\n",
      "Epoch Number :  46\n",
      "\t Training accuracy:  60.53313587560163\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.78397369384766\n",
      "Epoch Number :  47\n",
      "\t Training accuracy:  60.60718252499075\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.77114868164062\n",
      "Epoch Number :  48\n",
      "\t Training accuracy:  60.60718252499075\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.75843048095703\n",
      "Epoch Number :  49\n",
      "\t Training accuracy:  60.6442058496853\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.74585723876953\n",
      "Epoch Number :  50\n",
      "\t Training accuracy:  60.6442058496853\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.73310089111328\n",
      "Epoch Number :  51\n",
      "\t Training accuracy:  60.57015920029619\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.72016906738281\n",
      "Epoch Number :  52\n",
      "\t Training accuracy:  60.60718252499075\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.70732116699219\n",
      "Epoch Number :  53\n",
      "\t Training accuracy:  60.6442058496853\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.69471740722656\n",
      "Epoch Number :  54\n",
      "\t Training accuracy:  60.68122917437986\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.6819076538086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  55\n",
      "\t Training accuracy:  60.60718252499075\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.66910552978516\n",
      "Epoch Number :  56\n",
      "\t Training accuracy:  60.755275823768976\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.65619659423828\n",
      "Epoch Number :  57\n",
      "\t Training accuracy:  60.755275823768976\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.64313507080078\n",
      "Epoch Number :  58\n",
      "\t Training accuracy:  60.866345797852645\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.62989807128906\n",
      "Epoch Number :  59\n",
      "\t Training accuracy:  60.866345797852645\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.61681365966797\n",
      "Epoch Number :  60\n",
      "\t Training accuracy:  60.792299148463535\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.60384368896484\n",
      "Epoch Number :  61\n",
      "\t Training accuracy:  60.94039244724176\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.59086608886719\n",
      "Epoch Number :  62\n",
      "\t Training accuracy:  61.01443909663088\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  51.0\n",
      "\t Epoch Loss  71.57772827148438\n",
      "Epoch Number :  63\n",
      "\t Training accuracy:  60.97741577193632\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.56442260742188\n",
      "Epoch Number :  64\n",
      "\t Training accuracy:  61.08848574601999\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.55116271972656\n",
      "Epoch Number :  65\n",
      "\t Training accuracy:  61.08848574601999\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.53791046142578\n",
      "Epoch Number :  66\n",
      "\t Training accuracy:  61.27360236949278\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.5247573852539\n",
      "Epoch Number :  67\n",
      "\t Training accuracy:  61.458718992965565\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.51161193847656\n",
      "Epoch Number :  68\n",
      "\t Training accuracy:  61.458718992965565\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.49828338623047\n",
      "Epoch Number :  69\n",
      "\t Training accuracy:  61.458718992965565\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.48957061767578\n",
      "Epoch Number :  70\n",
      "\t Training accuracy:  61.64383561643836\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.47578430175781\n",
      "Epoch Number :  71\n",
      "\t Training accuracy:  61.75490559052203\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.46588134765625\n",
      "Epoch Number :  72\n",
      "\t Training accuracy:  61.79192891521659\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.4522933959961\n",
      "Epoch Number :  73\n",
      "\t Training accuracy:  61.79192891521659\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.43865966796875\n",
      "Epoch Number :  74\n",
      "\t Training accuracy:  61.828952239911146\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.42566680908203\n",
      "Epoch Number :  75\n",
      "\t Training accuracy:  61.828952239911146\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.41258239746094\n",
      "Epoch Number :  76\n",
      "\t Training accuracy:  61.90299888930026\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.39970397949219\n",
      "Epoch Number :  77\n",
      "\t Training accuracy:  61.977045538689374\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.38677215576172\n",
      "Epoch Number :  78\n",
      "\t Training accuracy:  61.977045538689374\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.37357330322266\n",
      "Epoch Number :  79\n",
      "\t Training accuracy:  62.01406886338393\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.36024475097656\n",
      "Epoch Number :  80\n",
      "\t Training accuracy:  61.977045538689374\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.34675598144531\n",
      "Epoch Number :  81\n",
      "\t Training accuracy:  62.01406886338393\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.33306884765625\n",
      "Epoch Number :  82\n",
      "\t Training accuracy:  62.01406886338393\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.3193359375\n",
      "Epoch Number :  83\n",
      "\t Training accuracy:  62.088115512773044\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.3048095703125\n",
      "Epoch Number :  84\n",
      "\t Training accuracy:  62.088115512773044\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.2911148071289\n",
      "Epoch Number :  85\n",
      "\t Training accuracy:  62.16216216216216\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.27732849121094\n",
      "Epoch Number :  86\n",
      "\t Training accuracy:  62.16216216216216\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.2632827758789\n",
      "Epoch Number :  87\n",
      "\t Training accuracy:  62.23620881155128\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.24931335449219\n",
      "Epoch Number :  88\n",
      "\t Training accuracy:  62.19918548685672\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.23494720458984\n",
      "Epoch Number :  89\n",
      "\t Training accuracy:  62.34727878563495\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.22021484375\n",
      "Epoch Number :  90\n",
      "\t Training accuracy:  62.421325435024066\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.20532989501953\n",
      "Epoch Number :  91\n",
      "\t Training accuracy:  62.458348759718625\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.19026184082031\n",
      "Epoch Number :  92\n",
      "\t Training accuracy:  62.458348759718625\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.17677307128906\n",
      "Epoch Number :  93\n",
      "\t Training accuracy:  62.532395409107735\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.16127014160156\n",
      "Epoch Number :  94\n",
      "\t Training accuracy:  62.569418733802294\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.14622497558594\n",
      "Epoch Number :  95\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.13123321533203\n",
      "Epoch Number :  96\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.11569213867188\n",
      "Epoch Number :  97\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.10002136230469\n",
      "Epoch Number :  98\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.08435821533203\n",
      "Epoch Number :  99\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.06903076171875\n",
      "Epoch Number :  100\n",
      "\t Training accuracy:  62.8285820066642\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.05282592773438\n",
      "Epoch Number :  101\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  71.03691101074219\n",
      "Epoch Number :  102\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.0205307006836\n",
      "Epoch Number :  103\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  52.0\n",
      "\t Epoch Loss  71.0012435913086\n",
      "Epoch Number :  104\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.9824447631836\n",
      "Epoch Number :  105\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.96369171142578\n",
      "Epoch Number :  106\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.93045043945312\n",
      "Epoch Number :  107\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.91255950927734\n",
      "Epoch Number :  108\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.89483642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  109\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.8772201538086\n",
      "Epoch Number :  110\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.85963439941406\n",
      "Epoch Number :  111\n",
      "\t Training accuracy:  63.087745279526104\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.84207153320312\n",
      "Epoch Number :  112\n",
      "\t Training accuracy:  63.12476860422066\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.82391357421875\n",
      "Epoch Number :  113\n",
      "\t Training accuracy:  63.12476860422066\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.80592346191406\n",
      "Epoch Number :  114\n",
      "\t Training accuracy:  63.087745279526104\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  53.0\n",
      "\t Epoch Loss  70.78800201416016\n",
      "Epoch Number :  115\n",
      "\t Training accuracy:  63.050721954831545\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.77029418945312\n",
      "Epoch Number :  116\n",
      "\t Training accuracy:  63.013698630136986\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.75269317626953\n",
      "Epoch Number :  117\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.71436309814453\n",
      "Epoch Number :  118\n",
      "\t Training accuracy:  63.013698630136986\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.6977310180664\n",
      "Epoch Number :  119\n",
      "\t Training accuracy:  63.087745279526104\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.68072509765625\n",
      "Epoch Number :  120\n",
      "\t Training accuracy:  63.050721954831545\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.66234588623047\n",
      "Epoch Number :  121\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.6234359741211\n",
      "Epoch Number :  122\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.60447692871094\n",
      "Epoch Number :  123\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.58501434326172\n",
      "Epoch Number :  124\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  70.56583404541016\n",
      "Epoch Number :  125\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.54629516601562\n",
      "Epoch Number :  126\n",
      "\t Training accuracy:  62.93965198074787\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.50284576416016\n",
      "Epoch Number :  127\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.48258209228516\n",
      "Epoch Number :  128\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.4595718383789\n",
      "Epoch Number :  129\n",
      "\t Training accuracy:  62.8285820066642\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.43760681152344\n",
      "Epoch Number :  130\n",
      "\t Training accuracy:  62.75453535727508\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.413330078125\n",
      "Epoch Number :  131\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.38902282714844\n",
      "Epoch Number :  132\n",
      "\t Training accuracy:  62.64346538319141\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.36282348632812\n",
      "Epoch Number :  133\n",
      "\t Training accuracy:  62.60644205849685\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.33731079101562\n",
      "Epoch Number :  134\n",
      "\t Training accuracy:  62.60644205849685\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.30877685546875\n",
      "Epoch Number :  135\n",
      "\t Training accuracy:  62.532395409107735\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.27890014648438\n",
      "Epoch Number :  136\n",
      "\t Training accuracy:  62.569418733802294\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.26197814941406\n",
      "Epoch Number :  137\n",
      "\t Training accuracy:  62.60644205849685\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.23448181152344\n",
      "Epoch Number :  138\n",
      "\t Training accuracy:  62.569418733802294\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.20563507080078\n",
      "Epoch Number :  139\n",
      "\t Training accuracy:  62.532395409107735\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.17581939697266\n",
      "Epoch Number :  140\n",
      "\t Training accuracy:  62.458348759718625\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.14494323730469\n",
      "Epoch Number :  141\n",
      "\t Training accuracy:  62.458348759718625\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.11454772949219\n",
      "Epoch Number :  142\n",
      "\t Training accuracy:  62.421325435024066\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.08295440673828\n",
      "Epoch Number :  143\n",
      "\t Training accuracy:  62.421325435024066\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.0545883178711\n",
      "Epoch Number :  144\n",
      "\t Training accuracy:  62.458348759718625\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  70.0275650024414\n",
      "Epoch Number :  145\n",
      "\t Training accuracy:  62.569418733802294\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  70.00150299072266\n",
      "Epoch Number :  146\n",
      "\t Training accuracy:  62.532395409107735\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  69.97589111328125\n",
      "Epoch Number :  147\n",
      "\t Training accuracy:  62.532395409107735\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  69.95030975341797\n",
      "Epoch Number :  148\n",
      "\t Training accuracy:  62.569418733802294\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  69.9248046875\n",
      "Epoch Number :  149\n",
      "\t Training accuracy:  62.495372084413184\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  69.9001235961914\n",
      "Epoch Number :  150\n",
      "\t Training accuracy:  62.60644205849685\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  69.87548828125\n",
      "Epoch Number :  151\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.86129760742188\n",
      "Epoch Number :  152\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.8366470336914\n",
      "Epoch Number :  153\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.81206512451172\n",
      "Epoch Number :  154\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.78727722167969\n",
      "Epoch Number :  155\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.76258087158203\n",
      "Epoch Number :  156\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.73786163330078\n",
      "Epoch Number :  157\n",
      "\t Training accuracy:  62.68048870788597\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.71385192871094\n",
      "Epoch Number :  158\n",
      "\t Training accuracy:  62.60644205849685\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.69058227539062\n",
      "Epoch Number :  159\n",
      "\t Training accuracy:  62.64346538319141\n",
      "\t Validation accuracy  62.5\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.66727447509766\n",
      "Epoch Number :  160\n",
      "\t Training accuracy:  62.71751203258052\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.64452362060547\n",
      "Epoch Number :  161\n",
      "\t Training accuracy:  62.79155868196964\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.62275695800781\n",
      "Epoch Number :  162\n",
      "\t Training accuracy:  62.86560533135876\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.60105895996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  163\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.5793685913086\n",
      "Epoch Number :  164\n",
      "\t Training accuracy:  62.90262865605332\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.55809783935547\n",
      "Epoch Number :  165\n",
      "\t Training accuracy:  62.97667530544243\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.53594207763672\n",
      "Epoch Number :  166\n",
      "\t Training accuracy:  63.087745279526104\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.51118469238281\n",
      "Epoch Number :  167\n",
      "\t Training accuracy:  63.12476860422066\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.47699737548828\n",
      "Epoch Number :  168\n",
      "\t Training accuracy:  63.19881525360977\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.42431640625\n",
      "Epoch Number :  169\n",
      "\t Training accuracy:  63.27286190299889\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.36131286621094\n",
      "Epoch Number :  170\n",
      "\t Training accuracy:  63.346908552388\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.32557678222656\n",
      "Epoch Number :  171\n",
      "\t Training accuracy:  63.346908552388\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.30168151855469\n",
      "Epoch Number :  172\n",
      "\t Training accuracy:  63.38393187708256\n",
      "\t Validation accuracy  63.19444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.28084564208984\n",
      "Epoch Number :  173\n",
      "\t Training accuracy:  63.42095520177712\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.26050567626953\n",
      "Epoch Number :  174\n",
      "\t Training accuracy:  63.495001851166236\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.24052429199219\n",
      "Epoch Number :  175\n",
      "\t Training accuracy:  63.532025175860795\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  69.22086334228516\n",
      "Epoch Number :  176\n",
      "\t Training accuracy:  63.56904850055535\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.2007827758789\n",
      "Epoch Number :  177\n",
      "\t Training accuracy:  63.532025175860795\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.18073272705078\n",
      "Epoch Number :  178\n",
      "\t Training accuracy:  63.56904850055535\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.16101837158203\n",
      "Epoch Number :  179\n",
      "\t Training accuracy:  63.71714179933358\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.14093017578125\n",
      "Epoch Number :  180\n",
      "\t Training accuracy:  63.71714179933358\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.1209487915039\n",
      "Epoch Number :  181\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.10083770751953\n",
      "Epoch Number :  182\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.08090209960938\n",
      "Epoch Number :  183\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.06078338623047\n",
      "Epoch Number :  184\n",
      "\t Training accuracy:  63.86523509811181\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.04061889648438\n",
      "Epoch Number :  185\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  69.02025604248047\n",
      "Epoch Number :  186\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  68.99933624267578\n",
      "Epoch Number :  187\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  68.97872924804688\n",
      "Epoch Number :  188\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  68.95841217041016\n",
      "Epoch Number :  189\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  68.93817901611328\n",
      "Epoch Number :  190\n",
      "\t Training accuracy:  63.75416512402814\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  68.91791534423828\n",
      "Epoch Number :  191\n",
      "\t Training accuracy:  63.75416512402814\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  68.89738464355469\n",
      "Epoch Number :  192\n",
      "\t Training accuracy:  63.68011847463902\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.87703704833984\n",
      "Epoch Number :  193\n",
      "\t Training accuracy:  63.68011847463902\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.85657501220703\n",
      "Epoch Number :  194\n",
      "\t Training accuracy:  63.75416512402814\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.83626556396484\n",
      "Epoch Number :  195\n",
      "\t Training accuracy:  63.75416512402814\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.81562805175781\n",
      "Epoch Number :  196\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.79510498046875\n",
      "Epoch Number :  197\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.77438354492188\n",
      "Epoch Number :  198\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.75341796875\n",
      "Epoch Number :  199\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.73213195800781\n",
      "Epoch Number :  200\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.7109146118164\n",
      "Epoch Number :  201\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.68978881835938\n",
      "Epoch Number :  202\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.66871643066406\n",
      "Epoch Number :  203\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.64750671386719\n",
      "Epoch Number :  204\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.62616729736328\n",
      "Epoch Number :  205\n",
      "\t Training accuracy:  63.86523509811181\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.60490417480469\n",
      "Epoch Number :  206\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.5839614868164\n",
      "Epoch Number :  207\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.56288146972656\n",
      "Epoch Number :  208\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.54129028320312\n",
      "Epoch Number :  209\n",
      "\t Training accuracy:  63.79118844872269\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.52037048339844\n",
      "Epoch Number :  210\n",
      "\t Training accuracy:  63.86523509811181\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  68.49938201904297\n",
      "Epoch Number :  211\n",
      "\t Training accuracy:  63.86523509811181\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.47810363769531\n",
      "Epoch Number :  212\n",
      "\t Training accuracy:  63.86523509811181\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.45691680908203\n",
      "Epoch Number :  213\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.4354019165039\n",
      "Epoch Number :  214\n",
      "\t Training accuracy:  63.82821177341725\n",
      "\t Validation accuracy  63.888888888888886\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  68.41389465332031\n",
      "Epoch Number :  215\n",
      "\t Training accuracy:  63.90225842280637\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.39228820800781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  216\n",
      "\t Training accuracy:  63.90225842280637\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.36994934082031\n",
      "Epoch Number :  217\n",
      "\t Training accuracy:  63.90225842280637\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.34732055664062\n",
      "Epoch Number :  218\n",
      "\t Training accuracy:  63.97630507219548\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.32415771484375\n",
      "Epoch Number :  219\n",
      "\t Training accuracy:  63.93928174750093\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.30140686035156\n",
      "Epoch Number :  220\n",
      "\t Training accuracy:  63.97630507219548\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.27874755859375\n",
      "Epoch Number :  221\n",
      "\t Training accuracy:  63.97630507219548\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.25650024414062\n",
      "Epoch Number :  222\n",
      "\t Training accuracy:  63.93928174750093\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.23369598388672\n",
      "Epoch Number :  223\n",
      "\t Training accuracy:  63.97630507219548\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.2101821899414\n",
      "Epoch Number :  224\n",
      "\t Training accuracy:  64.0503517215846\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.18546295166016\n",
      "Epoch Number :  225\n",
      "\t Training accuracy:  64.12439837097371\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.15953826904297\n",
      "Epoch Number :  226\n",
      "\t Training accuracy:  64.12439837097371\n",
      "\t Validation accuracy  64.58333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.1356430053711\n",
      "Epoch Number :  227\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  65.27777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.1124038696289\n",
      "Epoch Number :  228\n",
      "\t Training accuracy:  64.23546834505738\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.09005737304688\n",
      "Epoch Number :  229\n",
      "\t Training accuracy:  64.23546834505738\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.0692138671875\n",
      "Epoch Number :  230\n",
      "\t Training accuracy:  64.27249166975194\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.04761505126953\n",
      "Epoch Number :  231\n",
      "\t Training accuracy:  64.3095149944465\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.02584838867188\n",
      "Epoch Number :  232\n",
      "\t Training accuracy:  64.3095149944465\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  68.00391387939453\n",
      "Epoch Number :  233\n",
      "\t Training accuracy:  64.23546834505738\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  67.98235321044922\n",
      "Epoch Number :  234\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  67.96070861816406\n",
      "Epoch Number :  235\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  67.93902587890625\n",
      "Epoch Number :  236\n",
      "\t Training accuracy:  64.12439837097371\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  67.9174575805664\n",
      "Epoch Number :  237\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  67.8954086303711\n",
      "Epoch Number :  238\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  67.87336730957031\n",
      "Epoch Number :  239\n",
      "\t Training accuracy:  64.16142169566827\n",
      "\t Validation accuracy  67.36111111111111\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.85102844238281\n",
      "Epoch Number :  240\n",
      "\t Training accuracy:  64.23546834505738\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.828857421875\n",
      "Epoch Number :  241\n",
      "\t Training accuracy:  64.27249166975194\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.8066635131836\n",
      "Epoch Number :  242\n",
      "\t Training accuracy:  64.3095149944465\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.7852783203125\n",
      "Epoch Number :  243\n",
      "\t Training accuracy:  64.38356164383562\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.76396179199219\n",
      "Epoch Number :  244\n",
      "\t Training accuracy:  64.45760829322474\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.74246978759766\n",
      "Epoch Number :  245\n",
      "\t Training accuracy:  64.53165494261384\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.72113800048828\n",
      "Epoch Number :  246\n",
      "\t Training accuracy:  64.60570159200296\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.69998931884766\n",
      "Epoch Number :  247\n",
      "\t Training accuracy:  64.60570159200296\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.67864990234375\n",
      "Epoch Number :  248\n",
      "\t Training accuracy:  64.64272491669752\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.65740966796875\n",
      "Epoch Number :  249\n",
      "\t Training accuracy:  64.71677156608663\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.63615417480469\n",
      "Epoch Number :  250\n",
      "\t Training accuracy:  64.71677156608663\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.6147232055664\n",
      "Epoch Number :  251\n",
      "\t Training accuracy:  64.64272491669752\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.59345245361328\n",
      "Epoch Number :  252\n",
      "\t Training accuracy:  64.64272491669752\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.57254028320312\n",
      "Epoch Number :  253\n",
      "\t Training accuracy:  64.67974824139208\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.55135345458984\n",
      "Epoch Number :  254\n",
      "\t Training accuracy:  64.7537948907812\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.52989959716797\n",
      "Epoch Number :  255\n",
      "\t Training accuracy:  64.7537948907812\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.50810241699219\n",
      "Epoch Number :  256\n",
      "\t Training accuracy:  64.7537948907812\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.48603057861328\n",
      "Epoch Number :  257\n",
      "\t Training accuracy:  64.82784154017031\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.46387481689453\n",
      "Epoch Number :  258\n",
      "\t Training accuracy:  64.86486486486487\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.44111633300781\n",
      "Epoch Number :  259\n",
      "\t Training accuracy:  64.86486486486487\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.41825103759766\n",
      "Epoch Number :  260\n",
      "\t Training accuracy:  64.97593483894853\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.39540100097656\n",
      "Epoch Number :  261\n",
      "\t Training accuracy:  65.01295816364309\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.37272644042969\n",
      "Epoch Number :  262\n",
      "\t Training accuracy:  65.08700481303221\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.35030364990234\n",
      "Epoch Number :  263\n",
      "\t Training accuracy:  65.08700481303221\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.32792663574219\n",
      "Epoch Number :  264\n",
      "\t Training accuracy:  65.08700481303221\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.30560302734375\n",
      "Epoch Number :  265\n",
      "\t Training accuracy:  65.16105146242133\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.28316497802734\n",
      "Epoch Number :  266\n",
      "\t Training accuracy:  65.19807478711589\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.26041412353516\n",
      "Epoch Number :  267\n",
      "\t Training accuracy:  65.19807478711589\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.23805236816406\n",
      "Epoch Number :  268\n",
      "\t Training accuracy:  65.23509811181044\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.21542358398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  269\n",
      "\t Training accuracy:  65.272121436505\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.19215393066406\n",
      "Epoch Number :  270\n",
      "\t Training accuracy:  65.19807478711589\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.16923522949219\n",
      "Epoch Number :  271\n",
      "\t Training accuracy:  65.23509811181044\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.14579772949219\n",
      "Epoch Number :  272\n",
      "\t Training accuracy:  65.23509811181044\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.12216186523438\n",
      "Epoch Number :  273\n",
      "\t Training accuracy:  65.30914476119956\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.09893035888672\n",
      "Epoch Number :  274\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.07564544677734\n",
      "Epoch Number :  275\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.05229949951172\n",
      "Epoch Number :  276\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.02873992919922\n",
      "Epoch Number :  277\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  67.00556182861328\n",
      "Epoch Number :  278\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.98223876953125\n",
      "Epoch Number :  279\n",
      "\t Training accuracy:  65.42021473528322\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.95880889892578\n",
      "Epoch Number :  280\n",
      "\t Training accuracy:  65.42021473528322\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.93447875976562\n",
      "Epoch Number :  281\n",
      "\t Training accuracy:  65.42021473528322\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.91058349609375\n",
      "Epoch Number :  282\n",
      "\t Training accuracy:  65.42021473528322\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.88658142089844\n",
      "Epoch Number :  283\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.86227416992188\n",
      "Epoch Number :  284\n",
      "\t Training accuracy:  65.38319141058867\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.8377914428711\n",
      "Epoch Number :  285\n",
      "\t Training accuracy:  65.42021473528322\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.81328582763672\n",
      "Epoch Number :  286\n",
      "\t Training accuracy:  65.45723805997778\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.78941345214844\n",
      "Epoch Number :  287\n",
      "\t Training accuracy:  65.49426138467234\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.7658920288086\n",
      "Epoch Number :  288\n",
      "\t Training accuracy:  65.60533135875602\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.74263000488281\n",
      "Epoch Number :  289\n",
      "\t Training accuracy:  65.64235468345058\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.7200698852539\n",
      "Epoch Number :  290\n",
      "\t Training accuracy:  65.64235468345058\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.69781494140625\n",
      "Epoch Number :  291\n",
      "\t Training accuracy:  65.60533135875602\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.67561340332031\n",
      "Epoch Number :  292\n",
      "\t Training accuracy:  65.67937800814514\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.65339660644531\n",
      "Epoch Number :  293\n",
      "\t Training accuracy:  65.64235468345058\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.63172912597656\n",
      "Epoch Number :  294\n",
      "\t Training accuracy:  65.67937800814514\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.61003875732422\n",
      "Epoch Number :  295\n",
      "\t Training accuracy:  65.67937800814514\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.58735656738281\n",
      "Epoch Number :  296\n",
      "\t Training accuracy:  65.67937800814514\n",
      "\t Validation accuracy  68.05555555555556\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.56417846679688\n",
      "Epoch Number :  297\n",
      "\t Training accuracy:  65.7904479822288\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.54148864746094\n",
      "Epoch Number :  298\n",
      "\t Training accuracy:  65.75342465753425\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.51937103271484\n",
      "Epoch Number :  299\n",
      "\t Training accuracy:  65.75342465753425\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  66.4970474243164\n",
      "Epoch Number :  300\n",
      "\t Training accuracy:  65.7904479822288\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.47480773925781\n",
      "Epoch Number :  301\n",
      "\t Training accuracy:  65.75342465753425\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.45279693603516\n",
      "Epoch Number :  302\n",
      "\t Training accuracy:  65.75342465753425\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.43083953857422\n",
      "Epoch Number :  303\n",
      "\t Training accuracy:  65.86449463161792\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.40868377685547\n",
      "Epoch Number :  304\n",
      "\t Training accuracy:  65.86449463161792\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.38702392578125\n",
      "Epoch Number :  305\n",
      "\t Training accuracy:  65.90151795631247\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.36505126953125\n",
      "Epoch Number :  306\n",
      "\t Training accuracy:  65.93854128100703\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.3428955078125\n",
      "Epoch Number :  307\n",
      "\t Training accuracy:  65.97556460570159\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.32018280029297\n",
      "Epoch Number :  308\n",
      "\t Training accuracy:  65.97556460570159\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.29755401611328\n",
      "Epoch Number :  309\n",
      "\t Training accuracy:  66.01258793039615\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.27472686767578\n",
      "Epoch Number :  310\n",
      "\t Training accuracy:  66.08663457978527\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.25138092041016\n",
      "Epoch Number :  311\n",
      "\t Training accuracy:  66.12365790447983\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.22764587402344\n",
      "Epoch Number :  312\n",
      "\t Training accuracy:  66.23472787856349\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.20321655273438\n",
      "Epoch Number :  313\n",
      "\t Training accuracy:  66.27175120325805\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.17972564697266\n",
      "Epoch Number :  314\n",
      "\t Training accuracy:  66.34579785264717\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.1567611694336\n",
      "Epoch Number :  315\n",
      "\t Training accuracy:  66.34579785264717\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.13362884521484\n",
      "Epoch Number :  316\n",
      "\t Training accuracy:  66.34579785264717\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.11028289794922\n",
      "Epoch Number :  317\n",
      "\t Training accuracy:  66.38282117734173\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.087158203125\n",
      "Epoch Number :  318\n",
      "\t Training accuracy:  66.41984450203628\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.06393432617188\n",
      "Epoch Number :  319\n",
      "\t Training accuracy:  66.53091447611996\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.04047393798828\n",
      "Epoch Number :  320\n",
      "\t Training accuracy:  66.56793780081452\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  66.01677703857422\n",
      "Epoch Number :  321\n",
      "\t Training accuracy:  66.60496112550906\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.99332427978516\n",
      "Epoch Number :  322\n",
      "\t Training accuracy:  66.60496112550906\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.97038269042969\n",
      "Epoch Number :  323\n",
      "\t Training accuracy:  66.64198445020362\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.94731140136719\n",
      "Epoch Number :  324\n",
      "\t Training accuracy:  66.7530544242873\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.92475891113281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  325\n",
      "\t Training accuracy:  66.79007774898186\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.90216827392578\n",
      "Epoch Number :  326\n",
      "\t Training accuracy:  66.82710107367642\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.87828826904297\n",
      "Epoch Number :  327\n",
      "\t Training accuracy:  66.90114772306553\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.85429382324219\n",
      "Epoch Number :  328\n",
      "\t Training accuracy:  66.9381710477601\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.82968139648438\n",
      "Epoch Number :  329\n",
      "\t Training accuracy:  66.9381710477601\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.80561828613281\n",
      "Epoch Number :  330\n",
      "\t Training accuracy:  66.97519437245465\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.78178405761719\n",
      "Epoch Number :  331\n",
      "\t Training accuracy:  67.04924102184376\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.75812530517578\n",
      "Epoch Number :  332\n",
      "\t Training accuracy:  67.12328767123287\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.73552703857422\n",
      "Epoch Number :  333\n",
      "\t Training accuracy:  67.04924102184376\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.71287536621094\n",
      "Epoch Number :  334\n",
      "\t Training accuracy:  67.04924102184376\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.68900299072266\n",
      "Epoch Number :  335\n",
      "\t Training accuracy:  67.04924102184376\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.66506958007812\n",
      "Epoch Number :  336\n",
      "\t Training accuracy:  67.12328767123287\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.6424560546875\n",
      "Epoch Number :  337\n",
      "\t Training accuracy:  67.08626434653831\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  65.61933135986328\n",
      "Epoch Number :  338\n",
      "\t Training accuracy:  67.08626434653831\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.59590911865234\n",
      "Epoch Number :  339\n",
      "\t Training accuracy:  67.08626434653831\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.5723876953125\n",
      "Epoch Number :  340\n",
      "\t Training accuracy:  67.08626434653831\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.54825592041016\n",
      "Epoch Number :  341\n",
      "\t Training accuracy:  67.08626434653831\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.52371215820312\n",
      "Epoch Number :  342\n",
      "\t Training accuracy:  67.12328767123287\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.4998779296875\n",
      "Epoch Number :  343\n",
      "\t Training accuracy:  67.12328767123287\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.47611236572266\n",
      "Epoch Number :  344\n",
      "\t Training accuracy:  67.19733432062199\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.45263671875\n",
      "Epoch Number :  345\n",
      "\t Training accuracy:  67.19733432062199\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.42955780029297\n",
      "Epoch Number :  346\n",
      "\t Training accuracy:  67.23435764531655\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.40668487548828\n",
      "Epoch Number :  347\n",
      "\t Training accuracy:  67.27138097001111\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.38361358642578\n",
      "Epoch Number :  348\n",
      "\t Training accuracy:  67.30840429470567\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  65.36051177978516\n",
      "Epoch Number :  349\n",
      "\t Training accuracy:  67.30840429470567\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  65.33721160888672\n",
      "Epoch Number :  350\n",
      "\t Training accuracy:  67.34542761940023\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  54.0\n",
      "\t Epoch Loss  65.31353759765625\n",
      "Epoch Number :  351\n",
      "\t Training accuracy:  67.38245094409478\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.28974914550781\n",
      "Epoch Number :  352\n",
      "\t Training accuracy:  67.41947426878934\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.26600646972656\n",
      "Epoch Number :  353\n",
      "\t Training accuracy:  67.41947426878934\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.24200439453125\n",
      "Epoch Number :  354\n",
      "\t Training accuracy:  67.45649759348389\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.21778106689453\n",
      "Epoch Number :  355\n",
      "\t Training accuracy:  67.49352091817845\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.19369506835938\n",
      "Epoch Number :  356\n",
      "\t Training accuracy:  67.49352091817845\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.16925048828125\n",
      "Epoch Number :  357\n",
      "\t Training accuracy:  67.49352091817845\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.14456176757812\n",
      "Epoch Number :  358\n",
      "\t Training accuracy:  67.41947426878934\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.11942291259766\n",
      "Epoch Number :  359\n",
      "\t Training accuracy:  67.45649759348389\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.09423065185547\n",
      "Epoch Number :  360\n",
      "\t Training accuracy:  67.49352091817845\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.07003021240234\n",
      "Epoch Number :  361\n",
      "\t Training accuracy:  67.49352091817845\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  55.0\n",
      "\t Epoch Loss  65.0447006225586\n",
      "Epoch Number :  362\n",
      "\t Training accuracy:  67.45649759348389\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  65.0196304321289\n",
      "Epoch Number :  363\n",
      "\t Training accuracy:  67.41947426878934\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.99343872070312\n",
      "Epoch Number :  364\n",
      "\t Training accuracy:  67.45649759348389\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.96715545654297\n",
      "Epoch Number :  365\n",
      "\t Training accuracy:  67.530544242873\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.94184875488281\n",
      "Epoch Number :  366\n",
      "\t Training accuracy:  67.530544242873\n",
      "\t Validation accuracy  69.44444444444444\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.91626739501953\n",
      "Epoch Number :  367\n",
      "\t Training accuracy:  67.530544242873\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.89106750488281\n",
      "Epoch Number :  368\n",
      "\t Training accuracy:  67.56756756756756\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.87310791015625\n",
      "Epoch Number :  369\n",
      "\t Training accuracy:  67.56756756756756\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.84809875488281\n",
      "Epoch Number :  370\n",
      "\t Training accuracy:  67.60459089226212\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.8232192993164\n",
      "Epoch Number :  371\n",
      "\t Training accuracy:  67.64161421695668\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.79847717285156\n",
      "Epoch Number :  372\n",
      "\t Training accuracy:  67.7156608663458\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.77769470214844\n",
      "Epoch Number :  373\n",
      "\t Training accuracy:  67.75268419104036\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.75296020507812\n",
      "Epoch Number :  374\n",
      "\t Training accuracy:  67.82673084042948\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.72716522216797\n",
      "Epoch Number :  375\n",
      "\t Training accuracy:  67.93780081451314\n",
      "\t Validation accuracy  68.75\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.69804382324219\n",
      "Epoch Number :  376\n",
      "\t Training accuracy:  67.9748241392077\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.65380859375\n",
      "Epoch Number :  377\n",
      "\t Training accuracy:  68.27101073676417\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.56781005859375\n",
      "Epoch Number :  378\n",
      "\t Training accuracy:  68.38208071084783\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.50714874267578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  379\n",
      "\t Training accuracy:  68.41910403554239\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.46903991699219\n",
      "Epoch Number :  380\n",
      "\t Training accuracy:  68.45612736023695\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.43325805664062\n",
      "Epoch Number :  381\n",
      "\t Training accuracy:  68.34505738615327\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.39602661132812\n",
      "Epoch Number :  382\n",
      "\t Training accuracy:  68.53017400962607\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.34068298339844\n",
      "Epoch Number :  383\n",
      "\t Training accuracy:  68.64124398370974\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.2857437133789\n",
      "Epoch Number :  384\n",
      "\t Training accuracy:  68.64124398370974\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  64.24951171875\n",
      "Epoch Number :  385\n",
      "\t Training accuracy:  68.64124398370974\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.21470642089844\n",
      "Epoch Number :  386\n",
      "\t Training accuracy:  68.64124398370974\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.17951965332031\n",
      "Epoch Number :  387\n",
      "\t Training accuracy:  68.7523139577934\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.14391326904297\n",
      "Epoch Number :  388\n",
      "\t Training accuracy:  68.7523139577934\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.10855102539062\n",
      "Epoch Number :  389\n",
      "\t Training accuracy:  68.71529063309885\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.0732421875\n",
      "Epoch Number :  390\n",
      "\t Training accuracy:  68.71529063309885\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  64.03907012939453\n",
      "Epoch Number :  391\n",
      "\t Training accuracy:  68.78933728248796\n",
      "\t Validation accuracy  70.13888888888889\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  64.00575256347656\n",
      "Epoch Number :  392\n",
      "\t Training accuracy:  68.90040725657164\n",
      "\t Validation accuracy  70.83333333333333\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.97297286987305\n",
      "Epoch Number :  393\n",
      "\t Training accuracy:  68.9374305812662\n",
      "\t Validation accuracy  70.83333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.93986511230469\n",
      "Epoch Number :  394\n",
      "\t Training accuracy:  68.90040725657164\n",
      "\t Validation accuracy  70.83333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.907012939453125\n",
      "Epoch Number :  395\n",
      "\t Training accuracy:  68.97445390596076\n",
      "\t Validation accuracy  71.52777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.87043380737305\n",
      "Epoch Number :  396\n",
      "\t Training accuracy:  69.08552388004443\n",
      "\t Validation accuracy  71.52777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.834720611572266\n",
      "Epoch Number :  397\n",
      "\t Training accuracy:  69.12254720473898\n",
      "\t Validation accuracy  71.52777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.80229187011719\n",
      "Epoch Number :  398\n",
      "\t Training accuracy:  69.08552388004443\n",
      "\t Validation accuracy  71.52777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.77055358886719\n",
      "Epoch Number :  399\n",
      "\t Training accuracy:  69.15957052943354\n",
      "\t Validation accuracy  71.52777777777777\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.73896789550781\n",
      "Epoch Number :  400\n",
      "\t Training accuracy:  69.23361717882266\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.70726776123047\n",
      "Epoch Number :  401\n",
      "\t Training accuracy:  69.27064050351721\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.67631149291992\n",
      "Epoch Number :  402\n",
      "\t Training accuracy:  69.30766382821177\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.64474105834961\n",
      "Epoch Number :  403\n",
      "\t Training accuracy:  69.34468715290633\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.61526870727539\n",
      "Epoch Number :  404\n",
      "\t Training accuracy:  69.49278045168457\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.589195251464844\n",
      "Epoch Number :  405\n",
      "\t Training accuracy:  69.52980377637913\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.55748748779297\n",
      "Epoch Number :  406\n",
      "\t Training accuracy:  69.52980377637913\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  63.525054931640625\n",
      "Epoch Number :  407\n",
      "\t Training accuracy:  69.60385042576823\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.492469787597656\n",
      "Epoch Number :  408\n",
      "\t Training accuracy:  69.67789707515735\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.457820892333984\n",
      "Epoch Number :  409\n",
      "\t Training accuracy:  69.78896704924102\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.424896240234375\n",
      "Epoch Number :  410\n",
      "\t Training accuracy:  69.78896704924102\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.36476135253906\n",
      "Epoch Number :  411\n",
      "\t Training accuracy:  69.86301369863014\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  63.326873779296875\n",
      "Epoch Number :  412\n",
      "\t Training accuracy:  70.19622362088116\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  63.277828216552734\n",
      "Epoch Number :  413\n",
      "\t Training accuracy:  70.45538689374305\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  63.19522476196289\n",
      "Epoch Number :  414\n",
      "\t Training accuracy:  70.52943354313217\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.136470794677734\n",
      "Epoch Number :  415\n",
      "\t Training accuracy:  70.49241021843761\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  63.094268798828125\n",
      "Epoch Number :  416\n",
      "\t Training accuracy:  70.49241021843761\n",
      "\t Validation accuracy  72.91666666666667\n",
      "\t Test accuracy  56.0\n",
      "\t Epoch Loss  63.04096603393555\n",
      "Epoch Number :  417\n",
      "\t Training accuracy:  70.71455016660497\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.904178619384766\n",
      "Epoch Number :  418\n",
      "\t Training accuracy:  70.97371343946686\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  62.77444839477539\n",
      "Epoch Number :  419\n",
      "\t Training accuracy:  71.08478341355054\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  62.70747375488281\n",
      "Epoch Number :  420\n",
      "\t Training accuracy:  71.19585338763422\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  58.0\n",
      "\t Epoch Loss  62.66310119628906\n",
      "Epoch Number :  421\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.62802505493164\n",
      "Epoch Number :  422\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.59003448486328\n",
      "Epoch Number :  423\n",
      "\t Training accuracy:  71.380970011107\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.547340393066406\n",
      "Epoch Number :  424\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.509124755859375\n",
      "Epoch Number :  425\n",
      "\t Training accuracy:  71.380970011107\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.47145462036133\n",
      "Epoch Number :  426\n",
      "\t Training accuracy:  71.41799333580155\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.43160629272461\n",
      "Epoch Number :  427\n",
      "\t Training accuracy:  71.45501666049611\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.39142608642578\n",
      "Epoch Number :  428\n",
      "\t Training accuracy:  71.56608663457979\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.34968185424805\n",
      "Epoch Number :  429\n",
      "\t Training accuracy:  71.60310995927435\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.30869674682617\n",
      "Epoch Number :  430\n",
      "\t Training accuracy:  71.60310995927435\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.271339416503906\n",
      "Epoch Number :  431\n",
      "\t Training accuracy:  71.60310995927435\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.240474700927734\n",
      "Epoch Number :  432\n",
      "\t Training accuracy:  71.67715660866345\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.20213317871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  433\n",
      "\t Training accuracy:  71.71417993335801\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.15598678588867\n",
      "Epoch Number :  434\n",
      "\t Training accuracy:  71.78822658274713\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.11366653442383\n",
      "Epoch Number :  435\n",
      "\t Training accuracy:  71.86227323213625\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.076637268066406\n",
      "Epoch Number :  436\n",
      "\t Training accuracy:  71.82524990744169\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  62.024497985839844\n",
      "Epoch Number :  437\n",
      "\t Training accuracy:  71.8992965568308\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  61.98257827758789\n",
      "Epoch Number :  438\n",
      "\t Training accuracy:  72.01036653091448\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  57.0\n",
      "\t Epoch Loss  61.91802978515625\n",
      "Epoch Number :  439\n",
      "\t Training accuracy:  71.1218067382451\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  61.54833221435547\n",
      "Epoch Number :  440\n",
      "\t Training accuracy:  71.19585338763422\n",
      "\t Validation accuracy  72.91666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  60.25791931152344\n",
      "Epoch Number :  441\n",
      "\t Training accuracy:  71.19585338763422\n",
      "\t Validation accuracy  72.91666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.92284393310547\n",
      "Epoch Number :  442\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  72.91666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.86986541748047\n",
      "Epoch Number :  443\n",
      "\t Training accuracy:  71.23287671232876\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.81539535522461\n",
      "Epoch Number :  444\n",
      "\t Training accuracy:  71.19585338763422\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.755706787109375\n",
      "Epoch Number :  445\n",
      "\t Training accuracy:  71.23287671232876\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  59.71260070800781\n",
      "Epoch Number :  446\n",
      "\t Training accuracy:  71.19585338763422\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  59.66326141357422\n",
      "Epoch Number :  447\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.61748123168945\n",
      "Epoch Number :  448\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.56654739379883\n",
      "Epoch Number :  449\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.51806640625\n",
      "Epoch Number :  450\n",
      "\t Training accuracy:  71.34394668641244\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.46844482421875\n",
      "Epoch Number :  451\n",
      "\t Training accuracy:  71.380970011107\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.41744613647461\n",
      "Epoch Number :  452\n",
      "\t Training accuracy:  71.380970011107\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.3690185546875\n",
      "Epoch Number :  453\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.32032775878906\n",
      "Epoch Number :  454\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.268585205078125\n",
      "Epoch Number :  455\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.215057373046875\n",
      "Epoch Number :  456\n",
      "\t Training accuracy:  71.26990003702332\n",
      "\t Validation accuracy  72.22222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.16172409057617\n",
      "Epoch Number :  457\n",
      "\t Training accuracy:  71.23287671232876\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.108978271484375\n",
      "Epoch Number :  458\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  59.04911422729492\n",
      "Epoch Number :  459\n",
      "\t Training accuracy:  71.380970011107\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.99262237548828\n",
      "Epoch Number :  460\n",
      "\t Training accuracy:  71.30692336171788\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.92087173461914\n",
      "Epoch Number :  461\n",
      "\t Training accuracy:  71.41799333580155\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.85077667236328\n",
      "Epoch Number :  462\n",
      "\t Training accuracy:  71.41799333580155\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.78878402709961\n",
      "Epoch Number :  463\n",
      "\t Training accuracy:  71.45501666049611\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.71152877807617\n",
      "Epoch Number :  464\n",
      "\t Training accuracy:  71.49203998519067\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  58.59872055053711\n",
      "Epoch Number :  465\n",
      "\t Training accuracy:  71.52906330988523\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.42469024658203\n",
      "Epoch Number :  466\n",
      "\t Training accuracy:  71.52906330988523\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.34428405761719\n",
      "Epoch Number :  467\n",
      "\t Training accuracy:  71.60310995927435\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.29815673828125\n",
      "Epoch Number :  468\n",
      "\t Training accuracy:  71.75120325805257\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.25251388549805\n",
      "Epoch Number :  469\n",
      "\t Training accuracy:  71.86227323213625\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.19677734375\n",
      "Epoch Number :  470\n",
      "\t Training accuracy:  71.93631988152536\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.153594970703125\n",
      "Epoch Number :  471\n",
      "\t Training accuracy:  71.97334320621992\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.11635208129883\n",
      "Epoch Number :  472\n",
      "\t Training accuracy:  72.01036653091448\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.071414947509766\n",
      "Epoch Number :  473\n",
      "\t Training accuracy:  72.08441318030359\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  58.027305603027344\n",
      "Epoch Number :  474\n",
      "\t Training accuracy:  72.12143650499814\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  57.982765197753906\n",
      "Epoch Number :  475\n",
      "\t Training accuracy:  72.12143650499814\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  57.939266204833984\n",
      "Epoch Number :  476\n",
      "\t Training accuracy:  72.1584598296927\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.89580535888672\n",
      "Epoch Number :  477\n",
      "\t Training accuracy:  72.19548315438726\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.85285568237305\n",
      "Epoch Number :  478\n",
      "\t Training accuracy:  72.19548315438726\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.80906677246094\n",
      "Epoch Number :  479\n",
      "\t Training accuracy:  72.1584598296927\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.765785217285156\n",
      "Epoch Number :  480\n",
      "\t Training accuracy:  72.19548315438726\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.72178649902344\n",
      "Epoch Number :  481\n",
      "\t Training accuracy:  72.30655312847094\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.67902374267578\n",
      "Epoch Number :  482\n",
      "\t Training accuracy:  72.30655312847094\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.63712692260742\n",
      "Epoch Number :  483\n",
      "\t Training accuracy:  72.3435764531655\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.59644317626953\n",
      "Epoch Number :  484\n",
      "\t Training accuracy:  72.38059977786006\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.555545806884766\n",
      "Epoch Number :  485\n",
      "\t Training accuracy:  72.41762310255461\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.515113830566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  486\n",
      "\t Training accuracy:  72.52869307663828\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.474449157714844\n",
      "Epoch Number :  487\n",
      "\t Training accuracy:  72.52869307663828\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.43450164794922\n",
      "Epoch Number :  488\n",
      "\t Training accuracy:  72.52869307663828\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.39436340332031\n",
      "Epoch Number :  489\n",
      "\t Training accuracy:  72.52869307663828\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.35417938232422\n",
      "Epoch Number :  490\n",
      "\t Training accuracy:  72.52869307663828\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.31431198120117\n",
      "Epoch Number :  491\n",
      "\t Training accuracy:  72.6027397260274\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.274471282958984\n",
      "Epoch Number :  492\n",
      "\t Training accuracy:  72.67678637541651\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.23476791381836\n",
      "Epoch Number :  493\n",
      "\t Training accuracy:  72.75083302480563\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.19572448730469\n",
      "Epoch Number :  494\n",
      "\t Training accuracy:  72.8619029988893\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.15601348876953\n",
      "Epoch Number :  495\n",
      "\t Training accuracy:  72.82487967419475\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.1187744140625\n",
      "Epoch Number :  496\n",
      "\t Training accuracy:  72.8619029988893\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.07965850830078\n",
      "Epoch Number :  497\n",
      "\t Training accuracy:  72.97297297297297\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.04030227661133\n",
      "Epoch Number :  498\n",
      "\t Training accuracy:  73.00999629766753\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  57.000938415527344\n",
      "Epoch Number :  499\n",
      "\t Training accuracy:  73.00999629766753\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  56.961036682128906\n",
      "Epoch Number :  500\n",
      "\t Training accuracy:  73.04701962236209\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  56.91416549682617\n",
      "Epoch Number :  501\n",
      "\t Training accuracy:  73.1210662717512\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.87504196166992\n",
      "Epoch Number :  502\n",
      "\t Training accuracy:  73.23213624583488\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.83564376831055\n",
      "Epoch Number :  503\n",
      "\t Training accuracy:  73.23213624583488\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.796661376953125\n",
      "Epoch Number :  504\n",
      "\t Training accuracy:  73.23213624583488\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.75808334350586\n",
      "Epoch Number :  505\n",
      "\t Training accuracy:  73.34320621991854\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.71923828125\n",
      "Epoch Number :  506\n",
      "\t Training accuracy:  73.306182895224\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.680782318115234\n",
      "Epoch Number :  507\n",
      "\t Training accuracy:  73.23213624583488\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.64262771606445\n",
      "Epoch Number :  508\n",
      "\t Training accuracy:  73.26915957052944\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.604469299316406\n",
      "Epoch Number :  509\n",
      "\t Training accuracy:  73.23213624583488\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.5667610168457\n",
      "Epoch Number :  510\n",
      "\t Training accuracy:  73.306182895224\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.528076171875\n",
      "Epoch Number :  511\n",
      "\t Training accuracy:  73.45427619400222\n",
      "\t Validation accuracy  73.61111111111111\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.490020751953125\n",
      "Epoch Number :  512\n",
      "\t Training accuracy:  73.52832284339134\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.45355224609375\n",
      "Epoch Number :  513\n",
      "\t Training accuracy:  73.49129951869678\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.41546630859375\n",
      "Epoch Number :  514\n",
      "\t Training accuracy:  73.49129951869678\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.37751770019531\n",
      "Epoch Number :  515\n",
      "\t Training accuracy:  73.52832284339134\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.339820861816406\n",
      "Epoch Number :  516\n",
      "\t Training accuracy:  73.5653461680859\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.301307678222656\n",
      "Epoch Number :  517\n",
      "\t Training accuracy:  73.60236949278045\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.26353454589844\n",
      "Epoch Number :  518\n",
      "\t Training accuracy:  73.63939281747501\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.22126770019531\n",
      "Epoch Number :  519\n",
      "\t Training accuracy:  73.78748611625323\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.18331527709961\n",
      "Epoch Number :  520\n",
      "\t Training accuracy:  73.89855609033691\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.14503479003906\n",
      "Epoch Number :  521\n",
      "\t Training accuracy:  74.00962606442059\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.10676193237305\n",
      "Epoch Number :  522\n",
      "\t Training accuracy:  73.93557941503147\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.06855010986328\n",
      "Epoch Number :  523\n",
      "\t Training accuracy:  73.97260273972603\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  56.02936935424805\n",
      "Epoch Number :  524\n",
      "\t Training accuracy:  73.97260273972603\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.984806060791016\n",
      "Epoch Number :  525\n",
      "\t Training accuracy:  74.00962606442059\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.941001892089844\n",
      "Epoch Number :  526\n",
      "\t Training accuracy:  74.0836727138097\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.90311050415039\n",
      "Epoch Number :  527\n",
      "\t Training accuracy:  74.15771936319882\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.84937286376953\n",
      "Epoch Number :  528\n",
      "\t Training accuracy:  74.15771936319882\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.8055419921875\n",
      "Epoch Number :  529\n",
      "\t Training accuracy:  74.19474268789337\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.76233673095703\n",
      "Epoch Number :  530\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.73434829711914\n",
      "Epoch Number :  531\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.696231842041016\n",
      "Epoch Number :  532\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  55.653133392333984\n",
      "Epoch Number :  533\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.6153678894043\n",
      "Epoch Number :  534\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  74.30555555555556\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.578407287597656\n",
      "Epoch Number :  535\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.54084396362305\n",
      "Epoch Number :  536\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.50320816040039\n",
      "Epoch Number :  537\n",
      "\t Training accuracy:  74.26878933728248\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.4675407409668\n",
      "Epoch Number :  538\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.43243408203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  539\n",
      "\t Training accuracy:  74.19474268789337\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.39506912231445\n",
      "Epoch Number :  540\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.357017517089844\n",
      "Epoch Number :  541\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.318572998046875\n",
      "Epoch Number :  542\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.27336502075195\n",
      "Epoch Number :  543\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.228721618652344\n",
      "Epoch Number :  544\n",
      "\t Training accuracy:  74.23176601258793\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.184608459472656\n",
      "Epoch Number :  545\n",
      "\t Training accuracy:  74.3428359866716\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  55.14067077636719\n",
      "Epoch Number :  546\n",
      "\t Training accuracy:  74.37985931136616\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  55.09601593017578\n",
      "Epoch Number :  547\n",
      "\t Training accuracy:  74.37985931136616\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  55.051021575927734\n",
      "Epoch Number :  548\n",
      "\t Training accuracy:  74.37985931136616\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  55.00600814819336\n",
      "Epoch Number :  549\n",
      "\t Training accuracy:  74.37985931136616\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.961181640625\n",
      "Epoch Number :  550\n",
      "\t Training accuracy:  74.49092928544984\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.917198181152344\n",
      "Epoch Number :  551\n",
      "\t Training accuracy:  74.5279526101444\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.873661041259766\n",
      "Epoch Number :  552\n",
      "\t Training accuracy:  74.56497593483896\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.829559326171875\n",
      "Epoch Number :  553\n",
      "\t Training accuracy:  74.67604590892262\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.78486251831055\n",
      "Epoch Number :  554\n",
      "\t Training accuracy:  74.67604590892262\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  54.73811340332031\n",
      "Epoch Number :  555\n",
      "\t Training accuracy:  74.71306923361718\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.700477600097656\n",
      "Epoch Number :  556\n",
      "\t Training accuracy:  74.71306923361718\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.662715911865234\n",
      "Epoch Number :  557\n",
      "\t Training accuracy:  74.82413920770085\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.62467575073242\n",
      "Epoch Number :  558\n",
      "\t Training accuracy:  74.82413920770085\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.58106994628906\n",
      "Epoch Number :  559\n",
      "\t Training accuracy:  74.86116253239541\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.54262161254883\n",
      "Epoch Number :  560\n",
      "\t Training accuracy:  74.93520918178453\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.50495910644531\n",
      "Epoch Number :  561\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.46641159057617\n",
      "Epoch Number :  562\n",
      "\t Training accuracy:  75.00925583117363\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.42717361450195\n",
      "Epoch Number :  563\n",
      "\t Training accuracy:  75.00925583117363\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.387813568115234\n",
      "Epoch Number :  564\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.34868240356445\n",
      "Epoch Number :  565\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.309444427490234\n",
      "Epoch Number :  566\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.27182388305664\n",
      "Epoch Number :  567\n",
      "\t Training accuracy:  74.93520918178453\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.233951568603516\n",
      "Epoch Number :  568\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.19587707519531\n",
      "Epoch Number :  569\n",
      "\t Training accuracy:  74.97223250647909\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.15763854980469\n",
      "Epoch Number :  570\n",
      "\t Training accuracy:  75.00925583117363\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.11966323852539\n",
      "Epoch Number :  571\n",
      "\t Training accuracy:  75.00925583117363\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.08225631713867\n",
      "Epoch Number :  572\n",
      "\t Training accuracy:  75.04627915586819\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.04506301879883\n",
      "Epoch Number :  573\n",
      "\t Training accuracy:  75.08330248056275\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  54.00956726074219\n",
      "Epoch Number :  574\n",
      "\t Training accuracy:  75.08330248056275\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.97483825683594\n",
      "Epoch Number :  575\n",
      "\t Training accuracy:  75.12032580525731\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.93986129760742\n",
      "Epoch Number :  576\n",
      "\t Training accuracy:  75.12032580525731\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.90463638305664\n",
      "Epoch Number :  577\n",
      "\t Training accuracy:  75.19437245464643\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.870853424072266\n",
      "Epoch Number :  578\n",
      "\t Training accuracy:  75.26841910403554\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.835670471191406\n",
      "Epoch Number :  579\n",
      "\t Training accuracy:  75.23139577934099\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.8004264831543\n",
      "Epoch Number :  580\n",
      "\t Training accuracy:  75.23139577934099\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.76548385620117\n",
      "Epoch Number :  581\n",
      "\t Training accuracy:  75.26841910403554\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.73053741455078\n",
      "Epoch Number :  582\n",
      "\t Training accuracy:  75.3054424287301\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.688194274902344\n",
      "Epoch Number :  583\n",
      "\t Training accuracy:  75.34246575342466\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.653350830078125\n",
      "Epoch Number :  584\n",
      "\t Training accuracy:  75.37948907811922\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.61896896362305\n",
      "Epoch Number :  585\n",
      "\t Training accuracy:  75.41651240281378\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.584938049316406\n",
      "Epoch Number :  586\n",
      "\t Training accuracy:  75.49055905220288\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.55131912231445\n",
      "Epoch Number :  587\n",
      "\t Training accuracy:  75.52758237689744\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.5177116394043\n",
      "Epoch Number :  588\n",
      "\t Training accuracy:  75.60162902628656\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.4845085144043\n",
      "Epoch Number :  589\n",
      "\t Training accuracy:  75.67567567567568\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.45069122314453\n",
      "Epoch Number :  590\n",
      "\t Training accuracy:  75.67567567567568\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.41169738769531\n",
      "Epoch Number :  591\n",
      "\t Training accuracy:  75.67567567567568\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.32283401489258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  592\n",
      "\t Training accuracy:  75.67567567567568\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.2857666015625\n",
      "Epoch Number :  593\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.304630279541016\n",
      "Epoch Number :  594\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.219058990478516\n",
      "Epoch Number :  595\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.1806755065918\n",
      "Epoch Number :  596\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.14579772949219\n",
      "Epoch Number :  597\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.114036560058594\n",
      "Epoch Number :  598\n",
      "\t Training accuracy:  75.7497223250648\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.07926940917969\n",
      "Epoch Number :  599\n",
      "\t Training accuracy:  75.71269900037024\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.04817581176758\n",
      "Epoch Number :  600\n",
      "\t Training accuracy:  75.78674564975935\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  53.015987396240234\n",
      "Epoch Number :  601\n",
      "\t Training accuracy:  75.78674564975935\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  52.98432922363281\n",
      "Epoch Number :  602\n",
      "\t Training accuracy:  75.78674564975935\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  52.95197296142578\n",
      "Epoch Number :  603\n",
      "\t Training accuracy:  75.78674564975935\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  52.91860580444336\n",
      "Epoch Number :  604\n",
      "\t Training accuracy:  75.82376897445391\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  52.93382263183594\n",
      "Epoch Number :  605\n",
      "\t Training accuracy:  75.89781562384302\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.90460968017578\n",
      "Epoch Number :  606\n",
      "\t Training accuracy:  75.93483894853757\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.87150573730469\n",
      "Epoch Number :  607\n",
      "\t Training accuracy:  75.93483894853757\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.84174728393555\n",
      "Epoch Number :  608\n",
      "\t Training accuracy:  75.93483894853757\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.81155014038086\n",
      "Epoch Number :  609\n",
      "\t Training accuracy:  75.97186227323213\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.77903366088867\n",
      "Epoch Number :  610\n",
      "\t Training accuracy:  75.97186227323213\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.74603271484375\n",
      "Epoch Number :  611\n",
      "\t Training accuracy:  76.04590892262125\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.7123908996582\n",
      "Epoch Number :  612\n",
      "\t Training accuracy:  76.08293224731581\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.6781120300293\n",
      "Epoch Number :  613\n",
      "\t Training accuracy:  76.08293224731581\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.644561767578125\n",
      "Epoch Number :  614\n",
      "\t Training accuracy:  76.08293224731581\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.610862731933594\n",
      "Epoch Number :  615\n",
      "\t Training accuracy:  76.08293224731581\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.57796096801758\n",
      "Epoch Number :  616\n",
      "\t Training accuracy:  76.08293224731581\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.543296813964844\n",
      "Epoch Number :  617\n",
      "\t Training accuracy:  76.11995557201037\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.50727462768555\n",
      "Epoch Number :  618\n",
      "\t Training accuracy:  76.11995557201037\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.47089767456055\n",
      "Epoch Number :  619\n",
      "\t Training accuracy:  76.15697889670493\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.440040588378906\n",
      "Epoch Number :  620\n",
      "\t Training accuracy:  76.15697889670493\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.40547180175781\n",
      "Epoch Number :  621\n",
      "\t Training accuracy:  76.23102554609405\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.37443923950195\n",
      "Epoch Number :  622\n",
      "\t Training accuracy:  76.26804887078859\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.341705322265625\n",
      "Epoch Number :  623\n",
      "\t Training accuracy:  76.30507219548315\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.309898376464844\n",
      "Epoch Number :  624\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.277610778808594\n",
      "Epoch Number :  625\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.244850158691406\n",
      "Epoch Number :  626\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.21172332763672\n",
      "Epoch Number :  627\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.178184509277344\n",
      "Epoch Number :  628\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.14481735229492\n",
      "Epoch Number :  629\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.111698150634766\n",
      "Epoch Number :  630\n",
      "\t Training accuracy:  76.41614216956683\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.078529357910156\n",
      "Epoch Number :  631\n",
      "\t Training accuracy:  76.45316549426138\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  52.04584884643555\n",
      "Epoch Number :  632\n",
      "\t Training accuracy:  76.45316549426138\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  52.013858795166016\n",
      "Epoch Number :  633\n",
      "\t Training accuracy:  76.45316549426138\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.982200622558594\n",
      "Epoch Number :  634\n",
      "\t Training accuracy:  76.49018881895594\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.94872283935547\n",
      "Epoch Number :  635\n",
      "\t Training accuracy:  76.49018881895594\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.912261962890625\n",
      "Epoch Number :  636\n",
      "\t Training accuracy:  76.49018881895594\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.87916564941406\n",
      "Epoch Number :  637\n",
      "\t Training accuracy:  76.5272121436505\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.84633255004883\n",
      "Epoch Number :  638\n",
      "\t Training accuracy:  76.60125879303962\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.8134880065918\n",
      "Epoch Number :  639\n",
      "\t Training accuracy:  76.60125879303962\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.781005859375\n",
      "Epoch Number :  640\n",
      "\t Training accuracy:  76.60125879303962\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.748695373535156\n",
      "Epoch Number :  641\n",
      "\t Training accuracy:  76.5272121436505\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.71613311767578\n",
      "Epoch Number :  642\n",
      "\t Training accuracy:  76.45316549426138\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.68334197998047\n",
      "Epoch Number :  643\n",
      "\t Training accuracy:  76.56423546834506\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.65083694458008\n",
      "Epoch Number :  644\n",
      "\t Training accuracy:  76.49018881895594\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.61854934692383\n",
      "Epoch Number :  645\n",
      "\t Training accuracy:  76.45316549426138\n",
      "\t Validation accuracy  75.0\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.58693313598633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  646\n",
      "\t Training accuracy:  76.49018881895594\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.559452056884766\n",
      "Epoch Number :  647\n",
      "\t Training accuracy:  76.5272121436505\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.52764129638672\n",
      "Epoch Number :  648\n",
      "\t Training accuracy:  76.5272121436505\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.496337890625\n",
      "Epoch Number :  649\n",
      "\t Training accuracy:  76.63828211773418\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.464637756347656\n",
      "Epoch Number :  650\n",
      "\t Training accuracy:  76.63828211773418\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.43301773071289\n",
      "Epoch Number :  651\n",
      "\t Training accuracy:  76.63828211773418\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.39763259887695\n",
      "Epoch Number :  652\n",
      "\t Training accuracy:  76.74935209181784\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.36681365966797\n",
      "Epoch Number :  653\n",
      "\t Training accuracy:  76.74935209181784\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.33578872680664\n",
      "Epoch Number :  654\n",
      "\t Training accuracy:  76.74935209181784\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.30459213256836\n",
      "Epoch Number :  655\n",
      "\t Training accuracy:  76.71232876712328\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.273536682128906\n",
      "Epoch Number :  656\n",
      "\t Training accuracy:  76.82339874120696\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.24258041381836\n",
      "Epoch Number :  657\n",
      "\t Training accuracy:  76.89744539059608\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.21183395385742\n",
      "Epoch Number :  658\n",
      "\t Training accuracy:  76.9714920399852\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.181007385253906\n",
      "Epoch Number :  659\n",
      "\t Training accuracy:  76.9714920399852\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.150054931640625\n",
      "Epoch Number :  660\n",
      "\t Training accuracy:  76.9714920399852\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.11920928955078\n",
      "Epoch Number :  661\n",
      "\t Training accuracy:  76.93446871529063\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.08785629272461\n",
      "Epoch Number :  662\n",
      "\t Training accuracy:  76.93446871529063\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.056575775146484\n",
      "Epoch Number :  663\n",
      "\t Training accuracy:  76.86042206590152\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  51.02528381347656\n",
      "Epoch Number :  664\n",
      "\t Training accuracy:  76.86042206590152\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.993648529052734\n",
      "Epoch Number :  665\n",
      "\t Training accuracy:  76.89744539059608\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.962589263916016\n",
      "Epoch Number :  666\n",
      "\t Training accuracy:  76.93446871529063\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.931884765625\n",
      "Epoch Number :  667\n",
      "\t Training accuracy:  77.00851536467975\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.90081787109375\n",
      "Epoch Number :  668\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.86984634399414\n",
      "Epoch Number :  669\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.838462829589844\n",
      "Epoch Number :  670\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.8079948425293\n",
      "Epoch Number :  671\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.77769088745117\n",
      "Epoch Number :  672\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.74843978881836\n",
      "Epoch Number :  673\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.719444274902344\n",
      "Epoch Number :  674\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.69059371948242\n",
      "Epoch Number :  675\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.66204071044922\n",
      "Epoch Number :  676\n",
      "\t Training accuracy:  77.00851536467975\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  50.63368225097656\n",
      "Epoch Number :  677\n",
      "\t Training accuracy:  77.11958533876341\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.60536193847656\n",
      "Epoch Number :  678\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.576969146728516\n",
      "Epoch Number :  679\n",
      "\t Training accuracy:  77.04553868937431\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.54815673828125\n",
      "Epoch Number :  680\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.519466400146484\n",
      "Epoch Number :  681\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.49115753173828\n",
      "Epoch Number :  682\n",
      "\t Training accuracy:  77.08256201406887\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.4627685546875\n",
      "Epoch Number :  683\n",
      "\t Training accuracy:  77.11958533876341\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.433658599853516\n",
      "Epoch Number :  684\n",
      "\t Training accuracy:  77.15660866345797\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.405399322509766\n",
      "Epoch Number :  685\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.37677764892578\n",
      "Epoch Number :  686\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.348262786865234\n",
      "Epoch Number :  687\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.320011138916016\n",
      "Epoch Number :  688\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.29181671142578\n",
      "Epoch Number :  689\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.26347351074219\n",
      "Epoch Number :  690\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.23506164550781\n",
      "Epoch Number :  691\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.20689392089844\n",
      "Epoch Number :  692\n",
      "\t Training accuracy:  77.15660866345797\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.17911911010742\n",
      "Epoch Number :  693\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.15126037597656\n",
      "Epoch Number :  694\n",
      "\t Training accuracy:  77.19363198815253\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.123008728027344\n",
      "Epoch Number :  695\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.09510040283203\n",
      "Epoch Number :  696\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.072025299072266\n",
      "Epoch Number :  697\n",
      "\t Training accuracy:  77.26767863754165\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.043941497802734\n",
      "Epoch Number :  698\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  50.01571273803711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  699\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.98740768432617\n",
      "Epoch Number :  700\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.958961486816406\n",
      "Epoch Number :  701\n",
      "\t Training accuracy:  77.23065531284709\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.930789947509766\n",
      "Epoch Number :  702\n",
      "\t Training accuracy:  77.26767863754165\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.903499603271484\n",
      "Epoch Number :  703\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.87588119506836\n",
      "Epoch Number :  704\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.848392486572266\n",
      "Epoch Number :  705\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.820404052734375\n",
      "Epoch Number :  706\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.79221725463867\n",
      "Epoch Number :  707\n",
      "\t Training accuracy:  77.30470196223621\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.76433563232422\n",
      "Epoch Number :  708\n",
      "\t Training accuracy:  77.37874861162533\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.7327766418457\n",
      "Epoch Number :  709\n",
      "\t Training accuracy:  77.37874861162533\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.70537185668945\n",
      "Epoch Number :  710\n",
      "\t Training accuracy:  77.41577193631989\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.67790603637695\n",
      "Epoch Number :  711\n",
      "\t Training accuracy:  77.45279526101444\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.650726318359375\n",
      "Epoch Number :  712\n",
      "\t Training accuracy:  77.45279526101444\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.62338638305664\n",
      "Epoch Number :  713\n",
      "\t Training accuracy:  77.489818585709\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.59611511230469\n",
      "Epoch Number :  714\n",
      "\t Training accuracy:  77.489818585709\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.56951904296875\n",
      "Epoch Number :  715\n",
      "\t Training accuracy:  77.52684191040355\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.5433349609375\n",
      "Epoch Number :  716\n",
      "\t Training accuracy:  77.5638652350981\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.51644515991211\n",
      "Epoch Number :  717\n",
      "\t Training accuracy:  77.5638652350981\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.48955535888672\n",
      "Epoch Number :  718\n",
      "\t Training accuracy:  77.5638652350981\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.462310791015625\n",
      "Epoch Number :  719\n",
      "\t Training accuracy:  77.5638652350981\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.435028076171875\n",
      "Epoch Number :  720\n",
      "\t Training accuracy:  77.60088855979266\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.40803527832031\n",
      "Epoch Number :  721\n",
      "\t Training accuracy:  77.60088855979266\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.38108444213867\n",
      "Epoch Number :  722\n",
      "\t Training accuracy:  77.60088855979266\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.353736877441406\n",
      "Epoch Number :  723\n",
      "\t Training accuracy:  77.60088855979266\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.32661819458008\n",
      "Epoch Number :  724\n",
      "\t Training accuracy:  77.63791188448722\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.29295349121094\n",
      "Epoch Number :  725\n",
      "\t Training accuracy:  77.63791188448722\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.26723098754883\n",
      "Epoch Number :  726\n",
      "\t Training accuracy:  77.63791188448722\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.2411003112793\n",
      "Epoch Number :  727\n",
      "\t Training accuracy:  77.67493520918178\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.21479797363281\n",
      "Epoch Number :  728\n",
      "\t Training accuracy:  77.67493520918178\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  59.0\n",
      "\t Epoch Loss  49.18749237060547\n",
      "Epoch Number :  729\n",
      "\t Training accuracy:  77.71195853387634\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.160552978515625\n",
      "Epoch Number :  730\n",
      "\t Training accuracy:  77.71195853387634\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.133155822753906\n",
      "Epoch Number :  731\n",
      "\t Training accuracy:  77.71195853387634\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.10634231567383\n",
      "Epoch Number :  732\n",
      "\t Training accuracy:  77.71195853387634\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.080299377441406\n",
      "Epoch Number :  733\n",
      "\t Training accuracy:  77.7489818585709\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.05378341674805\n",
      "Epoch Number :  734\n",
      "\t Training accuracy:  77.7489818585709\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  49.026702880859375\n",
      "Epoch Number :  735\n",
      "\t Training accuracy:  77.78600518326546\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.997703552246094\n",
      "Epoch Number :  736\n",
      "\t Training accuracy:  77.86005183265458\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.96893310546875\n",
      "Epoch Number :  737\n",
      "\t Training accuracy:  77.86005183265458\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.94026565551758\n",
      "Epoch Number :  738\n",
      "\t Training accuracy:  77.9340984820437\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.91167449951172\n",
      "Epoch Number :  739\n",
      "\t Training accuracy:  78.04516845612736\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.88099670410156\n",
      "Epoch Number :  740\n",
      "\t Training accuracy:  78.0081451314328\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.849021911621094\n",
      "Epoch Number :  741\n",
      "\t Training accuracy:  77.97112180673824\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.818336486816406\n",
      "Epoch Number :  742\n",
      "\t Training accuracy:  77.9340984820437\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.78606414794922\n",
      "Epoch Number :  743\n",
      "\t Training accuracy:  77.97112180673824\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.757240295410156\n",
      "Epoch Number :  744\n",
      "\t Training accuracy:  77.97112180673824\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.72584915161133\n",
      "Epoch Number :  745\n",
      "\t Training accuracy:  78.0081451314328\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.69291305541992\n",
      "Epoch Number :  746\n",
      "\t Training accuracy:  78.0081451314328\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.66472244262695\n",
      "Epoch Number :  747\n",
      "\t Training accuracy:  78.0081451314328\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  60.0\n",
      "\t Epoch Loss  48.631446838378906\n",
      "Epoch Number :  748\n",
      "\t Training accuracy:  78.0081451314328\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.59878921508789\n",
      "Epoch Number :  749\n",
      "\t Training accuracy:  78.11921510551647\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.5705680847168\n",
      "Epoch Number :  750\n",
      "\t Training accuracy:  78.11921510551647\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.53789520263672\n",
      "Epoch Number :  751\n",
      "\t Training accuracy:  78.11921510551647\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.506675720214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  752\n",
      "\t Training accuracy:  78.15623843021103\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.4738883972168\n",
      "Epoch Number :  753\n",
      "\t Training accuracy:  78.15623843021103\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.44252014160156\n",
      "Epoch Number :  754\n",
      "\t Training accuracy:  78.19326175490559\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.410057067871094\n",
      "Epoch Number :  755\n",
      "\t Training accuracy:  78.19326175490559\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.3790168762207\n",
      "Epoch Number :  756\n",
      "\t Training accuracy:  78.19326175490559\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  48.345733642578125\n",
      "Epoch Number :  757\n",
      "\t Training accuracy:  78.19326175490559\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  48.31440353393555\n",
      "Epoch Number :  758\n",
      "\t Training accuracy:  78.19326175490559\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  48.28004455566406\n",
      "Epoch Number :  759\n",
      "\t Training accuracy:  78.23028507960015\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.2474479675293\n",
      "Epoch Number :  760\n",
      "\t Training accuracy:  78.26730840429471\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.21586227416992\n",
      "Epoch Number :  761\n",
      "\t Training accuracy:  78.26730840429471\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.18119430541992\n",
      "Epoch Number :  762\n",
      "\t Training accuracy:  78.23028507960015\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.146060943603516\n",
      "Epoch Number :  763\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.10981750488281\n",
      "Epoch Number :  764\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.0748405456543\n",
      "Epoch Number :  765\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.04206466674805\n",
      "Epoch Number :  766\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  48.01029968261719\n",
      "Epoch Number :  767\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.97685241699219\n",
      "Epoch Number :  768\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.94538497924805\n",
      "Epoch Number :  769\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.909053802490234\n",
      "Epoch Number :  770\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.87404251098633\n",
      "Epoch Number :  771\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.841434478759766\n",
      "Epoch Number :  772\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.804664611816406\n",
      "Epoch Number :  773\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.770416259765625\n",
      "Epoch Number :  774\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.73848342895508\n",
      "Epoch Number :  775\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.704185485839844\n",
      "Epoch Number :  776\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.67261505126953\n",
      "Epoch Number :  777\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.637916564941406\n",
      "Epoch Number :  778\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.603546142578125\n",
      "Epoch Number :  779\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.570899963378906\n",
      "Epoch Number :  780\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.541378021240234\n",
      "Epoch Number :  781\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.51169967651367\n",
      "Epoch Number :  782\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.481292724609375\n",
      "Epoch Number :  783\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.45208740234375\n",
      "Epoch Number :  784\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.42169189453125\n",
      "Epoch Number :  785\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.39207077026367\n",
      "Epoch Number :  786\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.36221694946289\n",
      "Epoch Number :  787\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.33214569091797\n",
      "Epoch Number :  788\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.302799224853516\n",
      "Epoch Number :  789\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.27305603027344\n",
      "Epoch Number :  790\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.24354553222656\n",
      "Epoch Number :  791\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.21357345581055\n",
      "Epoch Number :  792\n",
      "\t Training accuracy:  78.26730840429471\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.18391799926758\n",
      "Epoch Number :  793\n",
      "\t Training accuracy:  78.26730840429471\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.154476165771484\n",
      "Epoch Number :  794\n",
      "\t Training accuracy:  78.30433172898927\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.12493896484375\n",
      "Epoch Number :  795\n",
      "\t Training accuracy:  78.34135505368383\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.09535598754883\n",
      "Epoch Number :  796\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.06523132324219\n",
      "Epoch Number :  797\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.03635025024414\n",
      "Epoch Number :  798\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  47.00535583496094\n",
      "Epoch Number :  799\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.97674560546875\n",
      "Epoch Number :  800\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.9459228515625\n",
      "Epoch Number :  801\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.91746520996094\n",
      "Epoch Number :  802\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.88730239868164\n",
      "Epoch Number :  803\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.85788345336914\n",
      "Epoch Number :  804\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.829437255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  805\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.79990005493164\n",
      "Epoch Number :  806\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.77080535888672\n",
      "Epoch Number :  807\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.741817474365234\n",
      "Epoch Number :  808\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.712223052978516\n",
      "Epoch Number :  809\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.682769775390625\n",
      "Epoch Number :  810\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.65337371826172\n",
      "Epoch Number :  811\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.6231689453125\n",
      "Epoch Number :  812\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.593788146972656\n",
      "Epoch Number :  813\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.564186096191406\n",
      "Epoch Number :  814\n",
      "\t Training accuracy:  78.48944835246205\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.534305572509766\n",
      "Epoch Number :  815\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.50133514404297\n",
      "Epoch Number :  816\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.47162628173828\n",
      "Epoch Number :  817\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.44139099121094\n",
      "Epoch Number :  818\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.41029357910156\n",
      "Epoch Number :  819\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.37984085083008\n",
      "Epoch Number :  820\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.349609375\n",
      "Epoch Number :  821\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.318477630615234\n",
      "Epoch Number :  822\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.287906646728516\n",
      "Epoch Number :  823\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.25785446166992\n",
      "Epoch Number :  824\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.227020263671875\n",
      "Epoch Number :  825\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  46.196929931640625\n",
      "Epoch Number :  826\n",
      "\t Training accuracy:  78.37837837837837\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.165340423583984\n",
      "Epoch Number :  827\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.135135650634766\n",
      "Epoch Number :  828\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.104148864746094\n",
      "Epoch Number :  829\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.073265075683594\n",
      "Epoch Number :  830\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.042266845703125\n",
      "Epoch Number :  831\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  46.011497497558594\n",
      "Epoch Number :  832\n",
      "\t Training accuracy:  78.41540170307293\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  45.981292724609375\n",
      "Epoch Number :  833\n",
      "\t Training accuracy:  78.45242502776749\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  45.95096969604492\n",
      "Epoch Number :  834\n",
      "\t Training accuracy:  78.48944835246205\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  45.92079544067383\n",
      "Epoch Number :  835\n",
      "\t Training accuracy:  78.48944835246205\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  45.89094543457031\n",
      "Epoch Number :  836\n",
      "\t Training accuracy:  78.60051832654572\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.86054992675781\n",
      "Epoch Number :  837\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.831207275390625\n",
      "Epoch Number :  838\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.80140686035156\n",
      "Epoch Number :  839\n",
      "\t Training accuracy:  78.60051832654572\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.7723503112793\n",
      "Epoch Number :  840\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.74261474609375\n",
      "Epoch Number :  841\n",
      "\t Training accuracy:  78.52647167715661\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.71260070800781\n",
      "Epoch Number :  842\n",
      "\t Training accuracy:  78.56349500185117\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.68178939819336\n",
      "Epoch Number :  843\n",
      "\t Training accuracy:  78.60051832654572\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.651371002197266\n",
      "Epoch Number :  844\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.620941162109375\n",
      "Epoch Number :  845\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.59090805053711\n",
      "Epoch Number :  846\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.5604362487793\n",
      "Epoch Number :  847\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.531044006347656\n",
      "Epoch Number :  848\n",
      "\t Training accuracy:  78.67456497593484\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.50080490112305\n",
      "Epoch Number :  849\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.47059631347656\n",
      "Epoch Number :  850\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.440818786621094\n",
      "Epoch Number :  851\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.406761169433594\n",
      "Epoch Number :  852\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  45.377342224121094\n",
      "Epoch Number :  853\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.34685134887695\n",
      "Epoch Number :  854\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.317039489746094\n",
      "Epoch Number :  855\n",
      "\t Training accuracy:  78.63754165124028\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.28791427612305\n",
      "Epoch Number :  856\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.25802993774414\n",
      "Epoch Number :  857\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.228477478027344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  858\n",
      "\t Training accuracy:  78.7115883006294\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.198970794677734\n",
      "Epoch Number :  859\n",
      "\t Training accuracy:  78.74861162532396\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.16962814331055\n",
      "Epoch Number :  860\n",
      "\t Training accuracy:  78.74861162532396\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.139801025390625\n",
      "Epoch Number :  861\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.111324310302734\n",
      "Epoch Number :  862\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.081790924072266\n",
      "Epoch Number :  863\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.05220413208008\n",
      "Epoch Number :  864\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  45.02256393432617\n",
      "Epoch Number :  865\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.98971176147461\n",
      "Epoch Number :  866\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.96092224121094\n",
      "Epoch Number :  867\n",
      "\t Training accuracy:  78.82265827471306\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.93129348754883\n",
      "Epoch Number :  868\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.90260696411133\n",
      "Epoch Number :  869\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.875244140625\n",
      "Epoch Number :  870\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.848026275634766\n",
      "Epoch Number :  871\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.821533203125\n",
      "Epoch Number :  872\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.79494094848633\n",
      "Epoch Number :  873\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.76773452758789\n",
      "Epoch Number :  874\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.740478515625\n",
      "Epoch Number :  875\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.713523864746094\n",
      "Epoch Number :  876\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.68703079223633\n",
      "Epoch Number :  877\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.655731201171875\n",
      "Epoch Number :  878\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.62881851196289\n",
      "Epoch Number :  879\n",
      "\t Training accuracy:  78.7856349500185\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.601890563964844\n",
      "Epoch Number :  880\n",
      "\t Training accuracy:  78.82265827471306\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.57463836669922\n",
      "Epoch Number :  881\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.547874450683594\n",
      "Epoch Number :  882\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.52070999145508\n",
      "Epoch Number :  883\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.493568420410156\n",
      "Epoch Number :  884\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.466373443603516\n",
      "Epoch Number :  885\n",
      "\t Training accuracy:  78.89670492410218\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.43980026245117\n",
      "Epoch Number :  886\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.412750244140625\n",
      "Epoch Number :  887\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.38621520996094\n",
      "Epoch Number :  888\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.358741760253906\n",
      "Epoch Number :  889\n",
      "\t Training accuracy:  78.85968159940762\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.33169174194336\n",
      "Epoch Number :  890\n",
      "\t Training accuracy:  78.93372824879674\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.30495071411133\n",
      "Epoch Number :  891\n",
      "\t Training accuracy:  78.9707515734913\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.278358459472656\n",
      "Epoch Number :  892\n",
      "\t Training accuracy:  78.9707515734913\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.252044677734375\n",
      "Epoch Number :  893\n",
      "\t Training accuracy:  78.9707515734913\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.22501754760742\n",
      "Epoch Number :  894\n",
      "\t Training accuracy:  79.00777489818586\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.19868850708008\n",
      "Epoch Number :  895\n",
      "\t Training accuracy:  79.04479822288042\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.172672271728516\n",
      "Epoch Number :  896\n",
      "\t Training accuracy:  79.11884487226953\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.14790725708008\n",
      "Epoch Number :  897\n",
      "\t Training accuracy:  79.1558681969641\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.122596740722656\n",
      "Epoch Number :  898\n",
      "\t Training accuracy:  79.1558681969641\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.09700393676758\n",
      "Epoch Number :  899\n",
      "\t Training accuracy:  79.1558681969641\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.071563720703125\n",
      "Epoch Number :  900\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.0464973449707\n",
      "Epoch Number :  901\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  44.02093505859375\n",
      "Epoch Number :  902\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.99591827392578\n",
      "Epoch Number :  903\n",
      "\t Training accuracy:  79.30396149574231\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.977684020996094\n",
      "Epoch Number :  904\n",
      "\t Training accuracy:  79.30396149574231\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.95335006713867\n",
      "Epoch Number :  905\n",
      "\t Training accuracy:  79.30396149574231\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.929603576660156\n",
      "Epoch Number :  906\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.90589141845703\n",
      "Epoch Number :  907\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.88180923461914\n",
      "Epoch Number :  908\n",
      "\t Training accuracy:  79.30396149574231\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.856544494628906\n",
      "Epoch Number :  909\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  43.83209991455078\n",
      "Epoch Number :  910\n",
      "\t Training accuracy:  79.26693817104776\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.807029724121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  911\n",
      "\t Training accuracy:  79.34098482043687\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.783287048339844\n",
      "Epoch Number :  912\n",
      "\t Training accuracy:  79.37800814513143\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.75893783569336\n",
      "Epoch Number :  913\n",
      "\t Training accuracy:  79.37800814513143\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.73527526855469\n",
      "Epoch Number :  914\n",
      "\t Training accuracy:  79.37800814513143\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.71078109741211\n",
      "Epoch Number :  915\n",
      "\t Training accuracy:  79.37800814513143\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.68555450439453\n",
      "Epoch Number :  916\n",
      "\t Training accuracy:  79.37800814513143\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.66144561767578\n",
      "Epoch Number :  917\n",
      "\t Training accuracy:  79.41503146982599\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.637351989746094\n",
      "Epoch Number :  918\n",
      "\t Training accuracy:  79.48907811921511\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.612831115722656\n",
      "Epoch Number :  919\n",
      "\t Training accuracy:  79.48907811921511\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.58884048461914\n",
      "Epoch Number :  920\n",
      "\t Training accuracy:  79.56312476860423\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.56504440307617\n",
      "Epoch Number :  921\n",
      "\t Training accuracy:  79.60014809329878\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.54134750366211\n",
      "Epoch Number :  922\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.51835632324219\n",
      "Epoch Number :  923\n",
      "\t Training accuracy:  79.60014809329878\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.49722671508789\n",
      "Epoch Number :  924\n",
      "\t Training accuracy:  79.67419474268789\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.47377395629883\n",
      "Epoch Number :  925\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.450984954833984\n",
      "Epoch Number :  926\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.42723083496094\n",
      "Epoch Number :  927\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.40294647216797\n",
      "Epoch Number :  928\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.379852294921875\n",
      "Epoch Number :  929\n",
      "\t Training accuracy:  79.63717141799333\n",
      "\t Validation accuracy  75.69444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.356449127197266\n",
      "Epoch Number :  930\n",
      "\t Training accuracy:  79.748241392077\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.33304214477539\n",
      "Epoch Number :  931\n",
      "\t Training accuracy:  79.748241392077\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.30986022949219\n",
      "Epoch Number :  932\n",
      "\t Training accuracy:  79.78526471677156\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.28681182861328\n",
      "Epoch Number :  933\n",
      "\t Training accuracy:  79.78526471677156\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.264183044433594\n",
      "Epoch Number :  934\n",
      "\t Training accuracy:  79.78526471677156\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.24165344238281\n",
      "Epoch Number :  935\n",
      "\t Training accuracy:  79.82228804146612\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.21886444091797\n",
      "Epoch Number :  936\n",
      "\t Training accuracy:  79.78526471677156\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.1956787109375\n",
      "Epoch Number :  937\n",
      "\t Training accuracy:  79.78526471677156\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.1729850769043\n",
      "Epoch Number :  938\n",
      "\t Training accuracy:  79.82228804146612\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.15107345581055\n",
      "Epoch Number :  939\n",
      "\t Training accuracy:  79.89633469085524\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.44386672973633\n",
      "Epoch Number :  940\n",
      "\t Training accuracy:  79.9333580155498\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.10694122314453\n",
      "Epoch Number :  941\n",
      "\t Training accuracy:  79.97038134024436\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.08444595336914\n",
      "Epoch Number :  942\n",
      "\t Training accuracy:  79.97038134024436\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.06261444091797\n",
      "Epoch Number :  943\n",
      "\t Training accuracy:  80.00740466493892\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.041053771972656\n",
      "Epoch Number :  944\n",
      "\t Training accuracy:  80.04442798963346\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  43.020408630371094\n",
      "Epoch Number :  945\n",
      "\t Training accuracy:  80.04442798963346\n",
      "\t Validation accuracy  76.38888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.99891662597656\n",
      "Epoch Number :  946\n",
      "\t Training accuracy:  80.08145131432802\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.97685241699219\n",
      "Epoch Number :  947\n",
      "\t Training accuracy:  80.08145131432802\n",
      "\t Validation accuracy  77.08333333333333\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.9559440612793\n",
      "Epoch Number :  948\n",
      "\t Training accuracy:  80.15549796371714\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.934852600097656\n",
      "Epoch Number :  949\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.91375732421875\n",
      "Epoch Number :  950\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.89225387573242\n",
      "Epoch Number :  951\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.87138748168945\n",
      "Epoch Number :  952\n",
      "\t Training accuracy:  80.08145131432802\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  42.84993362426758\n",
      "Epoch Number :  953\n",
      "\t Training accuracy:  80.08145131432802\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.82804870605469\n",
      "Epoch Number :  954\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.805965423583984\n",
      "Epoch Number :  955\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.78364181518555\n",
      "Epoch Number :  956\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.7620964050293\n",
      "Epoch Number :  957\n",
      "\t Training accuracy:  80.15549796371714\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.74111557006836\n",
      "Epoch Number :  958\n",
      "\t Training accuracy:  80.15549796371714\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.72066116333008\n",
      "Epoch Number :  959\n",
      "\t Training accuracy:  80.11847463902258\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.70035171508789\n",
      "Epoch Number :  960\n",
      "\t Training accuracy:  80.1925212884117\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.6800537109375\n",
      "Epoch Number :  961\n",
      "\t Training accuracy:  80.15549796371714\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.65966796875\n",
      "Epoch Number :  962\n",
      "\t Training accuracy:  80.1925212884117\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.638580322265625\n",
      "Epoch Number :  963\n",
      "\t Training accuracy:  80.1925212884117\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.617469787597656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  964\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.59572219848633\n",
      "Epoch Number :  965\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.57555389404297\n",
      "Epoch Number :  966\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.55488204956055\n",
      "Epoch Number :  967\n",
      "\t Training accuracy:  80.22954461310626\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.84965515136719\n",
      "Epoch Number :  968\n",
      "\t Training accuracy:  80.1925212884117\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.82807922363281\n",
      "Epoch Number :  969\n",
      "\t Training accuracy:  80.1925212884117\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.49111557006836\n",
      "Epoch Number :  970\n",
      "\t Training accuracy:  80.22954461310626\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.470001220703125\n",
      "Epoch Number :  971\n",
      "\t Training accuracy:  80.22954461310626\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.44912338256836\n",
      "Epoch Number :  972\n",
      "\t Training accuracy:  80.22954461310626\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.42890167236328\n",
      "Epoch Number :  973\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.4081916809082\n",
      "Epoch Number :  974\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.38674545288086\n",
      "Epoch Number :  975\n",
      "\t Training accuracy:  80.26656793780082\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.36662673950195\n",
      "Epoch Number :  976\n",
      "\t Training accuracy:  80.34061458718993\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.346435546875\n",
      "Epoch Number :  977\n",
      "\t Training accuracy:  80.41466123657905\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.325679779052734\n",
      "Epoch Number :  978\n",
      "\t Training accuracy:  80.45168456127361\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.30534362792969\n",
      "Epoch Number :  979\n",
      "\t Training accuracy:  80.52573121066271\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.28486633300781\n",
      "Epoch Number :  980\n",
      "\t Training accuracy:  80.59977786005183\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.26275634765625\n",
      "Epoch Number :  981\n",
      "\t Training accuracy:  80.63680118474639\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.24207305908203\n",
      "Epoch Number :  982\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.221656799316406\n",
      "Epoch Number :  983\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.51512908935547\n",
      "Epoch Number :  984\n",
      "\t Training accuracy:  80.7108478341355\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.49436950683594\n",
      "Epoch Number :  985\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.4731559753418\n",
      "Epoch Number :  986\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.13737487792969\n",
      "Epoch Number :  987\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.116641998291016\n",
      "Epoch Number :  988\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.09632873535156\n",
      "Epoch Number :  989\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.07554244995117\n",
      "Epoch Number :  990\n",
      "\t Training accuracy:  80.63680118474639\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.05496597290039\n",
      "Epoch Number :  991\n",
      "\t Training accuracy:  80.67382450944095\n",
      "\t Validation accuracy  77.77777777777777\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.03468704223633\n",
      "Epoch Number :  992\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  42.014095306396484\n",
      "Epoch Number :  993\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.99373245239258\n",
      "Epoch Number :  994\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.97469711303711\n",
      "Epoch Number :  995\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.955421447753906\n",
      "Epoch Number :  996\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.93662643432617\n",
      "Epoch Number :  997\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.917625427246094\n",
      "Epoch Number :  998\n",
      "\t Training accuracy:  80.7108478341355\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.89747619628906\n",
      "Epoch Number :  999\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.875709533691406\n",
      "Epoch Number :  1000\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.85491943359375\n",
      "Epoch Number :  1001\n",
      "\t Training accuracy:  80.74787115883007\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.83409118652344\n",
      "Epoch Number :  1002\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.81352996826172\n",
      "Epoch Number :  1003\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.79249954223633\n",
      "Epoch Number :  1004\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.77251052856445\n",
      "Epoch Number :  1005\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.75217056274414\n",
      "Epoch Number :  1006\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.7308464050293\n",
      "Epoch Number :  1007\n",
      "\t Training accuracy:  80.78489448352462\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.71184158325195\n",
      "Epoch Number :  1008\n",
      "\t Training accuracy:  80.85894113291374\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.6916389465332\n",
      "Epoch Number :  1009\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.670658111572266\n",
      "Epoch Number :  1010\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.64907455444336\n",
      "Epoch Number :  1011\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.626502990722656\n",
      "Epoch Number :  1012\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.60637664794922\n",
      "Epoch Number :  1013\n",
      "\t Training accuracy:  80.93298778230285\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.5858039855957\n",
      "Epoch Number :  1014\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.563533782958984\n",
      "Epoch Number :  1015\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.54152297973633\n",
      "Epoch Number :  1016\n",
      "\t Training accuracy:  80.85894113291374\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.5197868347168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1017\n",
      "\t Training accuracy:  80.85894113291374\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.499629974365234\n",
      "Epoch Number :  1018\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  41.478328704833984\n",
      "Epoch Number :  1019\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.45683288574219\n",
      "Epoch Number :  1020\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.43472671508789\n",
      "Epoch Number :  1021\n",
      "\t Training accuracy:  80.93298778230285\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.413387298583984\n",
      "Epoch Number :  1022\n",
      "\t Training accuracy:  80.89596445760829\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.39204025268555\n",
      "Epoch Number :  1023\n",
      "\t Training accuracy:  80.93298778230285\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.37125778198242\n",
      "Epoch Number :  1024\n",
      "\t Training accuracy:  80.93298778230285\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.35031509399414\n",
      "Epoch Number :  1025\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.32843017578125\n",
      "Epoch Number :  1026\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.307716369628906\n",
      "Epoch Number :  1027\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.28699493408203\n",
      "Epoch Number :  1028\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.26668930053711\n",
      "Epoch Number :  1029\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.24567794799805\n",
      "Epoch Number :  1030\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.22586441040039\n",
      "Epoch Number :  1031\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.206085205078125\n",
      "Epoch Number :  1032\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.185848236083984\n",
      "Epoch Number :  1033\n",
      "\t Training accuracy:  80.9700111069974\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.16649627685547\n",
      "Epoch Number :  1034\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.14759826660156\n",
      "Epoch Number :  1035\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.128334045410156\n",
      "Epoch Number :  1036\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.109596252441406\n",
      "Epoch Number :  1037\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.08903121948242\n",
      "Epoch Number :  1038\n",
      "\t Training accuracy:  81.04405775638652\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.0689811706543\n",
      "Epoch Number :  1039\n",
      "\t Training accuracy:  81.04405775638652\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.049808502197266\n",
      "Epoch Number :  1040\n",
      "\t Training accuracy:  81.04405775638652\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.03068542480469\n",
      "Epoch Number :  1041\n",
      "\t Training accuracy:  81.04405775638652\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  41.01207733154297\n",
      "Epoch Number :  1042\n",
      "\t Training accuracy:  81.04405775638652\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.99314880371094\n",
      "Epoch Number :  1043\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.9735221862793\n",
      "Epoch Number :  1044\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.954124450683594\n",
      "Epoch Number :  1045\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.93386459350586\n",
      "Epoch Number :  1046\n",
      "\t Training accuracy:  81.00703443169196\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.913936614990234\n",
      "Epoch Number :  1047\n",
      "\t Training accuracy:  81.08108108108108\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.89486312866211\n",
      "Epoch Number :  1048\n",
      "\t Training accuracy:  81.11810440577564\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.874755859375\n",
      "Epoch Number :  1049\n",
      "\t Training accuracy:  81.11810440577564\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.85515213012695\n",
      "Epoch Number :  1050\n",
      "\t Training accuracy:  81.1551277304702\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.836631774902344\n",
      "Epoch Number :  1051\n",
      "\t Training accuracy:  81.19215105516476\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.81755447387695\n",
      "Epoch Number :  1052\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.79811477661133\n",
      "Epoch Number :  1053\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.77960205078125\n",
      "Epoch Number :  1054\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.76085662841797\n",
      "Epoch Number :  1055\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.74258804321289\n",
      "Epoch Number :  1056\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.7237663269043\n",
      "Epoch Number :  1057\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.70500946044922\n",
      "Epoch Number :  1058\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.68570327758789\n",
      "Epoch Number :  1059\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.66679382324219\n",
      "Epoch Number :  1060\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.648136138916016\n",
      "Epoch Number :  1061\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.629241943359375\n",
      "Epoch Number :  1062\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.61131286621094\n",
      "Epoch Number :  1063\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.59349822998047\n",
      "Epoch Number :  1064\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.572914123535156\n",
      "Epoch Number :  1065\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.551719665527344\n",
      "Epoch Number :  1066\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  40.53037643432617\n",
      "Epoch Number :  1067\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.51036071777344\n",
      "Epoch Number :  1068\n",
      "\t Training accuracy:  81.37726767863754\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.490291595458984\n",
      "Epoch Number :  1069\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.47003173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1070\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.4478874206543\n",
      "Epoch Number :  1071\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.42793655395508\n",
      "Epoch Number :  1072\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.409088134765625\n",
      "Epoch Number :  1073\n",
      "\t Training accuracy:  81.30322102924842\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.388771057128906\n",
      "Epoch Number :  1074\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.36883544921875\n",
      "Epoch Number :  1075\n",
      "\t Training accuracy:  81.26619770455387\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.34821319580078\n",
      "Epoch Number :  1076\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.32961654663086\n",
      "Epoch Number :  1077\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.31085205078125\n",
      "Epoch Number :  1078\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.290382385253906\n",
      "Epoch Number :  1079\n",
      "\t Training accuracy:  81.34024435394298\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.27186584472656\n",
      "Epoch Number :  1080\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.252567291259766\n",
      "Epoch Number :  1081\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.23466110229492\n",
      "Epoch Number :  1082\n",
      "\t Training accuracy:  81.45131432802665\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.21528244018555\n",
      "Epoch Number :  1083\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.19539260864258\n",
      "Epoch Number :  1084\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.17593765258789\n",
      "Epoch Number :  1085\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.15579605102539\n",
      "Epoch Number :  1086\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.1356086730957\n",
      "Epoch Number :  1087\n",
      "\t Training accuracy:  81.4142910033321\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.11768341064453\n",
      "Epoch Number :  1088\n",
      "\t Training accuracy:  81.48833765272121\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.10005187988281\n",
      "Epoch Number :  1089\n",
      "\t Training accuracy:  81.52536097741577\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.079811096191406\n",
      "Epoch Number :  1090\n",
      "\t Training accuracy:  81.52536097741577\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.05975341796875\n",
      "Epoch Number :  1091\n",
      "\t Training accuracy:  81.56238430211033\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.04052734375\n",
      "Epoch Number :  1092\n",
      "\t Training accuracy:  81.56238430211033\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  40.01988220214844\n",
      "Epoch Number :  1093\n",
      "\t Training accuracy:  81.56238430211033\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.99983215332031\n",
      "Epoch Number :  1094\n",
      "\t Training accuracy:  81.56238430211033\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.98029327392578\n",
      "Epoch Number :  1095\n",
      "\t Training accuracy:  81.59940762680489\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.96094512939453\n",
      "Epoch Number :  1096\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.94090270996094\n",
      "Epoch Number :  1097\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.921173095703125\n",
      "Epoch Number :  1098\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.90093994140625\n",
      "Epoch Number :  1099\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.880706787109375\n",
      "Epoch Number :  1100\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.86156463623047\n",
      "Epoch Number :  1101\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.84218978881836\n",
      "Epoch Number :  1102\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.82307815551758\n",
      "Epoch Number :  1103\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.803279876708984\n",
      "Epoch Number :  1104\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.78364181518555\n",
      "Epoch Number :  1105\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.76353454589844\n",
      "Epoch Number :  1106\n",
      "\t Training accuracy:  81.67345427619401\n",
      "\t Validation accuracy  78.47222222222223\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.74333953857422\n",
      "Epoch Number :  1107\n",
      "\t Training accuracy:  81.71047760088857\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.7238655090332\n",
      "Epoch Number :  1108\n",
      "\t Training accuracy:  81.74750092558311\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.703460693359375\n",
      "Epoch Number :  1109\n",
      "\t Training accuracy:  81.74750092558311\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.682979583740234\n",
      "Epoch Number :  1110\n",
      "\t Training accuracy:  81.74750092558311\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.66245651245117\n",
      "Epoch Number :  1111\n",
      "\t Training accuracy:  81.78452425027767\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.64295196533203\n",
      "Epoch Number :  1112\n",
      "\t Training accuracy:  81.78452425027767\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.62254333496094\n",
      "Epoch Number :  1113\n",
      "\t Training accuracy:  81.82154757497223\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.6017951965332\n",
      "Epoch Number :  1114\n",
      "\t Training accuracy:  81.85857089966679\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.576148986816406\n",
      "Epoch Number :  1115\n",
      "\t Training accuracy:  81.89559422436135\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.55656051635742\n",
      "Epoch Number :  1116\n",
      "\t Training accuracy:  81.9326175490559\n",
      "\t Validation accuracy  79.16666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.53557586669922\n",
      "Epoch Number :  1117\n",
      "\t Training accuracy:  82.00666419844502\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.514442443847656\n",
      "Epoch Number :  1118\n",
      "\t Training accuracy:  81.9326175490559\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.49442672729492\n",
      "Epoch Number :  1119\n",
      "\t Training accuracy:  81.9326175490559\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.47350311279297\n",
      "Epoch Number :  1120\n",
      "\t Training accuracy:  81.96964087375046\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.452781677246094\n",
      "Epoch Number :  1121\n",
      "\t Training accuracy:  81.9326175490559\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.43251419067383\n",
      "Epoch Number :  1122\n",
      "\t Training accuracy:  81.9326175490559\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.41206741333008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1123\n",
      "\t Training accuracy:  82.00666419844502\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.392852783203125\n",
      "Epoch Number :  1124\n",
      "\t Training accuracy:  82.00666419844502\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.3721923828125\n",
      "Epoch Number :  1125\n",
      "\t Training accuracy:  82.00666419844502\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.3514404296875\n",
      "Epoch Number :  1126\n",
      "\t Training accuracy:  82.00666419844502\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.33070755004883\n",
      "Epoch Number :  1127\n",
      "\t Training accuracy:  82.04368752313958\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.30996322631836\n",
      "Epoch Number :  1128\n",
      "\t Training accuracy:  82.04368752313958\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.2906494140625\n",
      "Epoch Number :  1129\n",
      "\t Training accuracy:  82.04368752313958\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.27130126953125\n",
      "Epoch Number :  1130\n",
      "\t Training accuracy:  82.04368752313958\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.25161361694336\n",
      "Epoch Number :  1131\n",
      "\t Training accuracy:  82.08071084783414\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.232051849365234\n",
      "Epoch Number :  1132\n",
      "\t Training accuracy:  82.08071084783414\n",
      "\t Validation accuracy  80.55555555555556\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  39.212074279785156\n",
      "Epoch Number :  1133\n",
      "\t Training accuracy:  82.1177341725287\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.1920166015625\n",
      "Epoch Number :  1134\n",
      "\t Training accuracy:  82.1177341725287\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.17281723022461\n",
      "Epoch Number :  1135\n",
      "\t Training accuracy:  82.1177341725287\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.15378952026367\n",
      "Epoch Number :  1136\n",
      "\t Training accuracy:  82.15475749722324\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.13435363769531\n",
      "Epoch Number :  1137\n",
      "\t Training accuracy:  82.15475749722324\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.11459732055664\n",
      "Epoch Number :  1138\n",
      "\t Training accuracy:  82.15475749722324\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.09458923339844\n",
      "Epoch Number :  1139\n",
      "\t Training accuracy:  82.1917808219178\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.075767517089844\n",
      "Epoch Number :  1140\n",
      "\t Training accuracy:  82.1917808219178\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.05636978149414\n",
      "Epoch Number :  1141\n",
      "\t Training accuracy:  82.1917808219178\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.03665542602539\n",
      "Epoch Number :  1142\n",
      "\t Training accuracy:  82.1917808219178\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  39.016841888427734\n",
      "Epoch Number :  1143\n",
      "\t Training accuracy:  82.22880414661236\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  38.99686050415039\n",
      "Epoch Number :  1144\n",
      "\t Training accuracy:  82.26582747130692\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  38.977256774902344\n",
      "Epoch Number :  1145\n",
      "\t Training accuracy:  82.1917808219178\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  38.958499908447266\n",
      "Epoch Number :  1146\n",
      "\t Training accuracy:  82.30285079600148\n",
      "\t Validation accuracy  81.25\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  38.93881607055664\n",
      "Epoch Number :  1147\n",
      "\t Training accuracy:  82.30285079600148\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.92060470581055\n",
      "Epoch Number :  1148\n",
      "\t Training accuracy:  82.33987412069604\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.90156173706055\n",
      "Epoch Number :  1149\n",
      "\t Training accuracy:  82.3768974453906\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.882633209228516\n",
      "Epoch Number :  1150\n",
      "\t Training accuracy:  82.41392077008516\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.86327362060547\n",
      "Epoch Number :  1151\n",
      "\t Training accuracy:  82.41392077008516\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.8441047668457\n",
      "Epoch Number :  1152\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.82480239868164\n",
      "Epoch Number :  1153\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.80581283569336\n",
      "Epoch Number :  1154\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.7861328125\n",
      "Epoch Number :  1155\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.766178131103516\n",
      "Epoch Number :  1156\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.74595260620117\n",
      "Epoch Number :  1157\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.725059509277344\n",
      "Epoch Number :  1158\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.704002380371094\n",
      "Epoch Number :  1159\n",
      "\t Training accuracy:  82.45094409477971\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.682701110839844\n",
      "Epoch Number :  1160\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.66239547729492\n",
      "Epoch Number :  1161\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.64268112182617\n",
      "Epoch Number :  1162\n",
      "\t Training accuracy:  82.52499074416883\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.621822357177734\n",
      "Epoch Number :  1163\n",
      "\t Training accuracy:  82.52499074416883\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.60176467895508\n",
      "Epoch Number :  1164\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.58253479003906\n",
      "Epoch Number :  1165\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.562255859375\n",
      "Epoch Number :  1166\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.54161071777344\n",
      "Epoch Number :  1167\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.52186584472656\n",
      "Epoch Number :  1168\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.50230407714844\n",
      "Epoch Number :  1169\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.4819450378418\n",
      "Epoch Number :  1170\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.46234893798828\n",
      "Epoch Number :  1171\n",
      "\t Training accuracy:  82.48796741947427\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.44259262084961\n",
      "Epoch Number :  1172\n",
      "\t Training accuracy:  82.52499074416883\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.4245719909668\n",
      "Epoch Number :  1173\n",
      "\t Training accuracy:  82.52499074416883\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.40541076660156\n",
      "Epoch Number :  1174\n",
      "\t Training accuracy:  82.56201406886339\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.385826110839844\n",
      "Epoch Number :  1175\n",
      "\t Training accuracy:  82.59903739355794\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.36614990234375\n",
      "Epoch Number :  1176\n",
      "\t Training accuracy:  82.59903739355794\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.346927642822266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1177\n",
      "\t Training accuracy:  82.59903739355794\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.32667541503906\n",
      "Epoch Number :  1178\n",
      "\t Training accuracy:  82.67308404294705\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.307064056396484\n",
      "Epoch Number :  1179\n",
      "\t Training accuracy:  82.67308404294705\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.28664016723633\n",
      "Epoch Number :  1180\n",
      "\t Training accuracy:  82.71010736764161\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.26741027832031\n",
      "Epoch Number :  1181\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.2475700378418\n",
      "Epoch Number :  1182\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.22685241699219\n",
      "Epoch Number :  1183\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.2051887512207\n",
      "Epoch Number :  1184\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.18525695800781\n",
      "Epoch Number :  1185\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.165157318115234\n",
      "Epoch Number :  1186\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  66.0\n",
      "\t Epoch Loss  38.14384460449219\n",
      "Epoch Number :  1187\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  66.0\n",
      "\t Epoch Loss  38.12199020385742\n",
      "Epoch Number :  1188\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  66.0\n",
      "\t Epoch Loss  38.10079574584961\n",
      "Epoch Number :  1189\n",
      "\t Training accuracy:  82.74713069233617\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.080589294433594\n",
      "Epoch Number :  1190\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.05976104736328\n",
      "Epoch Number :  1191\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.039520263671875\n",
      "Epoch Number :  1192\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  38.018924713134766\n",
      "Epoch Number :  1193\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.9986572265625\n",
      "Epoch Number :  1194\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.977996826171875\n",
      "Epoch Number :  1195\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.958309173583984\n",
      "Epoch Number :  1196\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.9371452331543\n",
      "Epoch Number :  1197\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.91617202758789\n",
      "Epoch Number :  1198\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.89545440673828\n",
      "Epoch Number :  1199\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.875858306884766\n",
      "Epoch Number :  1200\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.85634231567383\n",
      "Epoch Number :  1201\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.836368560791016\n",
      "Epoch Number :  1202\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.817283630371094\n",
      "Epoch Number :  1203\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.79928207397461\n",
      "Epoch Number :  1204\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.7795524597168\n",
      "Epoch Number :  1205\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.75918197631836\n",
      "Epoch Number :  1206\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.73960494995117\n",
      "Epoch Number :  1207\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.719058990478516\n",
      "Epoch Number :  1208\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.699283599853516\n",
      "Epoch Number :  1209\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.68029022216797\n",
      "Epoch Number :  1210\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.66082000732422\n",
      "Epoch Number :  1211\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.64244842529297\n",
      "Epoch Number :  1212\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.62458801269531\n",
      "Epoch Number :  1213\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.60588455200195\n",
      "Epoch Number :  1214\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.58729553222656\n",
      "Epoch Number :  1215\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.56970977783203\n",
      "Epoch Number :  1216\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.55107498168945\n",
      "Epoch Number :  1217\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.53234100341797\n",
      "Epoch Number :  1218\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.5123176574707\n",
      "Epoch Number :  1219\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.49233627319336\n",
      "Epoch Number :  1220\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.473052978515625\n",
      "Epoch Number :  1221\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.454071044921875\n",
      "Epoch Number :  1222\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  65.0\n",
      "\t Epoch Loss  37.43489074707031\n",
      "Epoch Number :  1223\n",
      "\t Training accuracy:  82.96927064050352\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.4154052734375\n",
      "Epoch Number :  1224\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.39605712890625\n",
      "Epoch Number :  1225\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.376522064208984\n",
      "Epoch Number :  1226\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.355865478515625\n",
      "Epoch Number :  1227\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.33541488647461\n",
      "Epoch Number :  1228\n",
      "\t Training accuracy:  82.8952239911144\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.31290054321289\n",
      "Epoch Number :  1229\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.29027557373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1230\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.26848220825195\n",
      "Epoch Number :  1231\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.24675369262695\n",
      "Epoch Number :  1232\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.22551727294922\n",
      "Epoch Number :  1233\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.204280853271484\n",
      "Epoch Number :  1234\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.18330383300781\n",
      "Epoch Number :  1235\n",
      "\t Training accuracy:  82.82117734172529\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.163272857666016\n",
      "Epoch Number :  1236\n",
      "\t Training accuracy:  82.85820066641985\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.14304733276367\n",
      "Epoch Number :  1237\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.123191833496094\n",
      "Epoch Number :  1238\n",
      "\t Training accuracy:  82.93224731580897\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.103599548339844\n",
      "Epoch Number :  1239\n",
      "\t Training accuracy:  83.00629396519807\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.083343505859375\n",
      "Epoch Number :  1240\n",
      "\t Training accuracy:  83.04331728989263\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.06294250488281\n",
      "Epoch Number :  1241\n",
      "\t Training accuracy:  83.04331728989263\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.04335021972656\n",
      "Epoch Number :  1242\n",
      "\t Training accuracy:  83.00629396519807\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.02358627319336\n",
      "Epoch Number :  1243\n",
      "\t Training accuracy:  83.04331728989263\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  37.003639221191406\n",
      "Epoch Number :  1244\n",
      "\t Training accuracy:  83.08034061458719\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.984737396240234\n",
      "Epoch Number :  1245\n",
      "\t Training accuracy:  83.11736393928174\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.96426773071289\n",
      "Epoch Number :  1246\n",
      "\t Training accuracy:  83.1543872639763\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.94426345825195\n",
      "Epoch Number :  1247\n",
      "\t Training accuracy:  83.1543872639763\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.92485046386719\n",
      "Epoch Number :  1248\n",
      "\t Training accuracy:  83.19141058867086\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.90509033203125\n",
      "Epoch Number :  1249\n",
      "\t Training accuracy:  83.19141058867086\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.88565444946289\n",
      "Epoch Number :  1250\n",
      "\t Training accuracy:  83.22843391336542\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.865928649902344\n",
      "Epoch Number :  1251\n",
      "\t Training accuracy:  83.22843391336542\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.84617614746094\n",
      "Epoch Number :  1252\n",
      "\t Training accuracy:  83.22843391336542\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.82658386230469\n",
      "Epoch Number :  1253\n",
      "\t Training accuracy:  83.26545723805998\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.80720520019531\n",
      "Epoch Number :  1254\n",
      "\t Training accuracy:  83.26545723805998\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.7884521484375\n",
      "Epoch Number :  1255\n",
      "\t Training accuracy:  83.26545723805998\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.76941680908203\n",
      "Epoch Number :  1256\n",
      "\t Training accuracy:  83.26545723805998\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.750152587890625\n",
      "Epoch Number :  1257\n",
      "\t Training accuracy:  83.30248056275454\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.731109619140625\n",
      "Epoch Number :  1258\n",
      "\t Training accuracy:  83.3395038874491\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.71150588989258\n",
      "Epoch Number :  1259\n",
      "\t Training accuracy:  83.3395038874491\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.693214416503906\n",
      "Epoch Number :  1260\n",
      "\t Training accuracy:  83.3395038874491\n",
      "\t Validation accuracy  81.94444444444444\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.67401885986328\n",
      "Epoch Number :  1261\n",
      "\t Training accuracy:  83.37652721214366\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.65559768676758\n",
      "Epoch Number :  1262\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.63690948486328\n",
      "Epoch Number :  1263\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.61861801147461\n",
      "Epoch Number :  1264\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.60032653808594\n",
      "Epoch Number :  1265\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.58179473876953\n",
      "Epoch Number :  1266\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.56358337402344\n",
      "Epoch Number :  1267\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.544883728027344\n",
      "Epoch Number :  1268\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.52669143676758\n",
      "Epoch Number :  1269\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.508113861083984\n",
      "Epoch Number :  1270\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.49007797241211\n",
      "Epoch Number :  1271\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.47196960449219\n",
      "Epoch Number :  1272\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.45387649536133\n",
      "Epoch Number :  1273\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.436187744140625\n",
      "Epoch Number :  1274\n",
      "\t Training accuracy:  83.4135505368382\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.418521881103516\n",
      "Epoch Number :  1275\n",
      "\t Training accuracy:  83.45057386153276\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.400726318359375\n",
      "Epoch Number :  1276\n",
      "\t Training accuracy:  83.48759718622732\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.38240432739258\n",
      "Epoch Number :  1277\n",
      "\t Training accuracy:  83.52462051092188\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.36492156982422\n",
      "Epoch Number :  1278\n",
      "\t Training accuracy:  83.52462051092188\n",
      "\t Validation accuracy  82.63888888888889\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.34635925292969\n",
      "Epoch Number :  1279\n",
      "\t Training accuracy:  83.56164383561644\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.32889938354492\n",
      "Epoch Number :  1280\n",
      "\t Training accuracy:  83.56164383561644\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.31169509887695\n",
      "Epoch Number :  1281\n",
      "\t Training accuracy:  83.598667160311\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.294281005859375\n",
      "Epoch Number :  1282\n",
      "\t Training accuracy:  83.67271380970011\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.2765998840332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1283\n",
      "\t Training accuracy:  83.63569048500555\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.2590217590332\n",
      "Epoch Number :  1284\n",
      "\t Training accuracy:  83.67271380970011\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.24171829223633\n",
      "Epoch Number :  1285\n",
      "\t Training accuracy:  83.63569048500555\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.22421646118164\n",
      "Epoch Number :  1286\n",
      "\t Training accuracy:  83.67271380970011\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.206722259521484\n",
      "Epoch Number :  1287\n",
      "\t Training accuracy:  83.74676045908923\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.1898078918457\n",
      "Epoch Number :  1288\n",
      "\t Training accuracy:  83.70973713439467\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.172359466552734\n",
      "Epoch Number :  1289\n",
      "\t Training accuracy:  83.70973713439467\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.154335021972656\n",
      "Epoch Number :  1290\n",
      "\t Training accuracy:  83.74676045908923\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.13572311401367\n",
      "Epoch Number :  1291\n",
      "\t Training accuracy:  83.78378378378379\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.11798095703125\n",
      "Epoch Number :  1292\n",
      "\t Training accuracy:  83.78378378378379\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.10061264038086\n",
      "Epoch Number :  1293\n",
      "\t Training accuracy:  83.82080710847835\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.08354949951172\n",
      "Epoch Number :  1294\n",
      "\t Training accuracy:  83.78378378378379\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.0659294128418\n",
      "Epoch Number :  1295\n",
      "\t Training accuracy:  83.78378378378379\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.04762268066406\n",
      "Epoch Number :  1296\n",
      "\t Training accuracy:  83.78378378378379\n",
      "\t Validation accuracy  83.33333333333333\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.02968978881836\n",
      "Epoch Number :  1297\n",
      "\t Training accuracy:  83.82080710847835\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  36.011253356933594\n",
      "Epoch Number :  1298\n",
      "\t Training accuracy:  83.82080710847835\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.992801666259766\n",
      "Epoch Number :  1299\n",
      "\t Training accuracy:  83.82080710847835\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.97384262084961\n",
      "Epoch Number :  1300\n",
      "\t Training accuracy:  83.8578304331729\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.9557991027832\n",
      "Epoch Number :  1301\n",
      "\t Training accuracy:  83.8578304331729\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.937767028808594\n",
      "Epoch Number :  1302\n",
      "\t Training accuracy:  83.8578304331729\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.919715881347656\n",
      "Epoch Number :  1303\n",
      "\t Training accuracy:  83.89485375786745\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.90102767944336\n",
      "Epoch Number :  1304\n",
      "\t Training accuracy:  83.93187708256201\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.88191604614258\n",
      "Epoch Number :  1305\n",
      "\t Training accuracy:  83.93187708256201\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.86309051513672\n",
      "Epoch Number :  1306\n",
      "\t Training accuracy:  83.93187708256201\n",
      "\t Validation accuracy  84.72222222222223\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.84488296508789\n",
      "Epoch Number :  1307\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.826324462890625\n",
      "Epoch Number :  1308\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.80797576904297\n",
      "Epoch Number :  1309\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.789161682128906\n",
      "Epoch Number :  1310\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.76964569091797\n",
      "Epoch Number :  1311\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  64.0\n",
      "\t Epoch Loss  35.751129150390625\n",
      "Epoch Number :  1312\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  35.732540130615234\n",
      "Epoch Number :  1313\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  63.0\n",
      "\t Epoch Loss  35.71459197998047\n",
      "Epoch Number :  1314\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.695735931396484\n",
      "Epoch Number :  1315\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.67713165283203\n",
      "Epoch Number :  1316\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.6574592590332\n",
      "Epoch Number :  1317\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.63850784301758\n",
      "Epoch Number :  1318\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.61961364746094\n",
      "Epoch Number :  1319\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.599647521972656\n",
      "Epoch Number :  1320\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.5804557800293\n",
      "Epoch Number :  1321\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.56110382080078\n",
      "Epoch Number :  1322\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.542747497558594\n",
      "Epoch Number :  1323\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.524208068847656\n",
      "Epoch Number :  1324\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.506202697753906\n",
      "Epoch Number :  1325\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.48750305175781\n",
      "Epoch Number :  1326\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.469120025634766\n",
      "Epoch Number :  1327\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.45159149169922\n",
      "Epoch Number :  1328\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.43342590332031\n",
      "Epoch Number :  1329\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.414737701416016\n",
      "Epoch Number :  1330\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.396278381347656\n",
      "Epoch Number :  1331\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.37872314453125\n",
      "Epoch Number :  1332\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.3611946105957\n",
      "Epoch Number :  1333\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.34278106689453\n",
      "Epoch Number :  1334\n",
      "\t Training accuracy:  83.96890040725657\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  35.32490158081055\n",
      "Epoch Number :  1335\n",
      "\t Training accuracy:  83.96890040725657\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.306549072265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1336\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.288455963134766\n",
      "Epoch Number :  1337\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.270484924316406\n",
      "Epoch Number :  1338\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.25250244140625\n",
      "Epoch Number :  1339\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.23387145996094\n",
      "Epoch Number :  1340\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.216400146484375\n",
      "Epoch Number :  1341\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.19898986816406\n",
      "Epoch Number :  1342\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.18096160888672\n",
      "Epoch Number :  1343\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.1627197265625\n",
      "Epoch Number :  1344\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.145423889160156\n",
      "Epoch Number :  1345\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.12799835205078\n",
      "Epoch Number :  1346\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.11117935180664\n",
      "Epoch Number :  1347\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.094749450683594\n",
      "Epoch Number :  1348\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.076881408691406\n",
      "Epoch Number :  1349\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.05936813354492\n",
      "Epoch Number :  1350\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.041839599609375\n",
      "Epoch Number :  1351\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.024330139160156\n",
      "Epoch Number :  1352\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  35.00618362426758\n",
      "Epoch Number :  1353\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.988548278808594\n",
      "Epoch Number :  1354\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.97092056274414\n",
      "Epoch Number :  1355\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.953182220458984\n",
      "Epoch Number :  1356\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.93563461303711\n",
      "Epoch Number :  1357\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.91757583618164\n",
      "Epoch Number :  1358\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.9002799987793\n",
      "Epoch Number :  1359\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.882347106933594\n",
      "Epoch Number :  1360\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.86431121826172\n",
      "Epoch Number :  1361\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.84644317626953\n",
      "Epoch Number :  1362\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.8289680480957\n",
      "Epoch Number :  1363\n",
      "\t Training accuracy:  84.04294705664569\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.81197738647461\n",
      "Epoch Number :  1364\n",
      "\t Training accuracy:  84.00592373195113\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.7949104309082\n",
      "Epoch Number :  1365\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.77763366699219\n",
      "Epoch Number :  1366\n",
      "\t Training accuracy:  84.07997038134025\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.760032653808594\n",
      "Epoch Number :  1367\n",
      "\t Training accuracy:  84.1169937060348\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.74247741699219\n",
      "Epoch Number :  1368\n",
      "\t Training accuracy:  84.15401703072936\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.72550964355469\n",
      "Epoch Number :  1369\n",
      "\t Training accuracy:  84.15401703072936\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.70745086669922\n",
      "Epoch Number :  1370\n",
      "\t Training accuracy:  84.15401703072936\n",
      "\t Validation accuracy  85.41666666666667\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.68890380859375\n",
      "Epoch Number :  1371\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.671234130859375\n",
      "Epoch Number :  1372\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.65365219116211\n",
      "Epoch Number :  1373\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.63510513305664\n",
      "Epoch Number :  1374\n",
      "\t Training accuracy:  84.22806368011848\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.6174201965332\n",
      "Epoch Number :  1375\n",
      "\t Training accuracy:  84.22806368011848\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.60014343261719\n",
      "Epoch Number :  1376\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.58277893066406\n",
      "Epoch Number :  1377\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.565086364746094\n",
      "Epoch Number :  1378\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.54695510864258\n",
      "Epoch Number :  1379\n",
      "\t Training accuracy:  84.22806368011848\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.52897644042969\n",
      "Epoch Number :  1380\n",
      "\t Training accuracy:  84.22806368011848\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.51145935058594\n",
      "Epoch Number :  1381\n",
      "\t Training accuracy:  84.22806368011848\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.49330520629883\n",
      "Epoch Number :  1382\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.475154876708984\n",
      "Epoch Number :  1383\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.457916259765625\n",
      "Epoch Number :  1384\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.44061279296875\n",
      "Epoch Number :  1385\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.423770904541016\n",
      "Epoch Number :  1386\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.40673065185547\n",
      "Epoch Number :  1387\n",
      "\t Training accuracy:  84.19104035542392\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.38945007324219\n",
      "Epoch Number :  1388\n",
      "\t Training accuracy:  84.26508700481303\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.371917724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1389\n",
      "\t Training accuracy:  84.30211032950758\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.35350799560547\n",
      "Epoch Number :  1390\n",
      "\t Training accuracy:  84.3761569788967\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.335113525390625\n",
      "Epoch Number :  1391\n",
      "\t Training accuracy:  84.3761569788967\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.31758117675781\n",
      "Epoch Number :  1392\n",
      "\t Training accuracy:  84.3761569788967\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.3003044128418\n",
      "Epoch Number :  1393\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.28298568725586\n",
      "Epoch Number :  1394\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.26572036743164\n",
      "Epoch Number :  1395\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.24831008911133\n",
      "Epoch Number :  1396\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.2305793762207\n",
      "Epoch Number :  1397\n",
      "\t Training accuracy:  84.3761569788967\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.21357345581055\n",
      "Epoch Number :  1398\n",
      "\t Training accuracy:  84.3761569788967\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.195960998535156\n",
      "Epoch Number :  1399\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.17915344238281\n",
      "Epoch Number :  1400\n",
      "\t Training accuracy:  84.41318030359126\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.1622200012207\n",
      "Epoch Number :  1401\n",
      "\t Training accuracy:  84.45020362828582\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.14619064331055\n",
      "Epoch Number :  1402\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.128990173339844\n",
      "Epoch Number :  1403\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.11237335205078\n",
      "Epoch Number :  1404\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.096134185791016\n",
      "Epoch Number :  1405\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.07905960083008\n",
      "Epoch Number :  1406\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.06269836425781\n",
      "Epoch Number :  1407\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.04652786254883\n",
      "Epoch Number :  1408\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.02919387817383\n",
      "Epoch Number :  1409\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  34.01266860961914\n",
      "Epoch Number :  1410\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.996219635009766\n",
      "Epoch Number :  1411\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.97975158691406\n",
      "Epoch Number :  1412\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.9628791809082\n",
      "Epoch Number :  1413\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.9459114074707\n",
      "Epoch Number :  1414\n",
      "\t Training accuracy:  84.45020362828582\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.92909240722656\n",
      "Epoch Number :  1415\n",
      "\t Training accuracy:  84.45020362828582\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.91182327270508\n",
      "Epoch Number :  1416\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.89430236816406\n",
      "Epoch Number :  1417\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.877193450927734\n",
      "Epoch Number :  1418\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.86037826538086\n",
      "Epoch Number :  1419\n",
      "\t Training accuracy:  84.48722695298038\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.843421936035156\n",
      "Epoch Number :  1420\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.827049255371094\n",
      "Epoch Number :  1421\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.80968475341797\n",
      "Epoch Number :  1422\n",
      "\t Training accuracy:  84.52425027767494\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.79277801513672\n",
      "Epoch Number :  1423\n",
      "\t Training accuracy:  84.59829692706406\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.775020599365234\n",
      "Epoch Number :  1424\n",
      "\t Training accuracy:  84.59829692706406\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.758419036865234\n",
      "Epoch Number :  1425\n",
      "\t Training accuracy:  84.59829692706406\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.74094772338867\n",
      "Epoch Number :  1426\n",
      "\t Training accuracy:  84.63532025175861\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.7247200012207\n",
      "Epoch Number :  1427\n",
      "\t Training accuracy:  84.63532025175861\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.70737075805664\n",
      "Epoch Number :  1428\n",
      "\t Training accuracy:  84.67234357645316\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.68968200683594\n",
      "Epoch Number :  1429\n",
      "\t Training accuracy:  84.63532025175861\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.67218780517578\n",
      "Epoch Number :  1430\n",
      "\t Training accuracy:  84.63532025175861\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.655357360839844\n",
      "Epoch Number :  1431\n",
      "\t Training accuracy:  84.63532025175861\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.637882232666016\n",
      "Epoch Number :  1432\n",
      "\t Training accuracy:  84.67234357645316\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.619747161865234\n",
      "Epoch Number :  1433\n",
      "\t Training accuracy:  84.67234357645316\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.602420806884766\n",
      "Epoch Number :  1434\n",
      "\t Training accuracy:  84.74639022584228\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.585750579833984\n",
      "Epoch Number :  1435\n",
      "\t Training accuracy:  84.74639022584228\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.56759262084961\n",
      "Epoch Number :  1436\n",
      "\t Training accuracy:  84.74639022584228\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.55039596557617\n",
      "Epoch Number :  1437\n",
      "\t Training accuracy:  84.70936690114772\n",
      "\t Validation accuracy  86.11111111111111\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.53197479248047\n",
      "Epoch Number :  1438\n",
      "\t Training accuracy:  84.78341355053684\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.51432418823242\n",
      "Epoch Number :  1439\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.49571990966797\n",
      "Epoch Number :  1440\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.4767951965332\n",
      "Epoch Number :  1441\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.45877456665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1442\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.44117736816406\n",
      "Epoch Number :  1443\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.42274856567383\n",
      "Epoch Number :  1444\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.40433883666992\n",
      "Epoch Number :  1445\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.3865852355957\n",
      "Epoch Number :  1446\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.36799240112305\n",
      "Epoch Number :  1447\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.349853515625\n",
      "Epoch Number :  1448\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.33203125\n",
      "Epoch Number :  1449\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.31401443481445\n",
      "Epoch Number :  1450\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.295135498046875\n",
      "Epoch Number :  1451\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.27722930908203\n",
      "Epoch Number :  1452\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.25894546508789\n",
      "Epoch Number :  1453\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.239280700683594\n",
      "Epoch Number :  1454\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.21982192993164\n",
      "Epoch Number :  1455\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.19834899902344\n",
      "Epoch Number :  1456\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.17931365966797\n",
      "Epoch Number :  1457\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.15995788574219\n",
      "Epoch Number :  1458\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.14289474487305\n",
      "Epoch Number :  1459\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.124168395996094\n",
      "Epoch Number :  1460\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.105316162109375\n",
      "Epoch Number :  1461\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.08606719970703\n",
      "Epoch Number :  1462\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.06641387939453\n",
      "Epoch Number :  1463\n",
      "\t Training accuracy:  84.8204368752314\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.04629898071289\n",
      "Epoch Number :  1464\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  33.027061462402344\n",
      "Epoch Number :  1465\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  86.80555555555556\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  33.006961822509766\n",
      "Epoch Number :  1466\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.986175537109375\n",
      "Epoch Number :  1467\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.96544647216797\n",
      "Epoch Number :  1468\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.94557571411133\n",
      "Epoch Number :  1469\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.92432403564453\n",
      "Epoch Number :  1470\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.90301513671875\n",
      "Epoch Number :  1471\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.88157653808594\n",
      "Epoch Number :  1472\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.85963821411133\n",
      "Epoch Number :  1473\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.83782196044922\n",
      "Epoch Number :  1474\n",
      "\t Training accuracy:  84.85746019992595\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  61.0\n",
      "\t Epoch Loss  32.81724548339844\n",
      "Epoch Number :  1475\n",
      "\t Training accuracy:  84.89448352462051\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.7977409362793\n",
      "Epoch Number :  1476\n",
      "\t Training accuracy:  84.93150684931507\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.77638244628906\n",
      "Epoch Number :  1477\n",
      "\t Training accuracy:  84.96853017400963\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.755615234375\n",
      "Epoch Number :  1478\n",
      "\t Training accuracy:  84.96853017400963\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.73586654663086\n",
      "Epoch Number :  1479\n",
      "\t Training accuracy:  85.00555349870419\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.71721267700195\n",
      "Epoch Number :  1480\n",
      "\t Training accuracy:  85.00555349870419\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.69767761230469\n",
      "Epoch Number :  1481\n",
      "\t Training accuracy:  85.00555349870419\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.679107666015625\n",
      "Epoch Number :  1482\n",
      "\t Training accuracy:  85.0796001480933\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.659690856933594\n",
      "Epoch Number :  1483\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.639549255371094\n",
      "Epoch Number :  1484\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.621219635009766\n",
      "Epoch Number :  1485\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.60299301147461\n",
      "Epoch Number :  1486\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.584224700927734\n",
      "Epoch Number :  1487\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.565189361572266\n",
      "Epoch Number :  1488\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.546966552734375\n",
      "Epoch Number :  1489\n",
      "\t Training accuracy:  85.19067012217697\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.528526306152344\n",
      "Epoch Number :  1490\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.50934982299805\n",
      "Epoch Number :  1491\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.490394592285156\n",
      "Epoch Number :  1492\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.4718132019043\n",
      "Epoch Number :  1493\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.452518463134766\n",
      "Epoch Number :  1494\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.433799743652344\n",
      "Epoch Number :  1495\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.415924072265625\n",
      "Epoch Number :  1496\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.39625930786133\n",
      "Epoch Number :  1497\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.377410888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number :  1498\n",
      "\t Training accuracy:  85.15364679748241\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.358245849609375\n",
      "Epoch Number :  1499\n",
      "\t Training accuracy:  85.11662347278785\n",
      "\t Validation accuracy  87.5\n",
      "\t Test accuracy  62.0\n",
      "\t Epoch Loss  32.33928680419922\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "# Train network \n",
    "criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.PoissonNLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.SmoothL1Loss() #interesting ... but does not converge\n",
    "#criterion = nn.MSELoss() #0.83 but unstable\n",
    "\n",
    "if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    test_target = Variable(test_target_100, volatile=True )\n",
    "    Noutputs = 2\n",
    "    \n",
    "elif isinstance(criterion, nn.NLLLoss):\n",
    "    train_target = Variable(preprocessed_input_train_target)  # keep long tensors\n",
    "    validation_target = Variable(preprocessed_input_validation_target, volatile=True) # convert to float\n",
    "    test_target = Variable(test_target_100, volatile=True )\n",
    "    Noutputs = 2\n",
    "    \n",
    "else:\n",
    "    train_target = Variable(preprocessed_input_train_target.float()) # convert to float\n",
    "    validation_target = Variable(preprocessed_input_validation_target.float(), volatile=True ) # convert to float\n",
    "    test_target = Variable(test_target_100.float(), volatile=True )\n",
    "    Noutputs = 1\n",
    "        \n",
    "model = conv2DNet(Nchannels, Nsamples_100, Noutputs)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.90, nesterov=False)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adagrad(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.ASGD(model.parameters())\n",
    "#optimizer = optim.RMSprop(model.parameters())\n",
    "optimizer = optim.Rprop(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "#optimizer = optim.Adamax(model.parameters())\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)\n",
    "\n",
    "batch_size = 25\n",
    "Nbatches = int(math.ceil(Ntrain/batch_size))\n",
    "Nepochs = 1500\n",
    "Nrep = 1\n",
    "\n",
    "train_errors = torch.Tensor(Nepochs).zero_()\n",
    "test_errors = torch.Tensor(Nepochs).zero_()\n",
    "validation_errors = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "ep_loss = torch.Tensor(Nepochs).zero_()\n",
    "\n",
    "for i_rep in range(Nrep):\n",
    "    for i_ep in range(Nepochs):\n",
    "        for b_start in range(0, Ntrain, batch_size):\n",
    "            bsize_eff = batch_size - max(0, b_start+batch_size-Ntrain)  # boundary case\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            output = model(train_input.narrow(0, b_start, bsize_eff))\n",
    "            batch_loss = criterion(output, train_target.narrow(0, b_start, bsize_eff))            \n",
    "            ep_loss[i_ep] += batch_loss.data[0]\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step(ep_loss[i_ep])\n",
    "        nb_train_errs = compute_nb_errors(model, train_input, train_target)\n",
    "        nb_validation_errs = compute_nb_errors(model, validation_input, validation_target)\n",
    "        # Evaluate on test data\n",
    "        nb_test_errs = compute_nb_errors(model, test_input, test_target)\n",
    "        \n",
    "        print(\"Epoch Number : \", i_ep)\n",
    "        print(\"\\t Training accuracy: \", (100*(Ntrain-nb_train_errs)/Ntrain))\n",
    "        print(\"\\t Validation accuracy \",(100*(Nvalidation-nb_validation_errs)/Nvalidation)) #!!!!!!!!!!!!!!!!\n",
    "        print(\"\\t Test accuracy \",(100*(Ntest-nb_test_errs)/Ntest))\n",
    "        \n",
    "        print(\"\\t Epoch Loss \", ep_loss[i_ep])\n",
    "        \n",
    "        train_errors[i_ep] = nb_train_errs\n",
    "        test_errors[i_ep] = nb_test_errs\n",
    "        validation_errors[i_ep] = nb_validation_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(train_errors))\n",
    "plt.plot(np.array(validation_errors))\n",
    "plt.plot(np.array(test_errors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4m9XZ+PHvkeQhz3jEiTOdCUnIxCEkhJVAIOxZAhRCKA1ltJRCy3xfeOEHbXnhZaVAA2W0Za+yRwgJJAGyyN7LSex4JY63ZFvS+f3xSLZsy7ZsS5Ys35/r8iXpPEO3H1u3j89zhtJaI4QQovszhToAIYQQgSEJXQghIoQkdCGEiBCS0IUQIkJIQhdCiAghCV0IISKEJHQhhIgQktCFECJCSEIXQogIYenKN0tPT9dZWVld+ZZCCNHtrV279rDWundb+3VpQs/KymLNmjVd+ZZCCNHtKaX2+7OfNLkIIUSEkIQuhBARQhK6EEJECEnoQggRISShCyFEhJCELoQQEUISuhBCRIgu7YcuhBARa9snkL+x5e3j50DasKCGIAldCCEC4aNbwV4KKN/bB06RhC6EEGHP5QJ7GZzyJ5hxX8jCkIQuhBBN2UqhpqJ5eXxvMEdDxSHQuqG8tgrQEJvUZSH6IgldCCG82Y7CE8eCw958W/9sGHoqLHvC97Fx6cGNrQ2S0IUQwlt5vpHMJ98AmRMayje9A4VboGQgJPSFGfc3Ps4SA8ee17WxNiEJXQghvNnLjMdjzoHhMxvKS/bA/h/BXg7J/WHSNaGJrxWS0IUQPZO9HD6+1Xj0ZisxHmOTG5fHJIGrDnLXQP9JXRNjO0lCF0L0TAWbYOtH0PtYI1l7mGNgxCyj3NuwGbD7G3DWwdjLujZWP0lCF0L0TDXumvlFz/tX4+43AeZ9HtyYOsmvhK6Uuh24AdDAJmAe8AJwKuBucOI6rfX6YAQphBCt0hp2L4aasrb39Tiw0nhs2rTSjbWZ0JVS/YHfAaO11jal1DvAHPfmP2qt3wtmgEII0aaCTfD6pe0/zhxj9C0PAnudk8JyO4PT4nG5NCZTCyNIA8jfJhcLYFVK1QFxwKHghSSEEO1UVWw8XvIiZI73/zhrSsAHA9nrnDy3ZDfPfLsbgGiLiRiLiYXXZDN1WFpA36upNhO61jpPKfU4cACwAV9rrb9WSl0FPKKU+m9gMXC31rqm6fFKqfnAfIBBgwYFNHghhAAa2sP7HAe9jwnqWxVV2Hnx+728tfogEwelUFPnJCUumqIKO5sPlVPrcAEwtn8yLq0ZkZHAyn0lDO0dH9S4wL8mlxTgQmAIUAq8q5T6JXAPUABEAwuBu4CHmh6vtV7o3k52drZuul0IITqs9CC8dIYxuhOC1h5eWl3Li8v28t3OYjbnGX88hqbHs6uwApfWrDtYisWkmHFMBgdKqvnV9CFcNLE/5i5oZvHmT5PLGcA+rXUxgFLqA2Ca1vrf7u01SqlXgDuDFKMQQvhWshcqC2DMxdD/eEjq1+FTaa1ZuqOYHYUVrNx7hCU7jGYci0nhcDXURccP7MVNpw7l7OMy68vqnC60NppXQsmfhH4AOFEpFYfR5DITWKOUytRa5yulFHARsDmIcQohRHMOdyvv1FthQHa7Di2z1bFoayG7iyqJNivySu28/3MuACYFJwxJpZc1ipwjVRzbN4mrpgzixKG+28CjzOGxVpA/begrlVLvAT8DDmAdRhPKF0qp3hiT/64HfhPMQIUQohmnkdDrVBQLFu3EbFKUVNVSZqvjYEk16Qkx9IqLom9yLLlHbRSW2ym3O3A4XWw5VN7sdGeO7sMfzhxJWkI0GYmxXf3ddJpfvVy01g8ADzQpnhH4cIQQwj85h6vYuXE/s4BLX1zLRnuf+m2ZybHUOlys2X+0viwhxkLvxBiUgrLqOvomxfLA+aMZP7AXMRYTVTVOBqZaMRoduicZKSqE6FZW7j3CFQt/AuBy835mRUGflGSePGU8Z47ui8WkiI0yA3Cksga7w0UvaxTWKHOjvuBa60bJOy2ha7+PYJCELoQIa5tyy3j+u93Yap3sLq6krOQwI5RR8751YjRshhevnw6JfZodm5YQ0+J5u3NNvCWS0IUQYae0upaXlu1j0dZCdhRWkBBjIT7GTGF5DT8mP0pmzT5jx82AMkF08Pt4dweS0IUQXc7l0uwvqSbZGsX2gnJyj9qYnJVKVlocf/1yBy98tweAYb3j+fXJQ5h30hD69bIaBz86H0aeDePdM5Ak9oOYCGgvCQBJ6EKIoDpYUs3W/HJW7D5Mfpmdb7cXEWMxUV3rbLZvn6QYCstrSIy1+B4q73JCbSX0m2j0PReNSEIXQgRUhb2Ooooakq1RPP3NLuLX/I2zTKu4GDCbFLdEaZKtUcQkmTApRa3Dhca4SfmOaTbV0y7jgfNHN7Rx714MS/8C2gXa/UcgJrSLMYcrSehCiE4rLLfzyGfbWH+wlINHq9Fek3x8F7+CzKgqHBnHEefufeJT7mr+NGAbXDCmcfmOz+HQOhhyivF65NmNl4YT9SShCyE6pLrWwaKthXy3s5gPfs4D4IxRGUwZksqAlDhio0yMG9CLwR85YehZRF/0XOsnfOXchkm2vNnLjSH913wQhO8iskhCF0L47e3VB3h79UEANuaW1c9xMkgV8n+Ty8kefLjxAaUYa3T600QSmwT5G2Hta43Li7cFfIrbSCUJXQjRohqHE3uti9zSal5ZkcN7a425TqItJs4dl8mZo/sw49gM4j6YCxs/hY0tnCh1aNtvljrUaF755HfNt42+sOPfRA8iCV0I0Ux1rYNXf8jhH8v2caSqtr780kkDmHdSFiP7JDaeWbD6CAycApe90vxkygSJfdt+0zMfhhNv9r0tofmgIdGcJHQheqgyWx2b88rYVVjB0eo6oi0mHE7Nh+ty2V9i3NhMT4jhdzOGk5YQw4xjMxiYGuf7ZPZySB0Cyf07HpDJ1LnjhSR0IXqi7QXlXPfyagrK7T63TxmSytUnDuaC8U3mFy/LhSfHwNxP4GgOfPw7jLXjMfqGi5CShC5EBCqrruObbYVYzIpluw5z4Eg1SVYLG3PLOFxZg0tDbJSJ+88dRf9eVqYNS2fzoTKOVtdy5ug+xFha6F64/0fjcc0rEJcKUVaY9jtQSgb6hAFJ6EJ0cxsOllJhd/DZpkMcKrXj0prVOSXY61yN9huYauWYvomcktQbp0tzy+nDGZ7RMGT+pOHpfrybbni0l0NCBpx+T+C+GdEpfiV0pdTtwA0YP81NwDwgE3gLSMVY/OIarXVtiycRQgTcqyv28eAnWxuVxUebmTgwhdlj+xIXbSE9IZppw9IDszzarkXG444vIL63UUsXYcOfRaL7A78DRmutbUqpd4A5wDnAk1rrt5RSLwC/Ap4ParRCCMrtdVTYHeQdtfHoF9s5rn8ScyYPIiUumtOP7U2spfG83wF1eKfxaIk1huIPPyM47yM6xN8mFwtgVUrVAXFAPsaKRVe5t78GPIgkdCECrriihgXf7iLaYuKdNbmU2erqtyXEWHjx2mwyk61dE4yzFkadD1f8u+19RZfzZ03RPKXU4xiLRduAr4G1QKnW2uHeLReQ/kZCBJDWmi82F3DnuxuazUx49pi+jOyTwKXHD+i6ZA7gsIO55UUjRGj50+SSAlwIDMEYyPsuMNvHrtpHGUqp+cB8gEGDBnU4UCF6is15ZXy1pYC3Vx+kqKKGERkJPHLxWNITohmUGofZpEK32o6j1mhuEWHJnyaXM4B9WutiAKXUB8A0oJdSyuKupQ8ADvk6WGu9EFgIkJ2d7TPpCyGMRR/+66PNvL7yQH3ZOWP78shFY0mJjw5hZF4cdrBIDT1c+ZPQDwAnKqXiMJpcZgJrgCXAZRg9XeYCHwUrSCEi1a7CCr7aUsD2ggpW55RQWF4DwAPnj+b88f1Ib2VNzJBw1EhCD2P+tKGvVEq9h9E10QGsw6hxfwa8pZT6f+6yfwQzUCEizQ97DnPViyvrX2ckxvCHM0fy2xnDA9+ksv9H+PxOcDmab5twFZx0W+vHL34Ytn8KtRVgDpP/FkQzfvVy0Vo/ADzQpHgvcELAIxIiwtQ4nHy/8zBJsRYGpMbx9ZYC1u4/ymeb8ukVF8VfLx3HwJQ4hmckBKavuC85y6FwM4y6wBjV6bH/R9j2adsJfcuHRg+XMRfLiNAwJiNFhQiQCnsdheV2Sqvr+HxTAQdKqjhQUs3Owkqf+08blsZTV0wgI6kLbjLaS8FihSv+1bj87WugeEfbx9eUw7HnwflPBSc+ERCS0IVowdGqWlLio7HXOalzurCYTHy4Lo+/LdlNXqmNSyb25+JJ/TlhSCpLthdzxzvrqWrSvdAaZWbu1MFMHJRCQbmd6lonJw1Lo09SLFnp8e0LKGc5HFrve1tChtGcUl3ie/vBVRCb3Lw8NhkqCuCHBa2/t61UFpnoBiShC+FWUGbnkc+3sTmvDJOCPcVVJMVaKLcb7c6JMRYqaozn8dFmPliXxwfr8hqdIz0hhsuOH8A1UwdztKqWUZlJmAM1avPD30DZwY4fP/S05mUZo2Ddv+Dr+9o+vvexHX9v0SUkoYseq8Jex77DVewuqmTBkt3sLa4CINkaRVpCNImxFuKijYQebTERH2PhhpOHctLwNLKzUikqt7NoWyH5pXZMJsU5Y/tybN+GWmz/XgEe8FNdAifMhxn/1bh819fw/q+M53PehKzpvo+P9vEfwdRbYNK1NFrV2RdlgpiE1vcRIScJXfRILpfm2pdXse5AaX3ZTacNY/yAXpwyMp24aEuz/V1aYzE33LTMSIrl6imDuybg2mqoq4K49OZNHwkZDc8T+7S/aSQmsfPxibAgCV30GE6XZmNuKd9sK+TrLYXsKjJuVt45ayTnj+/H4LSW27RNJoWJEI3OrKmEx9xrclpTmm+3es146Gu76DEkoYuIV1njYMG3u3l5+T5qncYc4UPT4/n9GSO4beaI0A2j91dFAThrYMAJMO7y5tv7jIEL/wYmC6QM6fr4RNiQhC4iisPpYlVOCXuKKtleUMHrKw8QZVbUOTUnDEnl/PH9mDo0leEZ3aiZoabMeDz5Dt81cKVg4i+7NiYRliShi27L5u4i+J/1eXy3o5gvtxRgjTJjq2vcdfC4/sncMt7MGQUvwYE6YzILD2svmP1Y4+HsWsPi/4GSfW0HkT4CZtwfgO+mFblrjEdf3Q6F8CIJXXRLRRV2zntmOUUVNY3KbXVO7jtnFNEWE5OzUhmWEW+sj/nT87DpXUgbYfTYAKitgvJcOH4e9JvQcJLaSlj+pLEij7WVFXlsJbD1P0bNOSqIU9iWu+e9631M8N5DRARJ6KLb2F5QTrTZxLoDpdzx7gbA6GI4fUQ6T1w+nsoaB2nx0b7bxO3uZoubfwKz+9d+3zJ47TxjFKQ3h/uPxCl/ginzWw5o9Uvw2R3G2prBTOg15UbvFlnuTbRBEroIveKdRpJNHdps05qcEtYfLGV1TglfbSlstO3OWSO5dcaI+texUU1WqrcdhbyfjeeFWyA6oSGZQ0MThifZe3gSeluzCsa4j9+9CBIzW98XjEmtBk1tHENLKgqNuVcAjuyW5hbhF0noIrRcLvjbZOP5g40T6+6iSn75j5XY61zEWEyM7JPAzsJK0uKjee+maQxpa+j8V/fB+tcbXqeNaLzd01/b3rSGbjce21rIIamf8fjRLa3v5+3Sf8DYy9re7z83wZ7FDa+zTvb/PUSPJQldhFat18RVWoNSLN91mGe+3cWqfSUkxFh4a/4JHD84hShzO2cirCiA3qPg/KeN1ylNBgHFeBJ6kxq6s9Z4tLQxTezgafCb5cagn7bUVsK/L4HKwrb3BWO/QdPgjAeN1+kjWttbCEASugg1r/br3XnFPLfiEB+syyPabOKSif258dRhHNO3g10Ma8ohKRMGTfG93ZPQm7Wh+1lDVwr6jvUvFpe7503T/wZaYi83zt1S7EL4IAm9p6qzwytnw6F1xuuk/jD9djjh14E5/5tXQX4LMwN60c66+vGXiS9O5k5M3B9vJtkahTlPwRtNDoiKM2rQvhZqaKqy0JjytSVmC0Qnwg/Pws//bCj3tw29PUxm4w/IjwuMybDaUn6o4Q+OEH7yZ5HoY4C3vYqGAv8N9AJ+DRS7y+/VWn8e8AhFcJTnNSRzMJoEcpYHLqHv+troZufdHdCHLXnl5Jbnk5xgRUfFM6x3AimJMfgcvHlwFRzeaTwffxWY/GiCGX9V69vPfLDxdfCIToABk9s+f3uc8YDv9/JFmWSwkGg3f5ag2wFMAFBKmYE84ENgHvCk1vrxoEYogqNpu3HyIHDWBebcLhe46mDU+XDa3T53OVhSzS1v/MzG3DIumtCPp+ZMbPu8X/+XkdCVGS56Dt9Zv50m39D5c4Tje4keqb1NLjOBPVrr/WE//4Vo3b7vG782RzXcDOwsp+8mi91FlfxnXR6HSm18svEQdU7NnMkDefii4/w7r6dXiiUmMMlciAjT3oQ+B3jT6/WtSqlrgTXAHVrro00PUErNB+YDDBo0qKNxikDbu9R4TB1mNI1UlwQuoXvaoM0NCX3DwVKuf3U1R6qM9xiRkcCjl4xlclY7Bsv0cd+AHJAdmDiFiDB+J3SlVDRwAXCPu+h54GFAux+fAK5vepzWeiGwECA7O7uNWfRFl3E5YPBJcN1nxuvXzg9ck0uTm4qb88q48G8rAPjH3GySrVEcPzil/bMcHnM2PFDa9n5C9FDtqaHPBn7WWhcCeB4BlFIvAp8GODYRTA67sbCBJ6mao6GurPVjWuJyQWVBw2vP3COWGNbuP8pVL/4EwFvzT+TEoWmdCBppahGiFe1J6Ffi1dyilMrUWue7X14MbA5kYCLIHHZj8ikPc3THm1wWPwgrnm5WfNO7O/nCZUz3uuCqiZ1P5kKIVvmV0JVSccCZwI1exY8ppSZgNLnkNNkmwp2jtvFNy87cFD2yB5L6s6L/9Xyy0fgbP7JfOnurj+eExEQeuGA0Y/rJXCRCBJtfCV1rXQ2kNSm7JigRia7hsDe6aYklpuMJvaYcV9IArl43ChjFY5eN4xfZA5vfUBFCBJWMFO2pHDVNaujRjW+Krv4HbP/Mr1PpQ+vZG2t0PXz2yomcP75fICMVQvhJEnpPVVcN0V6zFTZtcln7KpTubz5DYROVNQ7ynJksLB7H9OHpzD6ub3DiFUK0SRJ6T+RyGhNSec8V0vSmqKMGhp4Ov3itxdN8suEQv33TGMo+IiOBz66bjKW9MyIKIQJGPn09UU2F8RjrldBNFmNBiAp390OHvdXJqRZtLeSP7xmrBp2Qlcq7v5lKtEV+nYQIJamh90SeeVy8V8HJ32g8fvBrmPtJ8zZ2Lz/uOcKv/7mGjMQYvv79NAalxQU5YCGEP6RK1RN55v/2bnKxu0dgFmwyHp01PucDX7H7ML9901jW7eXrJksyFyKMSA29J/IssuDd5FJnMx6d7nnGHTVGu7qXH3YfZt4rq6l1unjs0nEc11/6lgsRTiSh9xS5a+DNOcaAIpe7e6J3k0tcGpTsgdoK+PMgoxeMeyX7qhoHf/liO//6aT9x0WY+uvVkRmXK4gtChBtJ6D1F/nqoKobjrwOLFay9GmYvBB5PuZ+TbS8zZbh79XqTGcZfidOl+e2b6/h2exGD0+J47upJksyFCFOS0HsKTzPL2X+pr3l7fLQ+jwWrK1nAL8j57bmNtn28LpdvtxfxwPmjmXfSkK6KVgjRAXJTtCeoLIYljwKq2Y3ON1Ye4La3fK/9WVnj4Nlvd9MvOZbrpmUFP04hRKdIDb0n2P6p0W7eb2Kj6WfveGcD7/+cy/CMBEZnJvHxhkOszinh2W93U1hmZ0eh0V/9z5eMbf/c5UKILicJvSfw9Duf2zBl/ea8Mt7/OReAV+dN5rmlewC4/IUfGx366MVjufIEWWlKiO5AEnpPcDTHePSau+U/6/IAWHXvTDKSYpl9XF/eWHmAERkJPHnFBGocLnonxEg/cyG6EUnokU5rWPuK0Xbu1WyyIbeU4wenkJFktKmfPKI3OX85t6WzCCG6gTZviiqljlFKrff6KldK/V4plaqUWqSU2uV+TOmKgEU71VYZj6MvrC9ak1PC6pyjjB/QK0RBCSGCoc2ErrXeobWeoLWeABwPVAMfAncDi7XWI4DF7tci3HjazwdNrS965PNtAJx2TG9fRwghuqn2NrnMBPZorfcrpS4ETnOXvwYsBe4KXGiiw6pL4P0boLayYUi/1zD/wjI7F0/szykjJaELEUna2w99Dg0LRffxLBLtfswIZGCiEwo2wZ7FxnwscakwcnZ9Dd1e5+RQmZ2stPg2TiKE6G78rqErpaKBC4B72vMGSqn5wHyAQYOk+1uX8CxUcc7jMHByo00fbzgEwKjMxK6OSggRZO1pcpkN/Ky1LnS/LlRKZWqt85VSmUCRr4O01guBhQDZ2dm6U9FGOkctbPsYMkZDn9HNt9dWGet8traYc3RCQ2+WJvOZr91fwl3vbyR7cApnjOoTwMCFEOGgPQn9ShqaWwA+BuYCf3E/fhTAuHqmvUvh/V9B0gD4w5bm27d8CB/d0vZ5pvzGePQa5l/rcPE/n2wlIdrC45ePx2SSkZ9CRBq/ErpSKg44E7jRq/gvwDtKqV8BB4DLAx9eD+NZeKI81/f2qsPG4y2rIar54hMUboU3r4ByY9CQp4bucLo49X+XkF9m538vG0dWurSfCxGJ/EroWutqIK1J2RGMXi8iUBw1rW+vKQdlhvQRjQYJ1XO65zn3JH5LDFprrlj4E/llds4a04fLswcGNmYhRNiQkaLhxGFveP5gMtA0aWtjIYqWJsqKdQ8UOmDMx/LjgWqu/NfnAAzrHc8Lvzw+sPEKIcKKJPRw0vRmZ/Y8iEtvXJY5vuXj49Pg/GegLJdicwZX/qthANHfrzleZkwUIsJJQg8n3jV0gOm3Q692dvU8fi5aaybfY9TM7zr7WG46bViAAhRChDNJ6F1lw9uwf0Xr++RvaPw6tmOLMBdVGG3xY/ol8avpssqQED2FJPSu8u3/M9b0bCtJDz7JGLIfFQ/RHRv8s2K3cVP03nNGEW2RRamE6CkkoXcVexlMuhbOeSyob7O3uJJHP9/G+AHJnDg0re0DhBARQxJ6MGkNxduNEZ415R1uQmlNndPF09/sYsGS3fVlsVEmHr1kLGYZPCREjyIJPZgO/ASvnN3wOiEw85e5XMYMCruKKrnp32vZe9iY89xsUmQPTuHRS8YyrHdCQN5LCNF9SEIPpuojxuPsxyBtuNE+3kkbDpZy4d8abq5aTIpnrpzIBeP7obWWrolC9GCS0IPJ5R65mTUd+ozp9Ol2FFTwy5dW1r++5sTB3HjqUAakGOt+SjIXomeThB5MTofxaI7u9Klyj1Yz9+VVWMyKT387neP6B749XgjRvUlCDyZPDd3UuctcXFHDtf9YRXFlDS9ee7wkcyGET5LQg8kzWZY5qsOnKLPVce4zyyiqqOFvV01ixrEyj7kQwjcZdRJMnrlZTB1L6LZaJ396bwOHK2v4+zXHc+64zAAGJ0TXWZa7jBc2vIBLu0IdSkSTGnowuTxt6O1L6LZaJ099s5O/f78XgN/NGM5ZY/oGOjohuszNi28GYPaQ2QxOGhziaCKXvwtc9AJeAo4DNHA9cBbwa6DYvdu9WuvPgxFkt9XOJpc6p4urX1zJqpyS+rKHLhzDtVOzghCcEF2vuq461CFENH9r6E8DX2qtL3MvFh2HkdCf1Fo/HrToOspR23BD0pspCizRxkISLgdEB3nlnvqboi0ndK01H67LY/G2IrYVlLO32Bgk9MezjuEX2QPpnRjT4rFCdDd2p73tnUSHtZnQlVJJwCnAdQBa61qgNmz7PB/dD387oflUtABRcXD5a/DWVUayPfUuOP3e4MXibL3J5dvthVz/6pr612nx0cydOpgHzh8ja36KiGSrs4U6hIjmTw19KEazyitKqfHAWuA297ZblVLXAmuAO7TWR4MTZjuU7DWS+eQbGs8lfmQP/Pwa7P7GSOYmCxT6WIg5kGorwGIFk7nZpldX7OPBT7YCcO64TB6/bDzW6Ob7hbPXt73OyvyVPreNSRvDjeNv9LlNNPfOjndYnre81X0SohK4/8T7iYuK66Ko/Ld4/2I+2tP2OvEL1i/grR1vcfrA09l8eDPFNqPFdkDiAP6Y/UcZHNdJ/iR0CzAJ+K3WeqVS6mngbmAB8DBGm/rDwBMYbeuNKKXmA/MBBg1q52INHeFZaPn466Dv2Ibyg6uNhF7mXoA5qX/DvsFiL4fYpEZFuworWLStkMe+3MGIjATe/c1UesV1fuBRKLy25TWq6qrIjG/c+6bYVsxP+T9JQm+H17e9TnF1Mf0S+vncXu2o5mDFQS4beRmT+kzq4uja9t6u91hTsKbFG55ZSVnklOdQ66xlVcEq1het52jNUfrG98XlcrHk4BJuGn8TiR2cMloY/EnouUCu1tpTFXsPuFtrXejZQSn1IvCpr4O11guBhQDZ2dm6c+G2Ye9SWPGM8TymcSKtT6zu9TZJHggFm+DdeY33UyY46XctL/VmL4ev7jVmUARI6gdnPmy0yX91D2SdDGUHIe9nyF3dKI6PNxzid2+uAyA9IYZX5k3utskcwO6wM3vIbO4/8f5G5QvWLeDvG/8uc8u0g91h5/RBp/PI9Ed8bl9ftJ5rvrgGmyM8myxsDhvHpR/HK2e/0ua+f1j6BxbtXwTAHcffQXltOQ//9DB2h10Seie1mdC11gVKqYNKqWO01juAmcBWpVSm1jrfvdvFwOZgBuqXta9CwUYYcgokNumz3WuQMTlWZREMOhGGz4SfCo2k7u3IbkjKbDmh566Cdf+C5EHgrIHKQpjyG7AdhdUvwZpXwBJr3HyNS6dq2GxyCypIiY/i3g+M97rl9GHcNnNkt198wuawYbVYm5V7yuxOu8/tormWrqVHrCW2fr9wZHPYSI1N9Wtf7+/TarFS5+48EK7fW3fiby+X3wKvu3u47AXmAc8opSZgNLnkAKH//9peZjSzzP2k+bYoK8xr0qty8g3N93t8pFELb+09AK5+15hcLB3oAAAf20lEQVTr/N25RtONp1w7oa4Kpv+eJX2u48Z/raX2+++NEMyKb+84laERMLWtS7taTNj1Cd0hCd1fbf3x82wL16TXnp+1JPTg8Suha63XA9lNiq8JfDidVLwD0kd27hwxScaN1b3fwYDsxl0bC7fAlv8Yz2OTqbEkEAOw73uoqWh0mmdXFPJE+WoAkq1R1Dld/OXScRGRzMH4AENDzdGb5wM778t5RJujuXH8jcwcNLNL4wu1nUd38uAPD9Ynq7bYHDaf19LDc02fWfcM/9z6z3bFcv1x1zN7yOx2HeOP5XnLeebnZ9BoDlQc4Lj04/w6Ltbc8H3GWmKpdRkjqu/47o5OVwDSrGk8e/qzRHViuo3uLHJGitbZoDwP0kd07jxJmUaCzlkGp/wRZrjbh22l8Py0+t1ueHsHOXv38E0M8OXdzU6zpTKBvkmxvH/zNPolx+J0aSzm7t3E4s1Tm/L1AZySOYVZg2dR66rlx0M/six3WY9L6OsK17Hp8CZO6neSX8mlf0L/Vq9RujWdK465gsLqwhb38WVl/kq+y/0uKAl9Rd4Kdh3dxfQB08mMz+T8Yef7ddysrFkcrDhIQnQCI1JGUOus5Zwh51Dt6Nygo8KqQlbkraCguoCBiQM7da7uKnISus3dY3JYJxPHZa/C4Z3w9tVQUdBQ7lmswu2bPZXAAGbX/ZV4VxVD0uOxq1h6x7rITE3kvjNnMzCtoTZuMUfWzUHPABFfCb1fQj+eOO0JAM754Jwe+a+053t+4rQniI/q/AA2kzI1u/nsj0s+viRofb9tDhu9Ynvx7Ixn23XcuN7jeHrG0/WvrRYrfz3lr52O5+ucr7njuzt65O+bR+QkdE+7d5Lvbl9+i0+D+KkQl9a4W6OnjdxtQEocS+48Da3hUKmNrPQgjzoNM54k0VozgWe73dcgrwjnSSrezQuhYDVbgzY60+60h/z78+b5XeyJv28e3Tuh//AsrFxoPHfWGI/tXIj5s435VNU6GJoez/GDUxq62cUmw86v4MmxMOp8oweNl2V/Or1+356WzKEhYcVZWh/kYrVYe2SNyeawEW2KxuxjUFlXCub1t9XZsEaFz03vcL9x3BW6d0Lfu9ToUTLiLON1dDwMnNLmYVprnvpmF08v3tWo/JSRvZk3LYvTj82Ak34P2z+DnOVGMq8z+p3vNw9m0Hl3RVz/6vzKfK754hoKqwuJs8TVt/umxqby1rlvced3d7Lx8Mb6/R3umSTbuokVa47lx/wfgxd4GPmvFf/FkoNLACPZhcOITqvFypq8NUx/a3qL+6TEpJAam8qesj3tOndVbRWj00d3NsSA8VQuVuavZEpm23kgEnXvhO6ogfRj4OLn/T7E6dL8+fNtvLR8HwBj+yeTnZXCKyty+H5nMd/vLDaWeBt1How6j5yXriWrzBjS/OvaP3DLTbcxeGCvoHw7obSvbF/9DTelFOcMOYcD5QdYcWgFBVUFrCpYxdDkoUzImFB/THxUPGPTx7Z0SsAYrg7GHwBLJ1duCnerC1aTGpvKiZknAvjd6yOY5h03j8yElufRP1hxkOV5y8kpz2FU6qhGP19/nNz/5M6GGDAjU40ebv72LIpE3esTtv4N2Pkl9BkLqUOMnihDT2vXKZ7+ZicvLd9HUqyFn+6dSVy0cQkeOH8MRRV2znl6Oec9u5x+ybHUuTQ32+zMc1+lK04+jgkRmMyh8b+po9NGc++Ue1lyYAkrDq2gqq6KGmcNpw88nZsm3NSu807qM4lvD36L3WEnIToyumy2xOawMa3fNO6dEsQJ39ppUp9JrU4V8H3u9/VzyHTk5xtOokxRpMSkSJNLt/Ef9y/bVq9JgPYu9fvwj9bn8cy3u5kyJJXXrj+B2KjG7ZsZibG8eO3x3PivtRwqM26sbDUPRqNwWqzMnBa5/8Z5dxnT2pihwdM+erTG6EHUkT7CnptmdqedBCI7oXfHgVRNB/l0d7GWWEno3YL2mgbmhBth1d/bcajmy80F3PbWegCfydxj4qAUVt13Bptyy6iw1zF12Dko15+xKBOYIqcfeVO+ekJ4PuAFVUb3zbZ6tPji+aNQVlNGujW9ExEGX52rDrMyY1Lt+zk7XU7sTrvR66MD1yiUvJN4d4vdF6vFSmVtZaOFNGItse3+mbbF7rA3W04vyhRFlDmKOlcddc7mzT7R5uigNzt2n4TuWZ8TINH/hZIr7HVc/sKPbC8wRnI+c+XEFpO5t7EDvHrLmLvPZeoo765eg5KMWTETo4yJkh7+6WGADvWn9rShX/zRxSyYuYBTBpzS2VCDwu6wc8rbpzCu9zhemvVSu46dv2g+qwpWAQ3fb3fhHW8g+suHWkJ0At8e/JYpbzT8Nz07azaPnfpYwN5jWe4ybll8C5rGcw1aLVbeP/99rvz8Sspqypod9/wZzzO9f8s3pwOh+2Qq776lSf0bng9u+QKVVtcy44nvKKmqJXtwCguvzSY1vvvObhhMTpcTgLsm38XZQ84GYEjyEB6a9hBlNWVEmaOYMWhGu887td9U7sy+k8fXPM7+8v0BjTmQjtqPYnPYWpzfvTV7Svcwrvc4zs46m3OHnhuE6IJncNJgHpr2ENWO6g79fMPN3ZPvZm3h2vrXH+35iL1lewP6HjnlOWg0t0y4pb5JcV/5Pj7Y9QFbSrZQVlPG2VlnMyZtTKPjspKyAhqHL90ooXvV0I89Fy56AfI3wLTftnjI/y3aSUlVLf/3i/FcMmlAFwTZfbkw/n28dOSl9f+GK6W4eMTFnTqv1WLlymOv5PE1j4d122ZnYrM77YxLH8c1o8NveqO2BOJnHE7G9h7L2N4NPa+2HtnKliOBXcjG87ty/XHXE202Koir8lfxwa4PKLEZ6wHPHDyTs7PODuj7+qMbJXSvGnp0Aky40vhqQWWNg3/+uB+zSXHRhP4t7icMnvbAQLc1gtG2aFbmsB7BZ3N2LKFrrduc+laEjjXKGvDfO7vDjlmZifJaK9jz8/d0IGhrwF2wdI+E/sOz8LXXPBZ+DOp5YakxSOK5qyfJ+px+qE/oBD6hK6WwWqwUVBWwp7T1wSsKxeCkwV0ywtKlXeSU55AWm8be0oZ/y9uK0Vudqw6XdklCD1NWi5UqR1W7fqZtKagqwGqxNhpc6Lmh7GlWDNXvQ/dI6Nu8FkPyjAptxccbDrFgyW4AThoe3j0rwkUwa+gAyTHJfLL3Ez7Z62Ou+iZumXALvxn/m6DE4e2Vza/w1M9PNSu/6KOL2n2u5Jj2TTkhukZyTDJVdVUd+pm2pn9C4//6PT//L/Z9AUBSdFKzY7pC90joHnM/hSEtj0xbf7CUBd/u5pttxojHZ66cSEJM9/oWQ8XT9zxYCf3ZGc/6NbT8oR8eoqi6KCgxNOU9Fe3Q5KHcOvFWAJza2a7zRKkopvWf1vaOosv9ctQvGZY8rP4eUaAMSx7W6HVGXAYvn/UyR+xHSIxKZGRKJ9dl6CC/sp1SqhfwEnAcxgpF1wM7gLeBLIwVi36htT4alCg93YNaaGr5cF0ut7+9oVHZPbOP5YLxnZx5sQfx/MIHa46aESkjGJHS9lz1T619qstunnq3rWYmZHLm4DO75H1F10mMTmRW1qwuea/JfSd3yfu0xt/q2NPAl1rrY4HxwDbgbmCx1noEsNj9OjhGXWA89hrUbFOd08Uzi3fXv779jJF8cdvJ3HjqsGb7ipa5tCtotfP26MrZGb3fx2qWNnDR/bVZQ1dKJQGnANcBaK1rgVql1IXAae7dXgOWAncFI0im3gITroK45ovQ3vrGz+w7XMWCqyYyfXg6veKkn3lHaK2DckO0vawWK/lV+SzLXdaoPCMug2NSj2n12C2Ht1BiL/G5Ld2aTkpsCruO7iIrKYv9Ffs5VHmo0fsK0d350+QyFCgGXlFKjQfWArcBfbTW+QBa63ylVIavg5VS84H5AIMGNa9h+0Upn8m8qNzOV1uMdtBzx2ZG3JS2XcmlXWFx/dKt6Sw5uISbF9/cqDzKFMWPV/1IjDnG53GHbYeZ89mcFs9rVmaG9hrKrqO7fG4P92kJhPCHPwndAkwCfqu1XqmUepp2NK9orRcCCwGys7N1G7v7raSqlhv/bYwI++iWk8IiGXVnLsKjyeXR6Y82G9m3aP8iXt3yKlV1VS0m9FJ7KQC/m/i7ZnNhf5f7HQs3LuRA+YH6stTYVJ6d8SwDEgeQX5XP8F7DA/ydCNH1/EnouUCu1tozJvo9jIReqJTKdNfOM4Eu6ZqgtWbh93v5+/d7Kamq5a+XjmV8hE5p25VcrvBI6AnRCYzrPa5RmacPcWtt655tx6Qe0+x4T9NKjWdVK4ybZZ79UmOb//cnRHfU5idYa10AHFRKeRowZwJbgY+Bue6yucBHPg4PuHfX5vLnL7ZT53TxynWTuWJyB5txRCPhUkP3xdO+3dqIP89skb7WuPTVPh5Oa2EKESj+dtL+LfC6Uioa2AvMw/hj8I5S6lfAAeDy4IRo0Frz3NI9/O9XO4gyK1bfd4ZfsyaGwtrCtc1Gpo1JH9Nssp6usqNkBxuKjW6d0eZozso6q1mSC5ebor54Yv1076dkxvtefWd36e5G+/o6vq0yIbo7vxK61no9kO1j08zAhuPbZxvzueWNn+tfP3WFf1PghsrtS26vn9PBY3iv4Xx44Ychieehnx5iY3HDeqAx5hhmD5ndaJ9wuSnqS2ZCJiZl4qVNrU9razFZyIhrfm8+Mz4TszLj1E76xPWhsLqQ/okyv4+IPN1iGOWXW4wFFiZnpfB/v5jAwNTQL77bmoq6Cq469ipuGHsDAI+tfoz1xetDFk9lbSWnDjiVWyfeyuWfXE5FbUWzfcKlH7ovI1NGsmzOMmocNa3uZ7VYfS5zNzBpIMvmLKPWWUtqbCpH7EdIiUkJVrhChEy3SOhzJg/k+53FPDVnIv17hfe/ynWuOhwuB6mxqfSO6w1Ar5heIZ061uawkRyTXD//hK9YNDpsEzq458boxBCDxOjE+ufSRVFEqm6R0E8ans6GB7pm+G5neZJlo7Uao6zY6kKb0K0Wa/2McL5uLrq0C0V4NrkIIfzTLRJ6uNtbupdP9xozQnoSuWctTTCGlde6akMyb7bD5aC0phSrxUqUKQqFYsH6Bew4uoPRaaO5bsx1WEyWsG5yEUL4RxJ6ALy+7XXe2flOozLvgSoxFmMwzKbiTZyQeUKXxrbj6A6A+sVpPauiL9q/iEX7FzG131TGpI0J+yYXIUTb5BMcAFWOKgYkDCAtNg2A6f2nMzFjYv32yX2MWdhC0Y7uWf38xMwTAfjLyX/xud3pckpCF6Kbkxp6ANgddmItsfWrgDdtVvG87ugyZ53RtE3fU1Nvul1q6EJ0f5LQA8DmsDVaQ7BZQne3p4fixmjThO69DiJAtcOooctNUSG6P0noPvxj0z/YVbqLXjG9uDP7zma1Wm/ritbxw6EfOKHvCS3W0D3DzN/Z8Q4rC1Y2O4e3Uwecyuwhs/kh7wc+3vuxz32KqovYX76ft897u9UueLkVuTzwwwNGDO4eLk2/l39v/TdLDy5lfdF6zCp8B2sJIdomCb0JrTXPrHsGkzLhcDm4dMSlra6088GuDwA4uf/J2J12SmtKOaFv4xufvWJ6MSVzCocqDzUasdnUYdth9pbuZfaQ2by14y2W5y2nb3zfZvsdrDgIwCd7PmHecfNaPN93ud9RVVfFiJQR9InrAzSvoZfYSyixl2BSJqb3n97iuYQQ4U8SehO1rlpc2sWE3hP4uejnNm9k2hw2spKyuO646wB8Lm5sNpl5aVbrw9YB7vzuTnaU7Kg/7+i00fz7nH8322/sa2ONWJ21bcYG8Oa5bxJtNkbleNfQhyYP5aOLumRONSFEF5C7YE14Bt14plT1J6EHqm+51WKtnzXQ7rB3+rw2hw2FItrUMMTSpRsWy22tKUkI0f1IQm/Ck8BTYo25PlqbstWzPVAJPdYcW//+Noetvt27JZ42+5Z4/th4T7rlcDnqnzdtfhFCdG9SRXOrrK3krmV3cdh2GGhI6Ld+eysfX/QxQ5KHNDtm59GdrCpYxUn9TgpIDNYoK+U15cz9Yi77y/cztNfQVvd/b+d7bDmyhb+e/FdizDHcs+weCqsL67cfqDjQ7I+NUzvrn3uaYYQQkUFq6G57y/byfe73OF1OThlwChcMu6B+cNC6onU+j1mZb/RYOWXAKQGJ4fSBpzMlcwpRpijG9x7P2Vln+9zv5bNeBiA5JpmlB5eSU57DYdthvsj5gqM1R4kyRRFlimJY8jCuOOaKRsdOzJjIpSMu5dQBp/Lo9EcDErcQIjz4VUNXSuUAFYATcGits5VSDwK/xlhAGuBerfXnwQiyK3iaIv6Q/Qem9ZsGwBOnPsGMd2c0aqbw5mmOuWzkZQGJYWLGRF6c9WKb+03uO5lNczfxw6EfuHHRjdgd9vqmml+P/TXnDzu/xWMtJgsPTnswIPEKIcJLe5pcTtdaH25S9qTW+vFABhQqda46oHG7suemoWdbUzaHDbMyh6wt2jOYyeaw1d9M9R7gJIToWaTJxc1TC/dOzp7nLdXQPTcuQ7XST/2UAg6bz2l7hRA9i781dA18rZTSwN+11gvd5bcqpa4F1gB3aK2PtniGMOcroXvX0A9WHOTmb25mar+puLSL73O/p6ymjLio0NWIPb1gbl96e303S+9pe4UQPYu/Cf0krfUhpVQGsEgptR14HngYI9k/DDwBXN/0QKXUfGA+wKBBgwISdDB4mlW8+2Z7njtcDnYe3UlOeQ455Tn0i+9HlCmKMwef2WhWxa7mXRufmDGRvvF9GZU6KmTxCCFCy99Fog+5H4uUUh8CJ2itv/dsV0q9CHzawrELgYUA2dnZrXecDiFPDd07oZuVGYWizlXXqD+6zWFjVtYs7j/x/i6P05t3P/W7Jt9FZkJmCKMRQoRam23oSql4pVSi5zkwC9islPLOHhcDm4MTYtfwdVNUKYXFZMHhcjQaMWpz2Oon3Aol7xp6W4OQhBCRz58aeh/gQ/eNPwvwhtb6S6XUv5RSEzCaXHKAG4MWZRfwVUP3vHa4HI1q6HanPSzaqr3/+MjNUCFEmwlda70XGO+j/JqgRNRF6px1zHp/Vv3IUI+moydjzbH8c+s/mx0fb4kPanztFWOOCXUIQogQ67FD/8tqyxol84uHX8zY3mObzS/+wLQH6mdAjLXEUuc0mmbOG3Ze1wXbiqdOf4paZ23Iuk4KIcJHj03oTVcPmnPsHEanjW6238xBM5k5aGZXhdVu4RybEKJr9diBRU3X95SbikKI7i7ia+jVddX1A4CSY5LRWlNUXcTB8oON9pMh80KI7i7iE/pFH11EflU+FmXh68u+ZvGBxTyy8pFm+8VHhddNTiGEaK+ITugu7SK/Kp/+Cf3Jq8yjyFbEoapDjfZ54YwXUCgSoxNDFKUQQgRGRCd0T9/xwUmDyavMM6aZrbORFJ1EeW05ACf1D8ziFEIIEWoRfVPUM7rTe31Qu9Me0gm1hBAiWCImoVfVVXGg/ED96xJ7CWsK1wANCX3L4S3kV+aHxbB9IYQItIhpcrnzuztZnrecVVevwmqxcud3d7K6YDUAQ5ONtTkXrF8AwKSMSRRVF8lweSFERImYhL48bzlgLPZstVg5YjvC8X2O57ZJtzEufRxj0sdQWlMKwLDkYThcDkwqYv5BEUKIyEnoHp4boXaHnf4J/evnKz829dhQhiWEEEEXcVXUakc1YNwAlSYVIURPEhE19IKqgvrn3x74ll2lu6iqq5Kbn0KIHiUiEvqTa5+sf/7chufqn/eN7xuKcIQQIiQiIqGX1ZaRGpvK2+e9TY2zBgCTMjEgYUCIIxNCiK7jV0JXSuUAFYATcGits5VSqcDbQBbGikW/0FofDU6YrbPV2RiaPFRq5EKIHq09N0VP11pP0Fpnu1/fDSzWWo8AFrtfh4TdaZcboEKIHq8zvVwuBF5zP38NuKjz4fi2PG85L258kS1HtvjcvvXIVknoQogez9+EroGvlVJrlVLz3WV9tNb5AO7HDF8HKqXmK6XWKKXWFBcXdyjIpQeX8sy6Z3hq7VPNtpXajcFCtc7aDp1bCCEihb83RU/SWh9SSmUAi5RS2/19A631QmAhQHZ2tu5AjNx9wt3sLdtLdV11s21VjioAZgya0ZFTCyFExPCrhq61PuR+LAI+BE4ACpVSmQDux6JgBWkxWUiKTqofNOTNszaoNUqaXIQQPVubCV0pFa+USvQ8B2YBm4GPgbnu3eYCHwUrSDDW/PQM6/dmdxplVrMkdCFEz+ZPk0sf4EOllGf/N7TWXyqlVgPvKKV+BRwALg9emGC1WOvnNwfQWvPChhfYWrK1frsQQvRkbSZ0rfVeYLyP8iPAzGAE5UvThF5YXchzG54jISqBwUmDyUrO6qpQhBAiLHWbkaKx5ljsTjtaa5RS9TdI/3vqfzN7yOwQRyeEEKHXbWZbjIuKw6Vd1LqM7ome2rpMwCWEEIZuk9A9idtzY9ST0KV3ixBCGLpNk4vnpuftS2/nQPkB0q3pjcqFEKKn6zYJfWKfiUzKmMT+sv0U2YqorKtkaubU+vVChRCip+s2TS5Dk4fy2uzXmHPsHADGpI1h4ayFJEYnhjgyIYQID90moXvEWuQmqBBC+NLtErq0mQshhG/dLqF7aujR5ugQRyKEEOGl29wU9ZjSdwoXDLuAy0ZeFupQhBAirHS7hN47rjePTH8k1GEIIUTY6XZNLkIIIXyThC6EEBFCEroQQkQISehCCBEh/E7oSimzUmqdUupT9+tXlVL7lFLr3V8TghemEEKItrSnl8ttwDYgyavsj1rr9wIbkhBCiI7wq4aulBoAnAu8FNxwhBBCdJS/TS5PAX8CXE3KH1FKbVRKPamUiglsaEIIIdqjzSYXpdR5QJHWeq1S6jSvTfcABUA0sBC4C3jIx/Hzgfnul5VKqR0djDUdONzBY7tKuMcY7vGBxBgI4R4fhH+M4RbfYH92Ulrr1ndQ6s/ANYADiMVoQ/9Aa/1Lr31OA+7UWp/X0WjbDFSpNVrr7GCdPxDCPcZwjw8kxkAI9/gg/GMM9/ha0maTi9b6Hq31AK11FjAH+FZr/UulVCaAUkoBFwGbgxqpEEKIVnVmLpfXlVK9AQWsB34TmJCEEEJ0RLsSutZ6KbDU/XxGEOJpzcIufr+OCPcYwz0+kBgDIdzjg/CPMdzj86nNNnQhhBDdgwz9F0KICNEtErpS6myl1A6l1G6l1N0himGgUmqJUmqbUmqLUuo2d3mqUmqRUmqX+zHFXa6UUs+4Y96olJrURXE2naJhiFJqpTu+t5VS0e7yGPfr3e7tWV0UXy+l1HtKqe3uazk1DK/h7e6f8Wal1JtKqdhQX0el1MtKqSKl1GavsnZfN6XUXPf+u5RSc4Mc3/+6f84blVIfKqV6eW27xx3fDqXUWV7lQfus+4rRa9udSimtlEp3v+7yaxgQWuuw/gLMwB5gKEaf9w3A6BDEkQlMcj9PBHYCo4HHgLvd5XcDf3U/Pwf4AuOm8YnAyi6K8w/AG8Cn7tfvAHPcz18AbnI/vxl4wf18DvB2F8X3GnCD+3k00CucriHQH9gHWL2u33Whvo7AKcAkYLNXWbuuG5AK7HU/prifpwQxvlmAxf38r17xjXZ/jmOAIe7PtznYn3VfMbrLBwJfAfuB9FBdw4B8j6EOwI8fwlTgK6/X9wD3hEFcHwFnAjuATHdZJrDD/fzvwJVe+9fvF8SYBgCLgRnAp+5fxsNeH6r6a+n+BZ7qfm5x76eCHF+SO1mqJuXhdA37AwfdH1iL+zqeFQ7XEchqkjDbdd2AK4G/e5U32i/Q8TXZdjHwuvt5o8+w5xp2xWfdV4zAe8B4IIeGhB6Sa9jZr+7Q5OL5gHnkustCxv1v9URgJdBHa50P4H7McO8WiribTtGQBpRqrR0+YqiPz729zL1/MA0FioFX3M1CLyml4gmja6i1zgMeBw4A+RjXZS3hdR092nvdQvlZuh6jxksrcXR5fEqpC4A8rfWGJpvCJsb26A4JXfkoC1nXHKVUAvA+8HutdXlru/ooC1rcymuKBj9jCMV1tWD8y/u81noiUIXRVNCSLo/R3Q59IUZTQD8gHpjdShxh9fvp1lJMIYlVKXUfxkjz1z1FLcTR1Z+ZOOA+4L99bW4hlnD8edfrDgk9F6ONy2MAcCgUgSilojCS+eta6w/cxYWqYdRsJlDkLu/quE8CLlBK5QBvYTS7PAX0Ukp5xht4x1Afn3t7MlASxPg875mrtV7pfv0eRoIPl2sIcAawT2tdrLWuAz4AphFe19Gjvdety6+n+6bhecDV2t1GEUbxDcP4w73B/bkZAPyslOobRjG2S3dI6KuBEe5eBtEYN54+7uoglFIK+AewTWv9f16bPgY8d7rnYrSte8qvdd8tPxEo8/x7HAza9xQNVwNLgMtaiM8T92Xu/YNa09BaFwAHlVLHuItmAlsJk2vodgA4USkV5/6Ze2IMm+vopb3X7StgllIqxf2fyCx3WVAopc7GmLTvAq11dZO457h7CA0BRgCr6OLPutZ6k9Y6Q2ud5f7c5GJ0fCggTK5hu4W6Ed/PGxnnYPQq2QPcF6IYpmP8a7URY6qD9e640jBuRO5yP6a691fA39wxbwKyuzDW02jo5TIU48OyG3gXiHGXx7pf73ZvH9pFsU0A1riv438wegqE1TUE/gfYjjE/0b8wemOE9DoCb2K06ddhJJ5fdeS6YbRl73Z/zQtyfLsx2ps9n5cXvPa/zx3fDmC2V3nQPuu+YmyyPYeGm6Jdfg0D8SUjRYUQIkJ0hyYXIYQQfpCELoQQEUISuhBCRAhJ6EIIESEkoQshRISQhC6EEBFCEroQQkQISehCCBEh/j9cma/bu7aqbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(100*(Ntrain-np.array(train_errors))/Ntrain)\n",
    "plt.plot(100*(Nvalidation-np.array(validation_errors))/Nvalidation)\n",
    "plt.plot(100*(Ntest-np.array(test_errors))/Ntest)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
